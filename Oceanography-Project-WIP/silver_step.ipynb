{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "from imports import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_postgresql_creds = r\"C:\\Users\\f.gionnane\\Documents\\Data Engineering\\Credentials\\postgresql_creds.json\"\n",
    "\n",
    "with open(path_postgresql_creds, 'r') as file:\n",
    "    content = json.load(file)\n",
    "    user = content[\"user\"]\n",
    "    password = content[\"password\"]\n",
    "    host = content[\"host\"]\n",
    "    port = content[\"port\"]\n",
    "\n",
    "db = \"Oceanography_ML_Project\"\n",
    "schema_bronze = \"Bronze\"\n",
    "schema_silver = \"Silver\"\n",
    "conn_string = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{db}\"\n",
    "# Créer l'engine PostgreSQL\n",
    "engine = create_engine(conn_string)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les Données des Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Chargement des métadonnées du schéma...\n",
      "✅ Métadonnées chargées avec succès.\n",
      "\n",
      "🔢 Nombre total de tables dans le schéma : 79\n",
      "\n",
      "🌊 Tables marines trouvées : 39\n",
      "🌧️ Tables météo trouvées : 39\n",
      "🐋 Tables de bouées trouvées : 1\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🔄 Chargement des données de la table 'buoys_datas'...\n",
      "📦 Données récupérées pour 'buoys_datas'.\n",
      "✅ Table 'buoys_datas' chargée avec succès! Nombre de bouées (lignes) : 39\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🔄 Chargement des données pour la table Marine : station_POTA2_marine_potato point, ak...\n",
      "📦 Données récupérées pour la station POTA2 (Marine).\n",
      "🌊 Données Marine chargées pour la station POTA2! Nombre de lignes collectées : 2569\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46071_marine_western aleutians...\n",
      "📦 Données récupérées pour la station 46071 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46071! Nombre de lignes collectées : 7644\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_LONF1_marine_long key, fl...\n",
      "📦 Données récupérées pour la station LONF1 (Marine).\n",
      "🌊 Données Marine chargées pour la station LONF1! Nombre de lignes collectées : 7566\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46053_marine_east santa barbara...\n",
      "📦 Données récupérées pour la station 46053 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46053! Nombre de lignes collectées : 7692\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_FFIA2_marine_five fingers, ak...\n",
      "📦 Données récupérées pour la station FFIA2 (Marine).\n",
      "🌊 Données Marine chargées pour la station FFIA2! Nombre de lignes collectées : 1287\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42001_marine_mid gulf...\n",
      "📦 Données récupérées pour la station 42001 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42001! Nombre de lignes collectées : 2494\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46025_marine_santa monica basin...\n",
      "📦 Données récupérées pour la station 46025 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46025! Nombre de lignes collectées : 7688\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46006_marine_southeast papa...\n",
      "📦 Données récupérées pour la station 46006 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46006! Nombre de lignes collectées : 7646\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_SBIO1_marine_south bass island, oh...\n",
      "📦 Données récupérées pour la station SBIO1 (Marine).\n",
      "🌊 Données Marine chargées pour la station SBIO1! Nombre de lignes collectées : 1285\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_51001_marine_northwestern hawaii one...\n",
      "📦 Données récupérées pour la station 51001 (Marine).\n",
      "🌊 Données Marine chargées pour la station 51001! Nombre de lignes collectées : 7640\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42058_marine_central caribbean...\n",
      "📦 Données récupérées pour la station 42058 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42058! Nombre de lignes collectées : 7623\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_41044_marine_ne st martin...\n",
      "📦 Données récupérées pour la station 41044 (Marine).\n",
      "🌊 Données Marine chargées pour la station 41044! Nombre de lignes collectées : 7636\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42056_marine_yucatan basin...\n",
      "📦 Données récupérées pour la station 42056 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42056! Nombre de lignes collectées : 7643\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_MRKA2_marine_middle rock light, ak...\n",
      "📦 Données récupérées pour la station MRKA2 (Marine).\n",
      "🌊 Données Marine chargées pour la station MRKA2! Nombre de lignes collectées : 2570\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_SANF1_marine_sand key, fl...\n",
      "📦 Données récupérées pour la station SANF1 (Marine).\n",
      "🌊 Données Marine chargées pour la station SANF1! Nombre de lignes collectées : 7604\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46027_marine_st georges...\n",
      "📦 Données récupérées pour la station 46027 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46027! Nombre de lignes collectées : 7693\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44020_marine_nantucket sound...\n",
      "📦 Données récupérées pour la station 44020 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44020! Nombre de lignes collectées : 7650\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44025_marine_long island...\n",
      "📦 Données récupérées pour la station 44025 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44025! Nombre de lignes collectées : 7666\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_51000_marine_northern hawaii one...\n",
      "📦 Données récupérées pour la station 51000 (Marine).\n",
      "🌊 Données Marine chargées pour la station 51000! Nombre de lignes collectées : 7647\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46069_marine_south santa rosa...\n",
      "📦 Données récupérées pour la station 46069 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46069! Nombre de lignes collectées : 7666\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_MDRM1_marine_mt_ desert rock, me...\n",
      "📦 Données récupérées pour la station MDRM1 (Marine).\n",
      "🌊 Données Marine chargées pour la station MDRM1! Nombre de lignes collectées : 1286\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_BURL1_marine_southwest pass, la...\n",
      "📦 Données récupérées pour la station BURL1 (Marine).\n",
      "🌊 Données Marine chargées pour la station BURL1! Nombre de lignes collectées : 1284\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46086_marine_san clemente basin...\n",
      "📦 Données récupérées pour la station 46086 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46086! Nombre de lignes collectées : 7694\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46014_marine_pt arena...\n",
      "📦 Données récupérées pour la station 46014 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46014! Nombre de lignes collectées : 7697\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46072_marine_central aleutians 230 nm sw dutch harbor...\n",
      "📦 Données récupérées pour la station 46072 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46072! Nombre de lignes collectées : 7647\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42002_marine_west gulf...\n",
      "📦 Données récupérées pour la station 42002 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42002! Nombre de lignes collectées : 2648\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_41008_marine_grays reef...\n",
      "📦 Données récupérées pour la station 41008 (Marine).\n",
      "🌊 Données Marine chargées pour la station 41008! Nombre de lignes collectées : 7676\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46088_marine_new dungeness...\n",
      "📦 Données récupérées pour la station 46088 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46088! Nombre de lignes collectées : 7694\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42012_marine_orange beach...\n",
      "📦 Données récupérées pour la station 42012 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42012! Nombre de lignes collectées : 7628\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46022_marine_eel river...\n",
      "📦 Données récupérées pour la station 46022 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46022! Nombre de lignes collectées : 7710\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46001_marine_western gulf of alaska...\n",
      "📦 Données récupérées pour la station 46001 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46001! Nombre de lignes collectées : 7638\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44065_marine_new york harbor entrance...\n",
      "📦 Données récupérées pour la station 44065 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44065! Nombre de lignes collectées : 7629\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46029_marine_columbia river bar...\n",
      "📦 Données récupérées pour la station 46029 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46029! Nombre de lignes collectées : 7692\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46087_marine_neah bay...\n",
      "📦 Données récupérées pour la station 46087 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46087! Nombre de lignes collectées : 7700\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46078_marine_albatross bank...\n",
      "📦 Données récupérées pour la station 46078 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46078! Nombre de lignes collectées : 7638\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44027_marine_jonesport, me...\n",
      "📦 Données récupérées pour la station 44027 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44027! Nombre de lignes collectées : 7644\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_51002_marine_southwest hawaii...\n",
      "📦 Données récupérées pour la station 51002 (Marine).\n",
      "🌊 Données Marine chargées pour la station 51002! Nombre de lignes collectées : 7637\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42036_marine_west tampa...\n",
      "📦 Données récupérées pour la station 42036 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42036! Nombre de lignes collectées : 7614\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46084_marine_cape edgecumbe...\n",
      "📦 Données récupérées pour la station 46084 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46084! Nombre de lignes collectées : 7646\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🔄 Chargement des données pour la table Meteo : station_46072_meteo_central aleutians 230 nm sw dutch harbor...\n",
      "📦 Données récupérées pour la station 46072 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46072! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_FFIA2_meteo_five fingers, ak...\n",
      "📦 Données récupérées pour la station FFIA2 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station FFIA2! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46027_meteo_st georges...\n",
      "📦 Données récupérées pour la station 46027 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46027! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46087_meteo_neah bay...\n",
      "📦 Données récupérées pour la station 46087 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46087! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_BURL1_meteo_southwest pass, la...\n",
      "📦 Données récupérées pour la station BURL1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station BURL1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44065_meteo_new york harbor entrance...\n",
      "📦 Données récupérées pour la station 44065 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44065! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42002_meteo_west gulf...\n",
      "📦 Données récupérées pour la station 42002 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42002! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46001_meteo_western gulf of alaska...\n",
      "📦 Données récupérées pour la station 46001 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46001! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46069_meteo_south santa rosa...\n",
      "📦 Données récupérées pour la station 46069 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46069! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46078_meteo_albatross bank...\n",
      "📦 Données récupérées pour la station 46078 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46078! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42012_meteo_orange beach...\n",
      "📦 Données récupérées pour la station 42012 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42012! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_SANF1_meteo_sand key, fl...\n",
      "📦 Données récupérées pour la station SANF1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station SANF1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46006_meteo_southeast papa...\n",
      "📦 Données récupérées pour la station 46006 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46006! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_41044_meteo_ne st martin...\n",
      "📦 Données récupérées pour la station 41044 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 41044! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44020_meteo_nantucket sound...\n",
      "📦 Données récupérées pour la station 44020 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44020! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46025_meteo_santa monica basin...\n",
      "📦 Données récupérées pour la station 46025 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46025! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42001_meteo_mid gulf...\n",
      "📦 Données récupérées pour la station 42001 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42001! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46014_meteo_pt arena...\n",
      "📦 Données récupérées pour la station 46014 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46014! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_LONF1_meteo_long key, fl...\n",
      "📦 Données récupérées pour la station LONF1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station LONF1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46053_meteo_east santa barbara...\n",
      "📦 Données récupérées pour la station 46053 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46053! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_51001_meteo_northwestern hawaii one...\n",
      "📦 Données récupérées pour la station 51001 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 51001! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46086_meteo_san clemente basin...\n",
      "📦 Données récupérées pour la station 46086 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46086! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42058_meteo_central caribbean...\n",
      "📦 Données récupérées pour la station 42058 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42058! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_MDRM1_meteo_mt_ desert rock, me...\n",
      "📦 Données récupérées pour la station MDRM1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station MDRM1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46022_meteo_eel river...\n",
      "📦 Données récupérées pour la station 46022 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46022! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_51002_meteo_southwest hawaii...\n",
      "📦 Données récupérées pour la station 51002 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 51002! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46088_meteo_new dungeness...\n",
      "📦 Données récupérées pour la station 46088 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46088! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_POTA2_meteo_potato point, ak...\n",
      "📦 Données récupérées pour la station POTA2 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station POTA2! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_MRKA2_meteo_middle rock light, ak...\n",
      "📦 Données récupérées pour la station MRKA2 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station MRKA2! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_SBIO1_meteo_south bass island, oh...\n",
      "📦 Données récupérées pour la station SBIO1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station SBIO1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46029_meteo_columbia river bar...\n",
      "📦 Données récupérées pour la station 46029 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46029! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_41008_meteo_grays reef...\n",
      "📦 Données récupérées pour la station 41008 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 41008! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_51000_meteo_northern hawaii one...\n",
      "📦 Données récupérées pour la station 51000 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 51000! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42036_meteo_west tampa...\n",
      "📦 Données récupérées pour la station 42036 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42036! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46084_meteo_cape edgecumbe...\n",
      "📦 Données récupérées pour la station 46084 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46084! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46071_meteo_western aleutians...\n",
      "📦 Données récupérées pour la station 46071 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46071! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42056_meteo_yucatan basin...\n",
      "📦 Données récupérées pour la station 42056 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42056! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44027_meteo_jonesport, me...\n",
      "📦 Données récupérées pour la station 44027 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44027! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44025_meteo_long island...\n",
      "📦 Données récupérées pour la station 44025 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44025! Nombre de lignes collectées : 2448\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🏆 Chargement des données terminé avec succès !\n",
      "🐋 Total des données bouées chargées : 1 - Nombre de bouées (lignes) : 39\n",
      "🌊 Total des données marines chargées : 39 - Nombre total de lignes : 252711\n",
      "🌧️ Total des données météorologiques chargées : 39 - Nombre total de lignes : 95472\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n"
     ]
    }
   ],
   "source": [
    "# Charger les métadonnées du schéma existant\n",
    "metadata = MetaData(schema=schema_bronze)\n",
    "\n",
    "print(\"\\n🔍 Chargement des métadonnées du schéma...\")\n",
    "metadata.reflect(bind=conn)\n",
    "print(\"✅ Métadonnées chargées avec succès.\\n\")\n",
    "\n",
    "# Récupérer les noms des tables\n",
    "table_names = [t.name for t in metadata.sorted_tables]\n",
    "print(f\"🔢 Nombre total de tables dans le schéma : {len(table_names)}\\n\")\n",
    "\n",
    "# Filtrer les tables en fonction du contenu de leur nom\n",
    "marine_tables = {t for t in table_names if \"marine\" in t.lower()}\n",
    "meteo_tables = {t for t in table_names if \"meteo\" in t.lower()}\n",
    "buoys_data_table = {t for t in table_names if \"buoy\" in t.lower()}\n",
    "\n",
    "print(f\"🌊 Tables marines trouvées : {len(marine_tables)}\")\n",
    "print(f\"🌧️ Tables météo trouvées : {len(meteo_tables)}\")\n",
    "print(f\"🐋 Tables de bouées trouvées : {len(buoys_data_table)}\\n\")\n",
    "\n",
    "# Initialiser le dictionnaire des résultats\n",
    "buoys_datas = {}\n",
    "\n",
    "# Compteurs pour suivre le nombre de tables chargées avec succès\n",
    "marine_data_count = 0\n",
    "meteo_data_count = 0\n",
    "buoys_data_count = 0\n",
    "\n",
    "# Compteur pour le nombre total de lignes\n",
    "total_marine_rows = 0\n",
    "total_meteo_rows = 0\n",
    "total_buoys_rows = 0  # Changer ici pour compter le nombre de lignes (bouées)\n",
    "\n",
    "# Vérifier et récupérer les données de la table \"buoys_datas\"\n",
    "if buoys_data_table:\n",
    "    print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "    print(\"🔄 Chargement des données de la table 'buoys_datas'...\")\n",
    "\n",
    "    try:\n",
    "        buoys_datas_raw = fetch_table_data(schema=schema_bronze, conn=conn, table_name=next(iter(buoys_data_table)), as_df=True)\n",
    "\n",
    "        if buoys_datas_raw is not None:\n",
    "            print(\"📦 Données récupérées pour 'buoys_datas'.\")\n",
    "\n",
    "            # Conversion JSON → dict si nécessaire\n",
    "            if isinstance(buoys_datas_raw, str):\n",
    "                buoys_datas_raw = json.loads(buoys_datas_raw)\n",
    "\n",
    "            elif isinstance(buoys_datas_raw, pd.DataFrame) and \"Station ID\" in buoys_datas_raw.columns:\n",
    "                # Convertir en dictionnaire avec \"Station ID\" comme clé\n",
    "                buoys_datas_raw = buoys_datas_raw.set_index(\"Station ID\").to_dict(orient=\"index\")\n",
    "\n",
    "            # Ajouter au dictionnaire principal directement avec les Station ID comme clés\n",
    "            buoys_datas.update(buoys_datas_raw)\n",
    "            buoys_data_count += 1\n",
    "            total_buoys_rows += len(buoys_datas_raw)  # Compter le nombre de bouées\n",
    "            print(f\"✅ Table 'buoys_datas' chargée avec succès! Nombre de bouées (lignes) : {total_buoys_rows}\\n\")\n",
    "        else:\n",
    "            print(\"⚠️ Aucun résultat trouvé dans 'buoys_datas'.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du chargement de 'buoys_datas': {e}\\n\")\n",
    "\n",
    "# Associer les tables marine et meteo en fonction du station_id et récupérer leurs données\n",
    "for table_set, label, icon, counter, total_rows in [\n",
    "    (marine_tables, \"Marine\", \"🌊\", marine_data_count, total_marine_rows),\n",
    "    (meteo_tables, \"Meteo\", \"🌧️\", meteo_data_count, total_meteo_rows)\n",
    "]:\n",
    "    print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "    for table_name in table_set:\n",
    "        print(f\"🔄 Chargement des données pour la table {label} : {table_name}...\")\n",
    "\n",
    "        try:\n",
    "            station_id = table_name.split(\"_\")[1]\n",
    "\n",
    "            # Vérifier si la station existe déjà dans buoys_datas, sinon initialiser un dictionnaire\n",
    "            if station_id not in buoys_datas:\n",
    "                buoys_datas[station_id] = {}\n",
    "\n",
    "            # Récupérer les données\n",
    "            data = fetch_table_data(schema=schema_bronze, conn=conn, table_name=table_name, as_df=True)\n",
    "\n",
    "            if data is not None:\n",
    "                print(f\"📦 Données récupérées pour la station {station_id} ({label}).\")\n",
    "\n",
    "                if isinstance(data, str):\n",
    "                    data = pd.DataFrame(json.loads(data))\n",
    "                elif isinstance(data, dict):\n",
    "                    data = pd.DataFrame(data)\n",
    "                # Ajouter les données au dictionnaire de bouées sous la station_id\n",
    "                buoys_datas[station_id][f\"{label} DataFrame\"] = data\n",
    "                counter += 1\n",
    "                total_rows += len(data)  # Ajouter le nombre de lignes collectées\n",
    "                print(f\"{icon} Données {label} chargées pour la station {station_id}! Nombre de lignes collectées : {len(data)}\\n\")\n",
    "            else:\n",
    "                print(f\"⚠️ Aucun résultat trouvé pour la station {station_id} ({label}).\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lors du chargement des données {label} pour {table_name} : {e}\\n\")\n",
    "\n",
    "    # Mise à jour des compteurs après le chargement des données pour chaque catégorie\n",
    "    if label == \"Marine\":\n",
    "        marine_data_count = counter\n",
    "        total_marine_rows = total_rows\n",
    "    elif label == \"Meteo\":\n",
    "        meteo_data_count = counter\n",
    "        total_meteo_rows = total_rows\n",
    "\n",
    "# Finalement, afficher un récapitulatif global\n",
    "print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "print(f\"🏆 Chargement des données terminé avec succès !\")\n",
    "print(f\"🐋 Total des données bouées chargées : {buoys_data_count} - Nombre de bouées (lignes) : {total_buoys_rows}\")\n",
    "print(f\"🌊 Total des données marines chargées : {marine_data_count} - Nombre total de lignes : {total_marine_rows}\")\n",
    "print(f\"🌧️ Total des données météorologiques chargées : {meteo_data_count} - Nombre total de lignes : {total_meteo_rows}\")\n",
    "print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           int64\n",
       "wind_direction             float64\n",
       "wind_speed                 float64\n",
       "wind_gust                  float64\n",
       "wave_height                float64\n",
       "dominant_wave_period       float64\n",
       "average_wave_period        float64\n",
       "dominant_wave_direction    float64\n",
       "pressure                   float64\n",
       "air_temperature            float64\n",
       "water_temperature          float64\n",
       "dewpoint                   float64\n",
       "visibility                  object\n",
       "3hr_pressure_tendency      float64\n",
       "water_level_above_mean      object\n",
       "time                        object\n",
       "Station ID                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buoys_datas[\"42058\"][\"Marine DataFrame\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'date', 'temperature_2m', 'relative_humidity_2m', 'dew_point_2m',\n",
       "       'precipitation', 'rain', 'showers', 'pressure_msl', 'surface_pressure',\n",
       "       'cloud_cover', 'cloud_cover_low', 'cloud_cover_mid', 'cloud_cover_high',\n",
       "       'visibility', 'wind_speed_10m', 'soil_temperature_0cm',\n",
       "       'soil_moisture_0_to_1cm', 'is_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buoys_datas[\"42058\"][\"Meteo DataFrame\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         int64\n",
       "date                      object\n",
       "temperature_2m            object\n",
       "relative_humidity_2m      object\n",
       "dew_point_2m              object\n",
       "precipitation             object\n",
       "rain                      object\n",
       "showers                   object\n",
       "pressure_msl              object\n",
       "surface_pressure          object\n",
       "cloud_cover               object\n",
       "cloud_cover_low           object\n",
       "cloud_cover_mid           object\n",
       "cloud_cover_high          object\n",
       "visibility                object\n",
       "wind_speed_10m            object\n",
       "soil_temperature_0cm      object\n",
       "soil_moisture_0_to_1cm    object\n",
       "is_day                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buoys_datas[\"42058\"][\"Meteo DataFrame\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_silver_merged_df = []  \n",
    "list_failed_dfs = []        \n",
    "\n",
    "number_marine_data = 0\n",
    "number_meteo_data = 0\n",
    "number_merged_data = 0\n",
    "\n",
    "marine_data_conversion = 0\n",
    "meteo_data_conversion = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n"
     ]
    }
   ],
   "source": [
    "marine_cols = [\n",
    "    \"wind_direction\", \"wind_speed\", \"wind_gust\", \"wave_height\",\n",
    "    \"dominant_wave_period\", \"average_wave_period\", \"dominant_wave_direction\",\n",
    "    \"pressure\", \"air_temperature\", \"water_temperature\", \"dewpoint\",\n",
    "    \"visibility\", \"3hr_pressure_tendency\", \"water_level_above_mean\"\n",
    "]\n",
    "\n",
    "meteo_cols = [\n",
    "    \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"precipitation\", \"rain\",\n",
    "    \"showers\", \"pressure_msl\", \"surface_pressure\", \"cloud_cover\", \"cloud_cover_low\",\n",
    "    \"cloud_cover_mid\", \"cloud_cover_high\", \"visibility\", \"wind_speed_10m\",\n",
    "    \"soil_temperature_0cm\", \"soil_moisture_0_to_1cm\"\n",
    "]\n",
    "\n",
    "col_to_rename={'temperature_2m': 'T°(C°)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (°C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (km)',  'wind_direction': 'Wind Direction (°)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (°)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air T°','water_temperature': 'Water T°'}\n",
    "\n",
    "meteo_cols_to_delete = ['soil_temperature_0cm','rain', 'showers', 'is_day',\n",
    "                  'soil_moisture_0_to_1cm']\n",
    "\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    marine_df = tables[\"Marine DataFrame\"]\n",
    "    marine_df = rename_columns(marine_df, col_to_rename)\n",
    "\n",
    "    marine_df = drop_columns_if_exist\n",
    "\n",
    "    meteo_df = tables[\"Meteo DataFrame\"]\n",
    "    meteo_df = rename_columns(meteo_df,col_to_rename)\n",
    "    meteo_df = drop_columns_if_exist(meteo_df, meteo_cols_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOUR RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Processing and resampling marine data for station 41008...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 41008...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 41044...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 41044...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42001...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42001...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42002...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42002...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42012...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42012...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42036...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42036...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42056...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42056...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42058...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42058...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 44020...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 44020...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 44025...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 44025...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 44027...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 44027...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 44065...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 44065...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46001...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46001...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46006...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46006...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46014...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46014...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46022...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46022...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46025...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46025...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46027...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46027...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46029...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46029...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46053...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46053...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46069...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46069...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46071...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46071...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46072...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46072...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46078...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46078...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46084...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46084...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46086...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46086...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46087...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46087...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46088...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46088...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 51000...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 51000...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 51001...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 51001...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 51002...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 51002...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station BURL1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station BURL1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station FFIA2...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station FFIA2...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station LONF1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station LONF1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station MDRM1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station MDRM1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station MRKA2...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station MRKA2...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station POTA2...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station POTA2...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station SANF1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station SANF1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station SBIO1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station SBIO1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n"
     ]
    }
   ],
   "source": [
    "# Resampling des données et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"🔁 Processing and resampling marine data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Marine DataFrame\"] = process_datetime_column(tables[\"Marine DataFrame\"], column='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Marine Data for {station_id}: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"🔁 Processing and resampling weather data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Meteo DataFrame\"] = process_datetime_column(tables[\"Meteo DataFrame\"], column='date')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Meteo Data for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Coordinates (Lat/Lon) added for station 41008.\n",
      "🌐 Coordinates (Lat/Lon) added for station 41044.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42001.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42002.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42012.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42036.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42056.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42058.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44020.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44025.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44027.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44065.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46001.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46006.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46014.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46022.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46025.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46027.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46029.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46053.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46069.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46071.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46072.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46078.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46084.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46086.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46087.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46088.\n",
      "🌐 Coordinates (Lat/Lon) added for station 51000.\n",
      "🌐 Coordinates (Lat/Lon) added for station 51001.\n",
      "🌐 Coordinates (Lat/Lon) added for station 51002.\n",
      "🌐 Coordinates (Lat/Lon) added for station BURL1.\n",
      "🌐 Coordinates (Lat/Lon) added for station FFIA2.\n",
      "🌐 Coordinates (Lat/Lon) added for station LONF1.\n",
      "🌐 Coordinates (Lat/Lon) added for station MDRM1.\n",
      "🌐 Coordinates (Lat/Lon) added for station MRKA2.\n",
      "🌐 Coordinates (Lat/Lon) added for station POTA2.\n",
      "🌐 Coordinates (Lat/Lon) added for station SANF1.\n",
      "🌐 Coordinates (Lat/Lon) added for station SBIO1.\n"
     ]
    }
   ],
   "source": [
    "# Ajout des coordonnées\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        tables[\"Marine DataFrame\"][\"Lat\"] = tables[\"Lat\"]\n",
    "        tables[\"Marine DataFrame\"][\"Lon\"] = tables[\"Lon\"]\n",
    "        print(f\"🌐 Coordinates (Lat/Lon) added for station {station_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding coordinates for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Based on Station ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Merging marine and weather data for station 41008...\n",
      "🔗 Merging marine and weather data for station 41044...\n",
      "🔗 Merging marine and weather data for station 42001...\n",
      "🔗 Merging marine and weather data for station 42002...\n",
      "🔗 Merging marine and weather data for station 42012...\n",
      "🔗 Merging marine and weather data for station 42036...\n",
      "🔗 Merging marine and weather data for station 42056...\n",
      "🔗 Merging marine and weather data for station 42058...\n",
      "🔗 Merging marine and weather data for station 44020...\n",
      "🔗 Merging marine and weather data for station 44025...\n",
      "🔗 Merging marine and weather data for station 44027...\n",
      "🔗 Merging marine and weather data for station 44065...\n",
      "🔗 Merging marine and weather data for station 46001...\n",
      "🔗 Merging marine and weather data for station 46006...\n",
      "🔗 Merging marine and weather data for station 46014...\n",
      "🔗 Merging marine and weather data for station 46022...\n",
      "🔗 Merging marine and weather data for station 46025...\n",
      "🔗 Merging marine and weather data for station 46027...\n",
      "🔗 Merging marine and weather data for station 46029...\n",
      "🔗 Merging marine and weather data for station 46053...\n",
      "🔗 Merging marine and weather data for station 46069...\n",
      "🔗 Merging marine and weather data for station 46071...\n",
      "🔗 Merging marine and weather data for station 46072...\n",
      "🔗 Merging marine and weather data for station 46078...\n",
      "🔗 Merging marine and weather data for station 46084...\n",
      "🔗 Merging marine and weather data for station 46086...\n",
      "🔗 Merging marine and weather data for station 46087...\n",
      "🔗 Merging marine and weather data for station 46088...\n",
      "🔗 Merging marine and weather data for station 51000...\n",
      "🔗 Merging marine and weather data for station 51001...\n",
      "🔗 Merging marine and weather data for station 51002...\n",
      "🔗 Merging marine and weather data for station BURL1...\n",
      "🔗 Merging marine and weather data for station FFIA2...\n",
      "🔗 Merging marine and weather data for station LONF1...\n",
      "🔗 Merging marine and weather data for station MDRM1...\n",
      "🔗 Merging marine and weather data for station MRKA2...\n",
      "🔗 Merging marine and weather data for station POTA2...\n",
      "🔗 Merging marine and weather data for station SANF1...\n",
      "🔗 Merging marine and weather data for station SBIO1...\n"
     ]
    }
   ],
   "source": [
    "number_merged_data = 0\n",
    "list_silver_merged_df=[]\n",
    "# Fusion des DataFrames\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "\n",
    "        metadatas = get_station_metadata(station_id=station_id)\n",
    "        print(f\"🔗 Merging marine and weather data for station {station_id}...\")\n",
    "        df_merged = pd.merge(\n",
    "            tables[\"Marine DataFrame\"], tables[\"Meteo DataFrame\"], on='Datetime', how='inner'\n",
    "        )\n",
    "        tables[\"Merged DataFrame\"] = df_merged\n",
    "        number_merged_data += df_merged.shape[0]\n",
    "        list_silver_merged_df.append(df_merged)\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging data for station {station_id}: {e}\")\n",
    "\n",
    "# print(f'{len(list_silver_merged_df)} DataFrames Merged :\\n{number_merged_data} rows in total !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "Zone\n",
      "Lat\n",
      "Lon\n",
      "Marine DataFrame\n",
      "Meteo DataFrame\n",
      "Merged DataFrame\n"
     ]
    }
   ],
   "source": [
    "for key, value in buoys_datas.items():\n",
    "    if value['id'] == 1:\n",
    "        for key, val in value.items():\n",
    "            print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_x', 'Wind Direction (°)', 'Wind Speed (km/h)', 'Wind Gusts (km/h)',\n",
       "       'Wave Height (m)', 'dominant_wave_period', 'Average Wave Period (s)',\n",
       "       'Dominant Wave Direction (°)', 'Pressure (hPA)', 'Air T°', 'Water T°',\n",
       "       'dewpoint', ' Visibility (km)_x', '3hr_pressure_tendency',\n",
       "       'water_level_above_mean', 'Datetime', 'Station ID', 'Lat', 'Lon',\n",
       "       'id_y', 'T°(C°)', 'Relative Humidity (%)', 'Dew Point (°C)',\n",
       "       'Precipitation (mm)', 'rain', 'showers', ' Sea Level Pressure (hPa)',\n",
       "       'surface_pressure', 'cloud_cover', 'Low Clouds (%)',\n",
       "       'Middle Clouds (%)', 'High Clouds (%)', ' Visibility (km)_y',\n",
       "       'wind_speed_10m', 'soil_temperature_0cm', 'soil_moisture_0_to_1cm',\n",
       "       'is_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_x                           1  (int64)\n",
      "Wind Direction (°)             240.0  (float64)\n",
      "Wind Speed (km/h)              9.3  (float64)\n",
      "Wind Gusts (km/h)              9.8  (float64)\n",
      "Wave Height (m)                None  (object)\n",
      "dominant_wave_period           None  (object)\n",
      "Average Wave Period (s)        None  (object)\n",
      "Dominant Wave Direction (°)    None  (object)\n",
      "Pressure (hPA)                 1002.7  (float64)\n",
      "Air T°                         7.6  (float64)\n",
      "Water T°                       None  (object)\n",
      "dewpoint                       None  (object)\n",
      " Visibility (km)_x             None  (object)\n",
      "3hr_pressure_tendency          0.4  (float64)\n",
      "water_level_above_mean         None  (object)\n",
      "Datetime                       2025-03-22 11:00:00  (datetime64[ns])\n",
      "Station ID                     SBIO1  (object)\n",
      "Lat                            41.63N  (object)\n",
      "Lon                            82.84W  (object)\n",
      "id_y                           2220  (int64)\n",
      "T°(C°)                         5.110000133514404  (object)\n",
      "Relative Humidity (%)          56.0  (object)\n",
      "Dew Point (°C)                 -2.9600000381469727  (object)\n",
      "Precipitation (mm)             0.0  (object)\n",
      "rain                           0.0  (object)\n",
      "showers                        0.0  (object)\n",
      " Sea Level Pressure (hPa)      1003.7000122070312  (object)\n",
      "surface_pressure               979.2899780273438  (object)\n",
      "cloud_cover                    0.0  (object)\n",
      "Low Clouds (%)                 0.0  (object)\n",
      "Middle Clouds (%)              0.0  (object)\n",
      "High Clouds (%)                0.0  (object)\n",
      " Visibility (km)_y             34300.0  (object)\n",
      "wind_speed_10m                 22.06999969482422  (object)\n",
      "soil_temperature_0cm           6.739999771118164  (object)\n",
      "soil_moisture_0_to_1cm         0.2800000011920929  (object)\n",
      "is_day                         0.0  (object)\n"
     ]
    }
   ],
   "source": [
    "show_first_row(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Adding MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       41008\n",
      "1       41008\n",
      "2       41008\n",
      "3       41008\n",
      "4       41008\n",
      "        ...  \n",
      "7671    41008\n",
      "7672    41008\n",
      "7673    41008\n",
      "7674    41008\n",
      "7675    41008\n",
      "Name: Station ID, Length: 7676, dtype: object\n",
      "0       41044\n",
      "1       41044\n",
      "2       41044\n",
      "3       41044\n",
      "4       41044\n",
      "        ...  \n",
      "7631    41044\n",
      "7632    41044\n",
      "7633    41044\n",
      "7634    41044\n",
      "7635    41044\n",
      "Name: Station ID, Length: 7636, dtype: object\n",
      "0       42001\n",
      "1       42001\n",
      "2       42001\n",
      "3       42001\n",
      "4       42001\n",
      "        ...  \n",
      "2489    42001\n",
      "2490    42001\n",
      "2491    42001\n",
      "2492    42001\n",
      "2493    42001\n",
      "Name: Station ID, Length: 2494, dtype: object\n",
      "0       42002\n",
      "1       42002\n",
      "2       42002\n",
      "3       42002\n",
      "4       42002\n",
      "        ...  \n",
      "2643    42002\n",
      "2644    42002\n",
      "2645    42002\n",
      "2646    42002\n",
      "2647    42002\n",
      "Name: Station ID, Length: 2648, dtype: object\n",
      "0       42012\n",
      "1       42012\n",
      "2       42012\n",
      "3       42012\n",
      "4       42012\n",
      "        ...  \n",
      "7623    42012\n",
      "7624    42012\n",
      "7625    42012\n",
      "7626    42012\n",
      "7627    42012\n",
      "Name: Station ID, Length: 7628, dtype: object\n",
      "0       42036\n",
      "1       42036\n",
      "2       42036\n",
      "3       42036\n",
      "4       42036\n",
      "        ...  \n",
      "7609    42036\n",
      "7610    42036\n",
      "7611    42036\n",
      "7612    42036\n",
      "7613    42036\n",
      "Name: Station ID, Length: 7614, dtype: object\n",
      "0       42056\n",
      "1       42056\n",
      "2       42056\n",
      "3       42056\n",
      "4       42056\n",
      "        ...  \n",
      "7638    42056\n",
      "7639    42056\n",
      "7640    42056\n",
      "7641    42056\n",
      "7642    42056\n",
      "Name: Station ID, Length: 7643, dtype: object\n",
      "0       42058\n",
      "1       42058\n",
      "2       42058\n",
      "3       42058\n",
      "4       42058\n",
      "        ...  \n",
      "7618    42058\n",
      "7619    42058\n",
      "7620    42058\n",
      "7621    42058\n",
      "7622    42058\n",
      "Name: Station ID, Length: 7623, dtype: object\n",
      "0       44020\n",
      "1       44020\n",
      "2       44020\n",
      "3       44020\n",
      "4       44020\n",
      "        ...  \n",
      "7645    44020\n",
      "7646    44020\n",
      "7647    44020\n",
      "7648    44020\n",
      "7649    44020\n",
      "Name: Station ID, Length: 7650, dtype: object\n",
      "0       44025\n",
      "1       44025\n",
      "2       44025\n",
      "3       44025\n",
      "4       44025\n",
      "        ...  \n",
      "7661    44025\n",
      "7662    44025\n",
      "7663    44025\n",
      "7664    44025\n",
      "7665    44025\n",
      "Name: Station ID, Length: 7666, dtype: object\n",
      "0       44027\n",
      "1       44027\n",
      "2       44027\n",
      "3       44027\n",
      "4       44027\n",
      "        ...  \n",
      "7639    44027\n",
      "7640    44027\n",
      "7641    44027\n",
      "7642    44027\n",
      "7643    44027\n",
      "Name: Station ID, Length: 7644, dtype: object\n",
      "0       44065\n",
      "1       44065\n",
      "2       44065\n",
      "3       44065\n",
      "4       44065\n",
      "        ...  \n",
      "7624    44065\n",
      "7625    44065\n",
      "7626    44065\n",
      "7627    44065\n",
      "7628    44065\n",
      "Name: Station ID, Length: 7629, dtype: object\n",
      "0       46001\n",
      "1       46001\n",
      "2       46001\n",
      "3       46001\n",
      "4       46001\n",
      "        ...  \n",
      "7633    46001\n",
      "7634    46001\n",
      "7635    46001\n",
      "7636    46001\n",
      "7637    46001\n",
      "Name: Station ID, Length: 7638, dtype: object\n",
      "0       46006\n",
      "1       46006\n",
      "2       46006\n",
      "3       46006\n",
      "4       46006\n",
      "        ...  \n",
      "7641    46006\n",
      "7642    46006\n",
      "7643    46006\n",
      "7644    46006\n",
      "7645    46006\n",
      "Name: Station ID, Length: 7646, dtype: object\n",
      "0       46014\n",
      "1       46014\n",
      "2       46014\n",
      "3       46014\n",
      "4       46014\n",
      "        ...  \n",
      "7692    46014\n",
      "7693    46014\n",
      "7694    46014\n",
      "7695    46014\n",
      "7696    46014\n",
      "Name: Station ID, Length: 7697, dtype: object\n",
      "0       46022\n",
      "1       46022\n",
      "2       46022\n",
      "3       46022\n",
      "4       46022\n",
      "        ...  \n",
      "7705    46022\n",
      "7706    46022\n",
      "7707    46022\n",
      "7708    46022\n",
      "7709    46022\n",
      "Name: Station ID, Length: 7710, dtype: object\n",
      "0       46025\n",
      "1       46025\n",
      "2       46025\n",
      "3       46025\n",
      "4       46025\n",
      "        ...  \n",
      "7683    46025\n",
      "7684    46025\n",
      "7685    46025\n",
      "7686    46025\n",
      "7687    46025\n",
      "Name: Station ID, Length: 7688, dtype: object\n",
      "0       46027\n",
      "1       46027\n",
      "2       46027\n",
      "3       46027\n",
      "4       46027\n",
      "        ...  \n",
      "7688    46027\n",
      "7689    46027\n",
      "7690    46027\n",
      "7691    46027\n",
      "7692    46027\n",
      "Name: Station ID, Length: 7693, dtype: object\n",
      "0       46029\n",
      "1       46029\n",
      "2       46029\n",
      "3       46029\n",
      "4       46029\n",
      "        ...  \n",
      "7687    46029\n",
      "7688    46029\n",
      "7689    46029\n",
      "7690    46029\n",
      "7691    46029\n",
      "Name: Station ID, Length: 7692, dtype: object\n",
      "0       46053\n",
      "1       46053\n",
      "2       46053\n",
      "3       46053\n",
      "4       46053\n",
      "        ...  \n",
      "7687    46053\n",
      "7688    46053\n",
      "7689    46053\n",
      "7690    46053\n",
      "7691    46053\n",
      "Name: Station ID, Length: 7692, dtype: object\n",
      "0       46069\n",
      "1       46069\n",
      "2       46069\n",
      "3       46069\n",
      "4       46069\n",
      "        ...  \n",
      "7661    46069\n",
      "7662    46069\n",
      "7663    46069\n",
      "7664    46069\n",
      "7665    46069\n",
      "Name: Station ID, Length: 7666, dtype: object\n",
      "0       46071\n",
      "1       46071\n",
      "2       46071\n",
      "3       46071\n",
      "4       46071\n",
      "        ...  \n",
      "7639    46071\n",
      "7640    46071\n",
      "7641    46071\n",
      "7642    46071\n",
      "7643    46071\n",
      "Name: Station ID, Length: 7644, dtype: object\n",
      "0       46072\n",
      "1       46072\n",
      "2       46072\n",
      "3       46072\n",
      "4       46072\n",
      "        ...  \n",
      "7642    46072\n",
      "7643    46072\n",
      "7644    46072\n",
      "7645    46072\n",
      "7646    46072\n",
      "Name: Station ID, Length: 7647, dtype: object\n",
      "0       46078\n",
      "1       46078\n",
      "2       46078\n",
      "3       46078\n",
      "4       46078\n",
      "        ...  \n",
      "7633    46078\n",
      "7634    46078\n",
      "7635    46078\n",
      "7636    46078\n",
      "7637    46078\n",
      "Name: Station ID, Length: 7638, dtype: object\n",
      "0       46084\n",
      "1       46084\n",
      "2       46084\n",
      "3       46084\n",
      "4       46084\n",
      "        ...  \n",
      "7641    46084\n",
      "7642    46084\n",
      "7643    46084\n",
      "7644    46084\n",
      "7645    46084\n",
      "Name: Station ID, Length: 7646, dtype: object\n",
      "0       46086\n",
      "1       46086\n",
      "2       46086\n",
      "3       46086\n",
      "4       46086\n",
      "        ...  \n",
      "7689    46086\n",
      "7690    46086\n",
      "7691    46086\n",
      "7692    46086\n",
      "7693    46086\n",
      "Name: Station ID, Length: 7694, dtype: object\n",
      "0       46087\n",
      "1       46087\n",
      "2       46087\n",
      "3       46087\n",
      "4       46087\n",
      "        ...  \n",
      "7695    46087\n",
      "7696    46087\n",
      "7697    46087\n",
      "7698    46087\n",
      "7699    46087\n",
      "Name: Station ID, Length: 7700, dtype: object\n",
      "0       46088\n",
      "1       46088\n",
      "2       46088\n",
      "3       46088\n",
      "4       46088\n",
      "        ...  \n",
      "7689    46088\n",
      "7690    46088\n",
      "7691    46088\n",
      "7692    46088\n",
      "7693    46088\n",
      "Name: Station ID, Length: 7694, dtype: object\n",
      "0       51000\n",
      "1       51000\n",
      "2       51000\n",
      "3       51000\n",
      "4       51000\n",
      "        ...  \n",
      "7642    51000\n",
      "7643    51000\n",
      "7644    51000\n",
      "7645    51000\n",
      "7646    51000\n",
      "Name: Station ID, Length: 7647, dtype: object\n",
      "0       51001\n",
      "1       51001\n",
      "2       51001\n",
      "3       51001\n",
      "4       51001\n",
      "        ...  \n",
      "7635    51001\n",
      "7636    51001\n",
      "7637    51001\n",
      "7638    51001\n",
      "7639    51001\n",
      "Name: Station ID, Length: 7640, dtype: object\n",
      "0       51002\n",
      "1       51002\n",
      "2       51002\n",
      "3       51002\n",
      "4       51002\n",
      "        ...  \n",
      "7632    51002\n",
      "7633    51002\n",
      "7634    51002\n",
      "7635    51002\n",
      "7636    51002\n",
      "Name: Station ID, Length: 7637, dtype: object\n",
      "0       BURL1\n",
      "1       BURL1\n",
      "2       BURL1\n",
      "3       BURL1\n",
      "4       BURL1\n",
      "        ...  \n",
      "1279    BURL1\n",
      "1280    BURL1\n",
      "1281    BURL1\n",
      "1282    BURL1\n",
      "1283    BURL1\n",
      "Name: Station ID, Length: 1284, dtype: object\n",
      "0       FFIA2\n",
      "1       FFIA2\n",
      "2       FFIA2\n",
      "3       FFIA2\n",
      "4       FFIA2\n",
      "        ...  \n",
      "1282    FFIA2\n",
      "1283    FFIA2\n",
      "1284    FFIA2\n",
      "1285    FFIA2\n",
      "1286    FFIA2\n",
      "Name: Station ID, Length: 1287, dtype: object\n",
      "0       LONF1\n",
      "1       LONF1\n",
      "2       LONF1\n",
      "3       LONF1\n",
      "4       LONF1\n",
      "        ...  \n",
      "7561    LONF1\n",
      "7562    LONF1\n",
      "7563    LONF1\n",
      "7564    LONF1\n",
      "7565    LONF1\n",
      "Name: Station ID, Length: 7566, dtype: object\n",
      "0       MDRM1\n",
      "1       MDRM1\n",
      "2       MDRM1\n",
      "3       MDRM1\n",
      "4       MDRM1\n",
      "        ...  \n",
      "1281    MDRM1\n",
      "1282    MDRM1\n",
      "1283    MDRM1\n",
      "1284    MDRM1\n",
      "1285    MDRM1\n",
      "Name: Station ID, Length: 1286, dtype: object\n",
      "0       MRKA2\n",
      "1       MRKA2\n",
      "2       MRKA2\n",
      "3       MRKA2\n",
      "4       MRKA2\n",
      "        ...  \n",
      "2565    MRKA2\n",
      "2566    MRKA2\n",
      "2567    MRKA2\n",
      "2568    MRKA2\n",
      "2569    MRKA2\n",
      "Name: Station ID, Length: 2570, dtype: object\n",
      "0       POTA2\n",
      "1       POTA2\n",
      "2       POTA2\n",
      "3       POTA2\n",
      "4       POTA2\n",
      "        ...  \n",
      "2564    POTA2\n",
      "2565    POTA2\n",
      "2566    POTA2\n",
      "2567    POTA2\n",
      "2568    POTA2\n",
      "Name: Station ID, Length: 2569, dtype: object\n",
      "0       SANF1\n",
      "1       SANF1\n",
      "2       SANF1\n",
      "3       SANF1\n",
      "4       SANF1\n",
      "        ...  \n",
      "7599    SANF1\n",
      "7600    SANF1\n",
      "7601    SANF1\n",
      "7602    SANF1\n",
      "7603    SANF1\n",
      "Name: Station ID, Length: 7604, dtype: object\n",
      "0       SBIO1\n",
      "1       SBIO1\n",
      "2       SBIO1\n",
      "3       SBIO1\n",
      "4       SBIO1\n",
      "        ...  \n",
      "1280    SBIO1\n",
      "1281    SBIO1\n",
      "1282    SBIO1\n",
      "1283    SBIO1\n",
      "1284    SBIO1\n",
      "Name: Station ID, Length: 1285, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ajout des coordonnées\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "\n",
    "        df_merged = tables[\"Merged DataFrame\"]\n",
    "        station_id = str(df_merged[\"Station ID\"])\n",
    "        print(station_id)\n",
    "        metadatas = get_station_metadata(station_id)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error adding Metadata for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadatas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Changing Data Types  for station 41008...\n",
      "Successfully Changed Data Types for Station 41008\n",
      "🔗 Changing Data Types  for station 41044...\n",
      "Successfully Changed Data Types for Station 41044\n",
      "🔗 Changing Data Types  for station 42001...\n",
      "Successfully Changed Data Types for Station 42001\n",
      "🔗 Changing Data Types  for station 42002...\n",
      "Successfully Changed Data Types for Station 42002\n",
      "🔗 Changing Data Types  for station 42012...\n",
      "Successfully Changed Data Types for Station 42012\n",
      "🔗 Changing Data Types  for station 42036...\n",
      "Successfully Changed Data Types for Station 42036\n",
      "🔗 Changing Data Types  for station 42056...\n",
      "Successfully Changed Data Types for Station 42056\n",
      "🔗 Changing Data Types  for station 42058...\n",
      "Successfully Changed Data Types for Station 42058\n",
      "🔗 Changing Data Types  for station 44020...\n",
      "Successfully Changed Data Types for Station 44020\n",
      "🔗 Changing Data Types  for station 44025...\n",
      "Successfully Changed Data Types for Station 44025\n",
      "🔗 Changing Data Types  for station 44027...\n",
      "Successfully Changed Data Types for Station 44027\n",
      "🔗 Changing Data Types  for station 44065...\n",
      "Successfully Changed Data Types for Station 44065\n",
      "🔗 Changing Data Types  for station 46001...\n",
      "Successfully Changed Data Types for Station 46001\n",
      "🔗 Changing Data Types  for station 46006...\n",
      "Successfully Changed Data Types for Station 46006\n",
      "🔗 Changing Data Types  for station 46014...\n",
      "Successfully Changed Data Types for Station 46014\n",
      "🔗 Changing Data Types  for station 46022...\n",
      "Successfully Changed Data Types for Station 46022\n",
      "🔗 Changing Data Types  for station 46025...\n",
      "Successfully Changed Data Types for Station 46025\n",
      "🔗 Changing Data Types  for station 46027...\n",
      "Successfully Changed Data Types for Station 46027\n",
      "🔗 Changing Data Types  for station 46029...\n",
      "Successfully Changed Data Types for Station 46029\n",
      "🔗 Changing Data Types  for station 46053...\n",
      "Successfully Changed Data Types for Station 46053\n",
      "🔗 Changing Data Types  for station 46069...\n",
      "Successfully Changed Data Types for Station 46069\n",
      "🔗 Changing Data Types  for station 46071...\n",
      "Successfully Changed Data Types for Station 46071\n",
      "🔗 Changing Data Types  for station 46072...\n",
      "Successfully Changed Data Types for Station 46072\n",
      "🔗 Changing Data Types  for station 46078...\n",
      "Successfully Changed Data Types for Station 46078\n",
      "🔗 Changing Data Types  for station 46084...\n",
      "Successfully Changed Data Types for Station 46084\n",
      "🔗 Changing Data Types  for station 46086...\n",
      "Successfully Changed Data Types for Station 46086\n",
      "🔗 Changing Data Types  for station 46087...\n",
      "Successfully Changed Data Types for Station 46087\n",
      "🔗 Changing Data Types  for station 46088...\n",
      "Successfully Changed Data Types for Station 46088\n",
      "🔗 Changing Data Types  for station 51000...\n",
      "Successfully Changed Data Types for Station 51000\n",
      "🔗 Changing Data Types  for station 51001...\n",
      "Successfully Changed Data Types for Station 51001\n",
      "🔗 Changing Data Types  for station 51002...\n",
      "Successfully Changed Data Types for Station 51002\n",
      "🔗 Changing Data Types  for station BURL1...\n",
      "Successfully Changed Data Types for Station BURL1\n",
      "🔗 Changing Data Types  for station FFIA2...\n",
      "Successfully Changed Data Types for Station FFIA2\n",
      "🔗 Changing Data Types  for station LONF1...\n",
      "Successfully Changed Data Types for Station LONF1\n",
      "🔗 Changing Data Types  for station MDRM1...\n",
      "Successfully Changed Data Types for Station MDRM1\n",
      "🔗 Changing Data Types  for station MRKA2...\n",
      "Successfully Changed Data Types for Station MRKA2\n",
      "🔗 Changing Data Types  for station POTA2...\n",
      "Successfully Changed Data Types for Station POTA2\n",
      "🔗 Changing Data Types  for station SANF1...\n",
      "Successfully Changed Data Types for Station SANF1\n",
      "🔗 Changing Data Types  for station SBIO1...\n",
      "Successfully Changed Data Types for Station SBIO1\n"
     ]
    }
   ],
   "source": [
    "def convert_df_columns(df):\n",
    "    \"\"\"\n",
    "    Convertit chaque colonne en son type approprié sans modifier les données\n",
    "    ou introduire des NaN.\n",
    "    \n",
    "    Args:\n",
    "    - df: pd.DataFrame. Le DataFrame à traiter.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Le DataFrame avec les types de données convertis.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Traitement des colonnes avec les types appropriés\n",
    "    for col in df.columns:\n",
    "        # Convertir les colonnes numériques\n",
    "        if df[col].dtype == 'object':\n",
    "            # Tenter de convertir en float si c'est un nombre représenté par des strings\n",
    "            try:\n",
    "                # Convertir en float pour les colonnes qui peuvent l'être (ex: \"Wind Speed (km/h)\", \"Pressure (hPa)\", etc.)\n",
    "                df[col] = pd.to_numeric(df[col], errors='raise')\n",
    "            except ValueError:\n",
    "                # Si la conversion échoue, laisser la colonne intacte\n",
    "                pass\n",
    "                \n",
    "        # Convertir des dates si la colonne contient des chaînes de caractères représentant des dates\n",
    "        if df[col].dtype == 'object' and 'date' in col.lower():\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], errors='raise')\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # Convertir les booléens (is_day) en int\n",
    "        if col == \"is_day\":\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Assurer les types numériques pour les colonnes déjà numériques mais mal typées\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        df[col] = df[col].astype(pd.Float64Dtype())  # Garantir une gestion correcte des NaN dans les colonnes numériques\n",
    "\n",
    "    return df\n",
    "\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        df_merged = tables[\"Merged DataFrame\"]\n",
    "        print(f\"🔗 Changing Data Types  for station {station_id}...\")\n",
    "        df_converted = convert_df_columns(df_merged)\n",
    "        tables[\"Converted DataFrame\"] = df_converted\n",
    "        \n",
    "        print(f\"Successfully Changed Data Types for Station {station_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error changing data types for station {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    for column in df.columns:\n",
    "        # Calculer le pourcentage de valeurs manquantes\n",
    "        missing_percentage = df[column].isnull().mean() * 100\n",
    "        \n",
    "        # Supprimer la colonne si elle est totalement nulle\n",
    "        if df[column].isnull().sum() == len(df[column]):\n",
    "            df = df.drop(columns=[column])\n",
    "            continue\n",
    "        \n",
    "        # Si plus de 50% des valeurs sont manquantes, on retire la colonne sauf si c'est numérique\n",
    "        if missing_percentage > 50:\n",
    "            if df[column].dtype not in ['float64', 'int64']:  # Ne pas supprimer les colonnes numériques\n",
    "                df = df.drop(columns=[column])\n",
    "        else:\n",
    "            # Si la colonne est numérique, on remplace les NaN par la médiane\n",
    "            if df[column].dtype in ['float64', 'int64']:  # vérifier si c'est une colonne numérique\n",
    "                median_value = df[column].median()\n",
    "                df[column].fillna(median_value, inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Cleaning DataFrame for station 41008...\n",
      "Successfully Cleaned DataFrame for Station 41008\n",
      "🔗 Cleaning DataFrame for station 41044...\n",
      "Successfully Cleaned DataFrame for Station 41044\n",
      "🔗 Cleaning DataFrame for station 42001...\n",
      "Successfully Cleaned DataFrame for Station 42001\n",
      "🔗 Cleaning DataFrame for station 42002...\n",
      "Successfully Cleaned DataFrame for Station 42002\n",
      "🔗 Cleaning DataFrame for station 42012...\n",
      "Successfully Cleaned DataFrame for Station 42012\n",
      "🔗 Cleaning DataFrame for station 42036...\n",
      "Successfully Cleaned DataFrame for Station 42036\n",
      "🔗 Cleaning DataFrame for station 42056...\n",
      "Successfully Cleaned DataFrame for Station 42056\n",
      "🔗 Cleaning DataFrame for station 42058...\n",
      "Successfully Cleaned DataFrame for Station 42058\n",
      "🔗 Cleaning DataFrame for station 44020...\n",
      "Successfully Cleaned DataFrame for Station 44020\n",
      "🔗 Cleaning DataFrame for station 44025...\n",
      "Successfully Cleaned DataFrame for Station 44025\n",
      "🔗 Cleaning DataFrame for station 44027...\n",
      "Successfully Cleaned DataFrame for Station 44027\n",
      "🔗 Cleaning DataFrame for station 44065...\n",
      "Successfully Cleaned DataFrame for Station 44065\n",
      "🔗 Cleaning DataFrame for station 46001...\n",
      "Successfully Cleaned DataFrame for Station 46001\n",
      "🔗 Cleaning DataFrame for station 46006...\n",
      "Successfully Cleaned DataFrame for Station 46006\n",
      "🔗 Cleaning DataFrame for station 46014...\n",
      "Successfully Cleaned DataFrame for Station 46014\n",
      "🔗 Cleaning DataFrame for station 46022...\n",
      "Successfully Cleaned DataFrame for Station 46022\n",
      "🔗 Cleaning DataFrame for station 46025...\n",
      "Successfully Cleaned DataFrame for Station 46025\n",
      "🔗 Cleaning DataFrame for station 46027...\n",
      "Successfully Cleaned DataFrame for Station 46027\n",
      "🔗 Cleaning DataFrame for station 46029...\n",
      "Successfully Cleaned DataFrame for Station 46029\n",
      "🔗 Cleaning DataFrame for station 46053...\n",
      "Successfully Cleaned DataFrame for Station 46053\n",
      "🔗 Cleaning DataFrame for station 46069...\n",
      "Successfully Cleaned DataFrame for Station 46069\n",
      "🔗 Cleaning DataFrame for station 46071...\n",
      "Successfully Cleaned DataFrame for Station 46071\n",
      "🔗 Cleaning DataFrame for station 46072...\n",
      "Successfully Cleaned DataFrame for Station 46072\n",
      "🔗 Cleaning DataFrame for station 46078...\n",
      "Successfully Cleaned DataFrame for Station 46078\n",
      "🔗 Cleaning DataFrame for station 46084...\n",
      "Successfully Cleaned DataFrame for Station 46084\n",
      "🔗 Cleaning DataFrame for station 46086...\n",
      "Successfully Cleaned DataFrame for Station 46086\n",
      "🔗 Cleaning DataFrame for station 46087...\n",
      "Successfully Cleaned DataFrame for Station 46087\n",
      "🔗 Cleaning DataFrame for station 46088...\n",
      "Successfully Cleaned DataFrame for Station 46088\n",
      "🔗 Cleaning DataFrame for station 51000...\n",
      "Successfully Cleaned DataFrame for Station 51000\n",
      "🔗 Cleaning DataFrame for station 51001...\n",
      "Successfully Cleaned DataFrame for Station 51001\n",
      "🔗 Cleaning DataFrame for station 51002...\n",
      "Successfully Cleaned DataFrame for Station 51002\n",
      "🔗 Cleaning DataFrame for station BURL1...\n",
      "Successfully Cleaned DataFrame for Station BURL1\n",
      "🔗 Cleaning DataFrame for station FFIA2...\n",
      "Successfully Cleaned DataFrame for Station FFIA2\n",
      "🔗 Cleaning DataFrame for station LONF1...\n",
      "Successfully Cleaned DataFrame for Station LONF1\n",
      "🔗 Cleaning DataFrame for station MDRM1...\n",
      "Successfully Cleaned DataFrame for Station MDRM1\n",
      "🔗 Cleaning DataFrame for station MRKA2...\n",
      "Successfully Cleaned DataFrame for Station MRKA2\n",
      "🔗 Cleaning DataFrame for station POTA2...\n",
      "Successfully Cleaned DataFrame for Station POTA2\n",
      "🔗 Cleaning DataFrame for station SANF1...\n",
      "Successfully Cleaned DataFrame for Station SANF1\n",
      "🔗 Cleaning DataFrame for station SBIO1...\n",
      "Successfully Cleaned DataFrame for Station SBIO1\n"
     ]
    }
   ],
   "source": [
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "\n",
    "        print(f\"🔗 Cleaning DataFrame for station {station_id}...\")\n",
    "        df_converted = tables[\"Converted DataFrame\"]\n",
    "        \n",
    "        df_cleaned = clean_dataframe(df_converted)\n",
    "\n",
    "        tables[\"Cleaned DataFrame\"] = df_cleaned\n",
    "\n",
    "        print(f\"Successfully Cleaned DataFrame for Station {station_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error Cleaning DataFrame for station {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating All in One Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔀 Merging all DataFrames into a final DataFrame...\n",
      "\n",
      "⭐🏆 Processing complete!\n",
      "🔢 Total stations processed: 39\n",
      "📝 Final merged DataFrame size: (252711, 34)\n"
     ]
    }
   ],
   "source": [
    "# Fusion finale de tous les DataFrames\n",
    "try:\n",
    "    print(\"🔀 Merging all DataFrames into a final DataFrame...\")\n",
    "    dataframes_to_concat = [tables[\"Cleaned DataFrame\"] for tables in buoys_datas.values()]\n",
    "\n",
    "    df_final = pd.concat(dataframes_to_concat, ignore_index=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during final merge: {e}\")\n",
    "    df_final = None\n",
    "\n",
    "# Résumé final\n",
    "print(\"\\n⭐🏆 Processing complete!\")\n",
    "print(f\"🔢 Total stations processed: {len(buoys_datas)}\")\n",
    "\n",
    "if df_final is not None and not df_final.empty:\n",
    "    print(f\"📝 Final merged DataFrame size: {df_final.shape}\")\n",
    "else:\n",
    "    print(\"The DataFrame is either None or empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_x                                  Float64\n",
       "Wind Direction (°)                    Float64\n",
       "Wind Speed (km/h)                     Float64\n",
       "Wind Gusts (km/h)                     Float64\n",
       "Wave Height (m)                       Float64\n",
       "Average Wave Period (s)               Float64\n",
       "Dominant Wave Direction (°)           Float64\n",
       "Pressure (hPA)                        Float64\n",
       "Air T°                                Float64\n",
       "Water T°                              Float64\n",
       "dewpoint                              Float64\n",
       "Datetime                       datetime64[ns]\n",
       "Station ID                             object\n",
       "Lat                                    object\n",
       "Lon                                    object\n",
       "id_y                                  Float64\n",
       "T°(C°)                                Float64\n",
       "Relative Humidity (%)                 Float64\n",
       "Dew Point (°C)                        Float64\n",
       "Precipitation (mm)                    Float64\n",
       "rain                                  Float64\n",
       "showers                               Float64\n",
       " Sea Level Pressure (hPa)             Float64\n",
       "surface_pressure                      Float64\n",
       "cloud_cover                           Float64\n",
       "Low Clouds (%)                        Float64\n",
       "Middle Clouds (%)                     Float64\n",
       "High Clouds (%)                       Float64\n",
       " Visibility (km)_y                    Float64\n",
       "wind_speed_10m                        Float64\n",
       "soil_temperature_0cm                  Float64\n",
       "soil_moisture_0_to_1cm                Float64\n",
       "is_day                                Float64\n",
       "3hr_pressure_tendency                 Float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in Conversion Step 1 for column: Station ID:\n",
      "Unable to parse string \"BURL1\" at position 227260\n",
      "id_x                           1.0  (Float64)\n",
      "Wind Direction (°)             240.0  (Float64)\n",
      "Wind Speed (km/h)              5.0  (Float64)\n",
      "Wind Gusts (km/h)              6.0  (Float64)\n",
      "Wave Height (m)                0.7  (Float64)\n",
      "Average Wave Period (s)        3.7  (Float64)\n",
      "Dominant Wave Direction (°)    218.0  (Float64)\n",
      "Pressure (hPA)                 1020.3  (Float64)\n",
      "Air T°                         14.1  (Float64)\n",
      "Water T°                       15.3  (Float64)\n",
      "dewpoint                       10.4  (Float64)\n",
      "Datetime                       2025-03-22 11:00:00  (datetime64[ns])\n",
      "Station ID                     41008.0  (object)\n",
      "Lat                            31.40N  (object)\n",
      "Lon                            80.87W  (object)\n",
      "id_y                           2220.0  (Float64)\n",
      "T°(C°)                         5.110000133514404  (Float64)\n",
      "Relative Humidity (%)          56.0  (Float64)\n",
      "Dew Point (°C)                 -2.9600000381469727  (Float64)\n",
      "Precipitation (mm)             0.0  (Float64)\n",
      "rain                           0.0  (Float64)\n",
      "showers                        0.0  (Float64)\n",
      " Sea Level Pressure (hPa)      1003.7000122070312  (Float64)\n",
      "surface_pressure               979.2899780273438  (Float64)\n",
      "cloud_cover                    0.0  (Float64)\n",
      "Low Clouds (%)                 0.0  (Float64)\n",
      "Middle Clouds (%)              0.0  (Float64)\n",
      "High Clouds (%)                0.0  (Float64)\n",
      " Visibility (km)_y             34300.0  (Float64)\n",
      "wind_speed_10m                 22.06999969482422  (Float64)\n",
      "soil_temperature_0cm           6.739999771118164  (Float64)\n",
      "soil_moisture_0_to_1cm         0.2800000011920929  (Float64)\n",
      "is_day                         0.0  (Float64)\n",
      "3hr_pressure_tendency          <NA>  (Float64)\n"
     ]
    }
   ],
   "source": [
    "# Parcourir toutes les colonnes contenant \"Station ID\" dans leur nom\n",
    "for column in df_final.columns:\n",
    "    if \"Station ID\" in column:\n",
    "        try:\n",
    "            # Tenter de convertir la colonne en numérique (en utilisant pd.to_numeric avec errors='coerce')\n",
    "            df_final[column] = pd.to_numeric(df_final[column], errors='raise')\n",
    "             # Si la conversion est réussie, convertir en int\n",
    "            df_final[column] = df_final[column].astype(int) \n",
    "\n",
    "        except Exception as e:\n",
    "                print(f\"Error in Conversion Step 1 for column: {column}:\\n{e}\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            df_final[column] = df_final[column].astype(str)\n",
    "\n",
    "        except Exception as e:\n",
    "                print(f\"Error in Conversion Step 2 for column: {column}:\\n{e}\")\n",
    "            \n",
    "\n",
    "show_first_row(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160309, 30)\n",
      "\n",
      "id_x                         0\n",
      "Wind Direction (°)           0\n",
      "Wind Speed (km/h)            0\n",
      "Wind Gusts (km/h)            0\n",
      "Pressure (hPA)               0\n",
      "Air T°                       0\n",
      "Water T°                     0\n",
      "dewpoint                     0\n",
      "Datetime                     0\n",
      "Station ID                   0\n",
      "Lat                          0\n",
      "Lon                          0\n",
      "id_y                         0\n",
      "T°(C°)                       0\n",
      "Relative Humidity (%)        0\n",
      "Dew Point (°C)               0\n",
      "Precipitation (mm)           0\n",
      "rain                         0\n",
      "showers                      0\n",
      " Sea Level Pressure (hPa)    0\n",
      "surface_pressure             0\n",
      "cloud_cover                  0\n",
      "Low Clouds (%)               0\n",
      "Middle Clouds (%)            0\n",
      "High Clouds (%)              0\n",
      " Visibility (km)_y           0\n",
      "wind_speed_10m               0\n",
      "soil_temperature_0cm         0\n",
      "soil_moisture_0_to_1cm       0\n",
      "is_day                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_final = clean_dataframe(df_final)\n",
    "df_final.isnull().sum()\n",
    "df_final2 = df_final.dropna()\n",
    "print(f'{df_final2.shape}\\n\\n{df_final2.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\functions.py:747: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns=existing_columns, inplace=True)\n",
      "C:\\Users\\f.gionnane\\AppData\\Local\\Temp\\ipykernel_11488\\1183428151.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final2['Visibility (km)'] = df_final2['Visibility (km)']/1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_to_rename={'temperature_2m': 'T°(C°)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (°C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (km)',  'wind_direction': 'Wind Direction (°)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (°)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air T°','water_temperature': 'Water T°'}\n",
    "\n",
    "meteo_cols_to_delete = ['soil_temperature_0cm','rain', 'showers', 'id_x','id_y' 'is_day',\n",
    "                  'soil_moisture_0_to_1cm']\n",
    "\n",
    "\n",
    "df_final2 = rename_columns(df_final2,{' Visibility (km)_y':'Visibility (km)'})\n",
    "\n",
    "df_final2['Visibility (km)'] = df_final2['Visibility (km)']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_x                           1.0  (Float64)\n",
      "Wind Direction (°)             240.0  (Float64)\n",
      "Wind Speed (km/h)              5.0  (Float64)\n",
      "Wind Gusts (km/h)              6.0  (Float64)\n",
      "Pressure (hPA)                 1020.3  (Float64)\n",
      "Air T°                         14.1  (Float64)\n",
      "Water T°                       15.3  (Float64)\n",
      "dewpoint                       10.4  (Float64)\n",
      "Datetime                       2025-03-22 11:00:00  (datetime64[ns])\n",
      "Station ID                     41008.0  (object)\n",
      "Lat                            31.40N  (object)\n",
      "Lon                            80.87W  (object)\n",
      "id_y                           2220.0  (Float64)\n",
      "T°(C°)                         5.11  (Float64)\n",
      "Relative Humidity (%)          56.0  (Float64)\n",
      "Dew Point (°C)                 -2.96  (Float64)\n",
      "Precipitation (mm)             0.0  (Float64)\n",
      "rain                           0.0  (Float64)\n",
      "showers                        0.0  (Float64)\n",
      " Sea Level Pressure (hPa)      1003.7  (Float64)\n",
      "surface_pressure               979.29  (Float64)\n",
      "cloud_cover                    0.0  (Float64)\n",
      "Low Clouds (%)                 0.0  (Float64)\n",
      "Middle Clouds (%)              0.0  (Float64)\n",
      "High Clouds (%)                0.0  (Float64)\n",
      "Visibility (km)                34.3  (Float64)\n",
      "wind_speed_10m                 22.07  (Float64)\n",
      "soil_temperature_0cm           6.74  (Float64)\n",
      "soil_moisture_0_to_1cm         0.28  (Float64)\n",
      "is_day                         0.0  (Float64)\n"
     ]
    }
   ],
   "source": [
    "df_final2 = df_final2.round(2)\n",
    "show_first_row(df_final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2[['Daytime', 'Month']] = df_final2['Datetime'].apply(lambda x: get_day_time(x)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_x                           1.0  (Float64)\n",
      "Wind Direction (°)             240.0  (Float64)\n",
      "Wind Speed (km/h)              5.0  (Float64)\n",
      "Wind Gusts (km/h)              6.0  (Float64)\n",
      "Pressure (hPA)                 1020.3  (Float64)\n",
      "Air T°                         14.1  (Float64)\n",
      "Water T°                       15.3  (Float64)\n",
      "dewpoint                       10.4  (Float64)\n",
      "Datetime                       2025-03-22 11:00:00  (datetime64[ns])\n",
      "Station ID                     41008.0  (object)\n",
      "Lat                            31.40N  (object)\n",
      "Lon                            80.87W  (object)\n",
      "id_y                           2220.0  (Float64)\n",
      "T°(C°)                         5.11  (Float64)\n",
      "Relative Humidity (%)          56.0  (Float64)\n",
      "Dew Point (°C)                 -2.96  (Float64)\n",
      "Precipitation (mm)             0.0  (Float64)\n",
      "rain                           0.0  (Float64)\n",
      "showers                        0.0  (Float64)\n",
      " Sea Level Pressure (hPa)      1003.7  (Float64)\n",
      "surface_pressure               979.29  (Float64)\n",
      "cloud_cover                    0.0  (Float64)\n",
      "Low Clouds (%)                 0.0  (Float64)\n",
      "Middle Clouds (%)              0.0  (Float64)\n",
      "High Clouds (%)                0.0  (Float64)\n",
      "Visibility (km)                34.3  (Float64)\n",
      "wind_speed_10m                 22.07  (Float64)\n",
      "soil_temperature_0cm           6.74  (Float64)\n",
      "soil_moisture_0_to_1cm         0.28  (Float64)\n",
      "is_day                         0.0  (Float64)\n",
      "Daytime                        Morning  (object)\n",
      "Month                          3  (int64)\n"
     ]
    }
   ],
   "source": [
    "df_final2=df_final2.round(2)\n",
    "show_first_row(df_final2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming, Dropping Useless Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_x                           1.0  (Float64)\n",
      "Wind Direction (°)             240.0  (Float64)\n",
      "Wind Speed (km/h)              5.0  (Float64)\n",
      "Wind Gusts (km/h)              6.0  (Float64)\n",
      "Pressure (hPA)                 1020.3  (Float64)\n",
      "Air T°                         14.1  (Float64)\n",
      "Water T°                       15.3  (Float64)\n",
      "dewpoint                       10.4  (Float64)\n",
      "Datetime                       2025-03-22 11:00:00  (datetime64[ns])\n",
      "Station ID                     41008.0  (object)\n",
      "Lat                            31.40N  (object)\n",
      "Lon                            80.87W  (object)\n",
      "id_y                           2220.0  (Float64)\n",
      "T°(C°)                         5.11  (Float64)\n",
      "Relative Humidity (%)          56.0  (Float64)\n",
      "Dew Point (°C)                 -2.96  (Float64)\n",
      "Precipitation (mm)             0.0  (Float64)\n",
      "rain                           0.0  (Float64)\n",
      "showers                        0.0  (Float64)\n",
      " Sea Level Pressure (hPa)      1003.7  (Float64)\n",
      "surface_pressure               979.29  (Float64)\n",
      "cloud_cover                    0.0  (Float64)\n",
      "Low Clouds (%)                 0.0  (Float64)\n",
      "Middle Clouds (%)              0.0  (Float64)\n",
      "High Clouds (%)                0.0  (Float64)\n",
      "Visibility (km)                34.3  (Float64)\n",
      "wind_speed_10m                 22.07  (Float64)\n",
      "soil_temperature_0cm           6.74  (Float64)\n",
      "soil_moisture_0_to_1cm         0.28  (Float64)\n",
      "is_day                         0.0  (Float64)\n",
      "Daytime                        Morning  (object)\n",
      "Month                          3  (int64)\n"
     ]
    }
   ],
   "source": [
    "show_first_row(df_final2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Envoi Vers PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Silver_Table' does not exist. Creating...\n",
      "Table 'Silver_Table' created in schema 'Silver'.\n",
      "Error retrieving existing values: This Connection is closed\n",
      "An error occurred: This Connection is closed\n"
     ]
    }
   ],
   "source": [
    "load_data_in_table(engine=engine, schema = schema_silver, table_name='Silver_Table', df=df_final2, key_column='Datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_x                                Float64\n",
       "Wind Direction (°)                  Float64\n",
       "Wind Speed (km/h)                   Float64\n",
       "Wind Gusts (km/h)                   Float64\n",
       "Pressure (hPA)                      Float64\n",
       "Air T°                              Float64\n",
       "Water T°                            Float64\n",
       "dewpoint                            Float64\n",
       "Datetime                     datetime64[ns]\n",
       "Station ID                           object\n",
       "Lat                                  object\n",
       "Lon                                  object\n",
       "id_y                                Float64\n",
       "T°(C°)                              Float64\n",
       "Relative Humidity (%)               Float64\n",
       "Dew Point (°C)                      Float64\n",
       "Precipitation (mm)                  Float64\n",
       "rain                                Float64\n",
       "showers                             Float64\n",
       " Sea Level Pressure (hPa)           Float64\n",
       "surface_pressure                    Float64\n",
       "cloud_cover                         Float64\n",
       "Low Clouds (%)                      Float64\n",
       "Middle Clouds (%)                   Float64\n",
       "High Clouds (%)                     Float64\n",
       "Visibility (km)                     Float64\n",
       "wind_speed_10m                      Float64\n",
       "soil_temperature_0cm                Float64\n",
       "soil_moisture_0_to_1cm              Float64\n",
       "is_day                              Float64\n",
       "Daytime                              object\n",
       "Month                                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>Wind Direction (°)</th>\n",
       "      <th>Wind Speed (km/h)</th>\n",
       "      <th>Wind Gusts (km/h)</th>\n",
       "      <th>Pressure (hPA)</th>\n",
       "      <th>Air T°</th>\n",
       "      <th>Water T°</th>\n",
       "      <th>dewpoint</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Station ID</th>\n",
       "      <th>...</th>\n",
       "      <th>Low Clouds (%)</th>\n",
       "      <th>Middle Clouds (%)</th>\n",
       "      <th>High Clouds (%)</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>soil_temperature_0cm</th>\n",
       "      <th>soil_moisture_0_to_1cm</th>\n",
       "      <th>is_day</th>\n",
       "      <th>Daytime</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_x, Wind Direction (°), Wind Speed (km/h), Wind Gusts (km/h), Pressure (hPA), Air T°, Water T°, dewpoint, Datetime, Station ID, Lat, Lon, id_y, T°(C°), Relative Humidity (%), Dew Point (°C), Precipitation (mm), rain, showers,  Sea Level Pressure (hPa), surface_pressure, cloud_cover, Low Clouds (%), Middle Clouds (%), High Clouds (%), Visibility (km), wind_speed_10m, soil_temperature_0cm, soil_moisture_0_to_1cm, is_day, Daytime, Month]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrer le dataframe pour la Station ID 42058\n",
    "df_42058 = df_final2[df_final2[\"Station ID\"] == 42058]\n",
    "df_42058.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# # Variables de contrôle des appels API\n",
    "# vc_api_key_path = r\"c:\\Credentials\\visual_crossing_weather_api.json\"\n",
    "# with open(vc_api_key_path, 'r') as file:\n",
    "#     content = json.load(file)\n",
    "#     vc_api_key = content[\"api_key\"]\n",
    "\n",
    "# # Ajouter un index numérique automatique (0, 1, 2, ...)\n",
    "# df_42058.index = range(len(df_42058))\n",
    "\n",
    "# # Assurez-vous que lat et lon sont définis\n",
    "# lat, lon = None, None\n",
    "\n",
    "# # Si le DataFrame n'est pas vide, récupérer les coordonnées de la première ligne\n",
    "# if not df_42058.empty:\n",
    "#     first_row = df_42058.iloc[0]\n",
    "#     lat = first_row[\"Lat\"]\n",
    "#     lon = first_row[\"Lon\"]\n",
    "\n",
    "#     # Convertir les coordonnées (si nécessaire)\n",
    "#     lat, lon = convert_coordinates(lat, lon)\n",
    "\n",
    "# print(f'{lat}\\n{lon}\\n{vc_api_key}')\n",
    "\n",
    "# # Définition des dates dynamiques\n",
    "# today = datetime.now().strftime(\"%Y-%m-%d\")  # Aujourd'hui\n",
    "# last_month = (datetime.now() - timedelta(days=31)).strftime(\"%Y-%m-%d\")  # 31 jours avant aujourd'hui\n",
    "\n",
    "# # Vérifier si lat et lon ont été correctement définis avant de continuer\n",
    "# if lat is not None and lon is not None:\n",
    "#     # Construction de l'URL\n",
    "#     url_last_month = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{lat},{lon}/{last_month}/{today}?unitGroup=metric&key={vc_api_key}&contentType=json\"\n",
    "    \n",
    "#     # Tentative de récupération des données météo\n",
    "#     try:\n",
    "#         response = requests.get(url_last_month)\n",
    "        \n",
    "#         # Vérifier si la requête a réussi (code 200)\n",
    "#         if response.status_code == 200:\n",
    "#             vc_meteo_data = response.json()  # Essayer de décoder le JSON\n",
    "#             print(f\"Données météo récupérées : {vc_meteo_data}\")\n",
    "#         else:\n",
    "#             print(f\"Erreur lors de l'appel à l'API, code de statut : {response.status_code}\")\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"Erreur lors de la récupération des données météo : {e}\")\n",
    "# else:\n",
    "#     print(\"Les coordonnées (lat, lon) ne sont pas définies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming the df_cleaned DataFrame already exists and contains the required data\n",
    "\n",
    "# # First, load your Visual Crossing Weather Data (example, you may already have it)\n",
    "# # Assuming vc_meteo_data is the JSON response from Visual Crossing\n",
    "# # Example of flattening the JSON\n",
    "# df_vc_meteo = pd.json_normalize(vc_meteo_data, record_path=[\"days\", \"hours\"], meta=[\"days\"])\n",
    "\n",
    "# # Convert the datetimeEpoch from Visual Crossing Weather data into Date and Hour columns\n",
    "# df_vc_meteo[\"Date\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%Y-%m-%d\")\n",
    "# df_vc_meteo[\"Hour\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%H\")\n",
    "\n",
    "# # Filter data from df_vc_meteo for the last 30 days\n",
    "# today = datetime.now()\n",
    "# thirty_days_ago = today - timedelta(days=30)\n",
    "\n",
    "# today_str = today.strftime(\"%Y-%m-%d\")\n",
    "# thirty_days_ago_str = thirty_days_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# # Filter df_vc_meteo for the last 30 days\n",
    "# df_test_last_month = df_vc_meteo[['Date', 'Hour', 'windspeed']]\n",
    "# df_test_last_month = df_test_last_month[(df_test_last_month['Date'] >= thirty_days_ago_str) & \n",
    "#                                         (df_test_last_month['Date'] <= today_str)]\n",
    "\n",
    "# # Prepare df_cleaned for merging (add Date and Hour columns)\n",
    "# df_cleaned['Date'] = df_cleaned['Datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "# df_cleaned['Hour'] = df_cleaned['Datetime'].dt.strftime(\"%H\")\n",
    "\n",
    "# # Filter df_cleaned for the last 30 days\n",
    "# df_cleaned_last_month = df_cleaned[(df_cleaned['Date'] >= thirty_days_ago_str) & \n",
    "#                                    (df_cleaned['Date'] <= today_str)]\n",
    "\n",
    "# # Merge df_vc_meteo and df_cleaned based on Date and Hour\n",
    "# df_merged = df_test_last_month.merge(df_cleaned_last_month[['Date', 'Hour', 'Wind Speed (km/h)', 'wind_speed_10m']], \n",
    "#                                     on=['Date', 'Hour'], \n",
    "#                                     how='inner')\n",
    "\n",
    "# # Display the merged dataframe\n",
    "# print(df_merged.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Aucune colonne à renommer pour ce spécification : {'temperature_2m': 'T°(C°)', 'relative_humidity_2m': 'Relative Humidity (%)', 'dew_point_2m': 'Dew Point (°C)', 'precipitation': 'Precipitation (mm)', 'pressure_msl': ' Sea Level Pressure (hPa)', 'cloud_cover_low': 'Low Clouds (%)', 'cloud_cover_mid': 'Middle Clouds (%)', 'cloud_cover_high': 'High Clouds (%)', 'visibility': ' Visibility (%)', 'wind_direction': 'Wind Direction (°)', 'wind_speed': 'Wind Speed (km/h)', 'wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)', 'average_wave_period': 'Average Wave Period (s)', 'dominant_wave_direction': 'Dominant Wave Direction (°)', 'pressure': 'Pressure (hPA)', 'air_temperature': 'Air T°', 'water_temperature': 'Water T°'}\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'id_x' Supprimée\n",
      "Colonne 'id_y' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Wind Direction (°)', 'Wind Speed (km/h)', 'Wind Gusts (km/h)',\n",
       "       'Pressure (hPA)', 'Air T°', '3hr_pressure_tendency', 'Datetime',\n",
       "       'Station ID', 'Lat', 'Lon', 'T°(C°)', 'Relative Humidity (%)',\n",
       "       'Dew Point (°C)', 'Precipitation (mm)', ' Sea Level Pressure (hPa)',\n",
       "       'surface_pressure', 'cloud_cover', 'Low Clouds (%)',\n",
       "       'Middle Clouds (%)', 'High Clouds (%)', ' Visibility (km)_y',\n",
       "       'wind_speed_10m'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_rename={'temperature_2m': 'T°(C°)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (°C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (%)',  'wind_direction': 'Wind Direction (°)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (°)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air T°','water_temperature': 'Water T°'}\n",
    "\n",
    "df_cleaned = rename_columns(df_cleaned, col_to_rename)\n",
    "df_cleaned = drop_columns_if_exist(df_cleaned,['soil_temperature_0cm','rain', 'showers', 'is_day', 'id_x', 'id_y','soil_moisture_0_to_1cm'])\n",
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Récupérer les données de l'API\n",
    "# vc_meteo_data = response.json()\n",
    "# print(vc_meteo_data)  # Vérifiez les données récupérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normaliser les données JSON en DataFrame\n",
    "# df_vc_meteo = pd.json_normalize(vc_meteo_data, record_path=[\"days\", \"hours\"], meta=[\"days\"])\n",
    "\n",
    "# # Afficher la première ligne des données\n",
    "# df_vc_meteo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_vc_meteo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Conversion du timestamp en datetime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df_vc_meteo[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(\u001b[43mdf_vc_meteo\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mdatetimeEpoch\u001b[39m\u001b[33m\"\u001b[39m], unit=\u001b[33m\"\u001b[39m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m).dt.strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m df_vc_meteo[\u001b[33m\"\u001b[39m\u001b[33mHour\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(df_vc_meteo[\u001b[33m\"\u001b[39m\u001b[33mdatetimeEpoch\u001b[39m\u001b[33m\"\u001b[39m], unit=\u001b[33m\"\u001b[39m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m).dt.strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_vc_meteo' is not defined"
     ]
    }
   ],
   "source": [
    "# Conversion du timestamp en datetime\n",
    "df_vc_meteo[\"Date\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%Y-%m-%d\")\n",
    "df_vc_meteo[\"Hour\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les dates de filtrage pour les 30 derniers jours\n",
    "today = datetime.now()\n",
    "thirty_days_ago = today - timedelta(days=30)\n",
    "\n",
    "# Convertir les dates en format YYYY-MM-DD\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "thirty_days_ago_str = thirty_days_ago.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données des 30 derniers jours de df_vc_meteo\n",
    "df_test_last_month = df_vc_meteo[['Date', 'Hour', 'windspeed']]\n",
    "df_test_last_month = df_test_last_month[(df_test_last_month['Date'] >= thirty_days_ago_str) & \n",
    "                                        (df_test_last_month['Date'] <= today_str)]\n",
    "\n",
    "# Ajouter les colonnes Date et Hour à df_42058\n",
    "df_42058.loc[:, 'Date'] = df_42058['Datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "df_42058.loc[:, 'Hour'] = df_42058['Datetime'].dt.strftime(\"%H\")\n",
    "\n",
    "# Filtrer les données des 30 derniers jours dans df_42058\n",
    "df_42058_last_month = df_42058[(df_42058['Date'] >= thirty_days_ago_str) & \n",
    "                                (df_42058['Date'] <= today_str)]\n",
    "\n",
    "# Fusionner les deux DataFrames sur Date et Hour\n",
    "df_test_merged = df_test_last_month.merge(df_42058_last_month[['Date', 'Hour', 'Wind Speed (km/h)', 'wind_speed_10m']], \n",
    "                                     on=['Date', 'Hour'], \n",
    "                                     how='inner')\n",
    "\n",
    "df_test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def handle_null_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     row_count = df.shape[0]\n",
    "    \n",
    "#     # Initialisation des listes pour suivre les colonnes supprimées\n",
    "#     removed_columns = []\n",
    "#     non_numeric_columns_to_drop = []\n",
    "    \n",
    "#     # Utiliser lambda et apply() pour calculer le nombre de valeurs nulles dans chaque colonne\n",
    "#     null_counts = df.apply(lambda col: int(col.isnull().sum()))  # Calculer le nombre de NaN par colonne\n",
    "    \n",
    "#     # Condition : 1. Colonnes avec toutes les valeurs nulles ou 2. Plus de 50% de valeurs nulles et colonne non numérique\n",
    "#     columns_to_drop = null_counts[\n",
    "#         (null_counts == row_count) | \n",
    "#         ((null_counts > row_count * 0.5) & ~df.apply(lambda col: pd.api.types.is_numeric_dtype(col)))\n",
    "#     ].index\n",
    "    \n",
    "#     # Ajouter les noms des colonnes supprimées dans les listes appropriées\n",
    "#     for col in columns_to_drop:\n",
    "#         if null_counts[col] == row_count:\n",
    "#             removed_columns.append(col)  # Colonnes entièrement vides\n",
    "#         elif null_counts[col] > row_count * 0.5 and not pd.api.types.is_numeric_dtype(df[col]):\n",
    "#             non_numeric_columns_to_drop.append(col)  # Colonnes > 50% nulles et non numériques\n",
    "    \n",
    "#     # Supprimer les colonnes identifiées\n",
    "#     df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "#     # Afficher les résultats\n",
    "#     print(\"Colonnes supprimées pour avoir toutes les valeurs nulles:\")\n",
    "#     print(removed_columns)\n",
    "    \n",
    "#     print(\"\\nColonnes supprimées pour avoir plus de 50% de valeurs nulles et être non numériques:\")\n",
    "#     print(non_numeric_columns_to_drop)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# # df_final = pd.read_csv('ton_fichier.csv') # Assure-toi que df_final est bien un DataFrame valide avant d'appeler la fonction\n",
    "# df_final = handle_null_values(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = df_final.round(2)\n",
    "# print(df_final.columns)\n",
    "# df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def explore_dict_keys(d, parent_key='', sep='_'):\n",
    "#     \"\"\"\n",
    "#     Explore un dictionnaire récursivement pour obtenir toutes les clés, y compris les sous-clés,\n",
    "#     mais ne retourne pas les valeurs finales.\n",
    "\n",
    "#     :param d: Le dictionnaire à explorer\n",
    "#     :param parent_key: La clé parent qui est utilisée pour concaténer les sous-clés\n",
    "#     :param sep: Le séparateur utilisé pour concaténer les clés (par défaut '_')\n",
    "#     :return: Une liste des clés (et sous-clés)\n",
    "#     \"\"\"\n",
    "#     keys = []\n",
    "#     for k, v in d.items():\n",
    "#         new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "#         if isinstance(v, dict):  # Si la valeur est un dictionnaire, on explore récursivement\n",
    "#             keys.append(new_key)  # Ajouter la clé, mais ne pas inclure la valeur\n",
    "#             keys.extend(explore_dict_keys(v, new_key, sep=sep))  # Continuer l'exploration\n",
    "#         else:\n",
    "#             keys.append(new_key)  # Ajouter la clé finale\n",
    "#     return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_key_path(d, target_key, path=[]):\n",
    "#     \"\"\"\n",
    "#     Recherche récursive d'une clé dans un dictionnaire et retourne son chemin.\n",
    "#     :param d: dictionnaire\n",
    "#     :param target_key: clé recherchée\n",
    "#     :param path: liste pour stocker le chemin jusqu'à la clé\n",
    "#     :return: chemin sous forme de liste\n",
    "#     \"\"\"\n",
    "#     if isinstance(d, dict):  # Si le dictionnaire est encore imbriqué\n",
    "#         for key, value in d.items():\n",
    "#             new_path = path + [key]\n",
    "#             if key == target_key:\n",
    "#                 return new_path\n",
    "#             elif isinstance(value, dict):\n",
    "#                 result = find_key_path(value, target_key, new_path)\n",
    "#                 if result:  # Si la clé est trouvée, retourner le chemin\n",
    "#                     return result\n",
    "#     return None  # Retourne None si la clé n'a pas été trouvée\n",
    "\n",
    "\n",
    "\n",
    "# # Recherche du chemin pour la clé 'marine_data'\n",
    "# path = find_key_path(table_dict, \"Marine Dataframe\")\n",
    "# print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto_convert Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, (buoy_id, tables) in enumerate(table_dict.items()):  # Utilisation de .items() pour obtenir (clé, valeur)\n",
    "#     if isinstance(tables, dict):\n",
    "#         if idx == 1:  # Vérifier si l'index est égal à 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Rows of all Dataframes in total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
