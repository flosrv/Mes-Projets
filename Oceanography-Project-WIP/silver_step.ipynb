{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_postgresql_creds = r\"C:\\Users\\f.gionnane\\Documents\\Data Engineering\\Credentials\\postgresql_creds.json\"\n",
    "\n",
    "with open(path_postgresql_creds, 'r') as file:\n",
    "    content = json.load(file)\n",
    "    user = content[\"user\"]\n",
    "    password = content[\"password\"]\n",
    "    host = content[\"host\"]\n",
    "    port = content[\"port\"]\n",
    "\n",
    "db = \"Oceanography_ML_Project\"\n",
    "schema_bronze = \"Bronze\"\n",
    "schema_silver = \"Silver\"\n",
    "\n",
    "# Créer l'engine PostgreSQL\n",
    "engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{db}\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les Données des Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Chargement des métadonnées du schéma...\n",
      "✅ Métadonnées chargées avec succès.\n",
      "\n",
      "🔢 Nombre total de tables dans le schéma : 79\n",
      "\n",
      "🌊 Tables marines trouvées : 39\n",
      "🌧️ Tables météo trouvées : 39\n",
      "🐋 Tables de bouées trouvées : 1\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🔄 Chargement des données de la table 'buoys_datas'...\n",
      "📦 Données récupérées pour 'buoys_datas'.\n",
      "✅ Table 'buoys_datas' chargée avec succès! Nombre de bouées (lignes) : 39\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🔄 Chargement des données pour la table Marine : station_42001_marine_mid gulf...\n",
      "📦 Données récupérées pour la station 42001 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42001! Nombre de lignes collectées : 2322\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46088_marine_new dungeness...\n",
      "📦 Données récupérées pour la station 46088 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46088! Nombre de lignes collectées : 7520\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_POTA2_marine_potato point, ak...\n",
      "📦 Données récupérées pour la station POTA2 (Marine).\n",
      "🌊 Données Marine chargées pour la station POTA2! Nombre de lignes collectées : 2511\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_51002_marine_southwest hawaii...\n",
      "📦 Données récupérées pour la station 51002 (Marine).\n",
      "🌊 Données Marine chargées pour la station 51002! Nombre de lignes collectées : 7464\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46086_marine_san clemente basin...\n",
      "📦 Données récupérées pour la station 46086 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46086! Nombre de lignes collectées : 7520\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_SBIO1_marine_south bass island, oh...\n",
      "📦 Données récupérées pour la station SBIO1 (Marine).\n",
      "🌊 Données Marine chargées pour la station SBIO1! Nombre de lignes collectées : 1256\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42056_marine_yucatan basin...\n",
      "📦 Données récupérées pour la station 42056 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42056! Nombre de lignes collectées : 7471\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_41008_marine_grays reef...\n",
      "📦 Données récupérées pour la station 41008 (Marine).\n",
      "🌊 Données Marine chargées pour la station 41008! Nombre de lignes collectées : 7502\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_51001_marine_northwestern hawaii one...\n",
      "📦 Données récupérées pour la station 51001 (Marine).\n",
      "🌊 Données Marine chargées pour la station 51001! Nombre de lignes collectées : 7468\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_SANF1_marine_sand key, fl...\n",
      "📦 Données récupérées pour la station SANF1 (Marine).\n",
      "🌊 Données Marine chargées pour la station SANF1! Nombre de lignes collectées : 7431\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46022_marine_eel river...\n",
      "📦 Données récupérées pour la station 46022 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46022! Nombre de lignes collectées : 7536\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46071_marine_western aleutians...\n",
      "📦 Données récupérées pour la station 46071 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46071! Nombre de lignes collectées : 7472\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_41044_marine_ne st martin...\n",
      "📦 Données récupérées pour la station 41044 (Marine).\n",
      "🌊 Données Marine chargées pour la station 41044! Nombre de lignes collectées : 7465\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46053_marine_east santa barbara...\n",
      "📦 Données récupérées pour la station 46053 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46053! Nombre de lignes collectées : 7519\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46025_marine_santa monica basin...\n",
      "📦 Données récupérées pour la station 46025 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46025! Nombre de lignes collectées : 7515\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42058_marine_central caribbean...\n",
      "📦 Données récupérées pour la station 42058 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42058! Nombre de lignes collectées : 7452\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46029_marine_columbia river bar...\n",
      "📦 Données récupérées pour la station 46029 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46029! Nombre de lignes collectées : 7520\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_LONF1_marine_long key, fl...\n",
      "📦 Données récupérées pour la station LONF1 (Marine).\n",
      "🌊 Données Marine chargées pour la station LONF1! Nombre de lignes collectées : 7392\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46078_marine_albatross bank...\n",
      "📦 Données récupérées pour la station 46078 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46078! Nombre de lignes collectées : 7467\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46027_marine_st georges...\n",
      "📦 Données récupérées pour la station 46027 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46027! Nombre de lignes collectées : 7521\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_FFIA2_marine_five fingers, ak...\n",
      "📦 Données récupérées pour la station FFIA2 (Marine).\n",
      "🌊 Données Marine chargées pour la station FFIA2! Nombre de lignes collectées : 1258\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46087_marine_neah bay...\n",
      "📦 Données récupérées pour la station 46087 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46087! Nombre de lignes collectées : 7526\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_BURL1_marine_southwest pass, la...\n",
      "📦 Données récupérées pour la station BURL1 (Marine).\n",
      "🌊 Données Marine chargées pour la station BURL1! Nombre de lignes collectées : 1255\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44027_marine_jonesport, me...\n",
      "📦 Données récupérées pour la station 44027 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44027! Nombre de lignes collectées : 7470\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46084_marine_cape edgecumbe...\n",
      "📦 Données récupérées pour la station 46084 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46084! Nombre de lignes collectées : 7474\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42036_marine_west tampa...\n",
      "📦 Données récupérées pour la station 42036 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42036! Nombre de lignes collectées : 7443\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44020_marine_nantucket sound...\n",
      "📦 Données récupérées pour la station 44020 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44020! Nombre de lignes collectées : 7476\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46069_marine_south santa rosa...\n",
      "📦 Données récupérées pour la station 46069 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46069! Nombre de lignes collectées : 7494\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44025_marine_long island...\n",
      "📦 Données récupérées pour la station 44025 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44025! Nombre de lignes collectées : 7492\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_51000_marine_northern hawaii one...\n",
      "📦 Données récupérées pour la station 51000 (Marine).\n",
      "🌊 Données Marine chargées pour la station 51000! Nombre de lignes collectées : 7475\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46001_marine_western gulf of alaska...\n",
      "📦 Données récupérées pour la station 46001 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46001! Nombre de lignes collectées : 7465\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46006_marine_southeast papa...\n",
      "📦 Données récupérées pour la station 46006 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46006! Nombre de lignes collectées : 7474\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_MRKA2_marine_middle rock light, ak...\n",
      "📦 Données récupérées pour la station MRKA2 (Marine).\n",
      "🌊 Données Marine chargées pour la station MRKA2! Nombre de lignes collectées : 2512\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46072_marine_central aleutians 230 nm sw dutch harbor...\n",
      "📦 Données récupérées pour la station 46072 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46072! Nombre de lignes collectées : 7476\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42002_marine_west gulf...\n",
      "📦 Données récupérées pour la station 42002 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42002! Nombre de lignes collectées : 2475\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_44065_marine_new york harbor entrance...\n",
      "📦 Données récupérées pour la station 44065 (Marine).\n",
      "🌊 Données Marine chargées pour la station 44065! Nombre de lignes collectées : 7457\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_MDRM1_marine_mt_ desert rock, me...\n",
      "📦 Données récupérées pour la station MDRM1 (Marine).\n",
      "🌊 Données Marine chargées pour la station MDRM1! Nombre de lignes collectées : 1257\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_46014_marine_pt arena...\n",
      "📦 Données récupérées pour la station 46014 (Marine).\n",
      "🌊 Données Marine chargées pour la station 46014! Nombre de lignes collectées : 7523\n",
      "\n",
      "🔄 Chargement des données pour la table Marine : station_42012_marine_orange beach...\n",
      "📦 Données récupérées pour la station 42012 (Marine).\n",
      "🌊 Données Marine chargées pour la station 42012! Nombre de lignes collectées : 7456\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🔄 Chargement des données pour la table Meteo : station_44027_meteo_jonesport, me...\n",
      "📦 Données récupérées pour la station 44027 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44027! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42012_meteo_orange beach...\n",
      "📦 Données récupérées pour la station 42012 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42012! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44025_meteo_long island...\n",
      "📦 Données récupérées pour la station 44025 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44025! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46014_meteo_pt arena...\n",
      "📦 Données récupérées pour la station 46014 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46014! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_MRKA2_meteo_middle rock light, ak...\n",
      "📦 Données récupérées pour la station MRKA2 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station MRKA2! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46022_meteo_eel river...\n",
      "📦 Données récupérées pour la station 46022 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46022! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46006_meteo_southeast papa...\n",
      "📦 Données récupérées pour la station 46006 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46006! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_51001_meteo_northwestern hawaii one...\n",
      "📦 Données récupérées pour la station 51001 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 51001! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46025_meteo_santa monica basin...\n",
      "📦 Données récupérées pour la station 46025 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46025! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44020_meteo_nantucket sound...\n",
      "📦 Données récupérées pour la station 44020 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44020! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_41008_meteo_grays reef...\n",
      "📦 Données récupérées pour la station 41008 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 41008! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42058_meteo_central caribbean...\n",
      "📦 Données récupérées pour la station 42058 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42058! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46071_meteo_western aleutians...\n",
      "📦 Données récupérées pour la station 46071 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46071! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46072_meteo_central aleutians 230 nm sw dutch harbor...\n",
      "📦 Données récupérées pour la station 46072 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46072! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46053_meteo_east santa barbara...\n",
      "📦 Données récupérées pour la station 46053 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46053! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46029_meteo_columbia river bar...\n",
      "📦 Données récupérées pour la station 46029 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46029! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_POTA2_meteo_potato point, ak...\n",
      "📦 Données récupérées pour la station POTA2 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station POTA2! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42036_meteo_west tampa...\n",
      "📦 Données récupérées pour la station 42036 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42036! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46084_meteo_cape edgecumbe...\n",
      "📦 Données récupérées pour la station 46084 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46084! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_FFIA2_meteo_five fingers, ak...\n",
      "📦 Données récupérées pour la station FFIA2 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station FFIA2! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_SBIO1_meteo_south bass island, oh...\n",
      "📦 Données récupérées pour la station SBIO1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station SBIO1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_44065_meteo_new york harbor entrance...\n",
      "📦 Données récupérées pour la station 44065 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 44065! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46027_meteo_st georges...\n",
      "📦 Données récupérées pour la station 46027 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46027! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_51002_meteo_southwest hawaii...\n",
      "📦 Données récupérées pour la station 51002 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 51002! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46088_meteo_new dungeness...\n",
      "📦 Données récupérées pour la station 46088 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46088! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46086_meteo_san clemente basin...\n",
      "📦 Données récupérées pour la station 46086 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46086! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_41044_meteo_ne st martin...\n",
      "📦 Données récupérées pour la station 41044 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 41044! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42002_meteo_west gulf...\n",
      "📦 Données récupérées pour la station 42002 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42002! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42001_meteo_mid gulf...\n",
      "📦 Données récupérées pour la station 42001 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42001! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46069_meteo_south santa rosa...\n",
      "📦 Données récupérées pour la station 46069 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46069! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_42056_meteo_yucatan basin...\n",
      "📦 Données récupérées pour la station 42056 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 42056! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_MDRM1_meteo_mt_ desert rock, me...\n",
      "📦 Données récupérées pour la station MDRM1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station MDRM1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_51000_meteo_northern hawaii one...\n",
      "📦 Données récupérées pour la station 51000 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 51000! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46001_meteo_western gulf of alaska...\n",
      "📦 Données récupérées pour la station 46001 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46001! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46087_meteo_neah bay...\n",
      "📦 Données récupérées pour la station 46087 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46087! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_SANF1_meteo_sand key, fl...\n",
      "📦 Données récupérées pour la station SANF1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station SANF1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_BURL1_meteo_southwest pass, la...\n",
      "📦 Données récupérées pour la station BURL1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station BURL1! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_46078_meteo_albatross bank...\n",
      "📦 Données récupérées pour la station 46078 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station 46078! Nombre de lignes collectées : 2448\n",
      "\n",
      "🔄 Chargement des données pour la table Meteo : station_LONF1_meteo_long key, fl...\n",
      "📦 Données récupérées pour la station LONF1 (Meteo).\n",
      "🌧️ Données Meteo chargées pour la station LONF1! Nombre de lignes collectées : 2448\n",
      "\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
      "🏆 Chargement des données terminé avec succès !\n",
      "🐋 Total des données bouées chargées : 1 - Nombre de bouées (lignes) : 39\n",
      "🌊 Total des données marines chargées : 39 - Nombre total de lignes : 246782\n",
      "🌧️ Total des données météorologiques chargées : 39 - Nombre total de lignes : 95472\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n"
     ]
    }
   ],
   "source": [
    "# Charger les métadonnées du schéma existant\n",
    "metadata = MetaData(schema=schema_bronze)\n",
    "\n",
    "print(\"\\n🔍 Chargement des métadonnées du schéma...\")\n",
    "metadata.reflect(bind=conn)\n",
    "print(\"✅ Métadonnées chargées avec succès.\\n\")\n",
    "\n",
    "# Récupérer les noms des tables\n",
    "table_names = [t.name for t in metadata.sorted_tables]\n",
    "print(f\"🔢 Nombre total de tables dans le schéma : {len(table_names)}\\n\")\n",
    "\n",
    "# Filtrer les tables en fonction du contenu de leur nom\n",
    "marine_tables = {t for t in table_names if \"marine\" in t.lower()}\n",
    "meteo_tables = {t for t in table_names if \"meteo\" in t.lower()}\n",
    "buoys_data_table = {t for t in table_names if \"buoy\" in t.lower()}\n",
    "\n",
    "print(f\"🌊 Tables marines trouvées : {len(marine_tables)}\")\n",
    "print(f\"🌧️ Tables météo trouvées : {len(meteo_tables)}\")\n",
    "print(f\"🐋 Tables de bouées trouvées : {len(buoys_data_table)}\\n\")\n",
    "\n",
    "# Initialiser le dictionnaire des résultats\n",
    "buoys_datas = {}\n",
    "\n",
    "# Compteurs pour suivre le nombre de tables chargées avec succès\n",
    "marine_data_count = 0\n",
    "meteo_data_count = 0\n",
    "buoys_data_count = 0\n",
    "\n",
    "# Compteur pour le nombre total de lignes\n",
    "total_marine_rows = 0\n",
    "total_meteo_rows = 0\n",
    "total_buoys_rows = 0  # Changer ici pour compter le nombre de lignes (bouées)\n",
    "\n",
    "# Vérifier et récupérer les données de la table \"buoys_datas\"\n",
    "if buoys_data_table:\n",
    "    print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "    print(\"🔄 Chargement des données de la table 'buoys_datas'...\")\n",
    "\n",
    "    try:\n",
    "        buoys_datas_raw = fetch_table_data(schema=schema_bronze, conn=conn, table_name=next(iter(buoys_data_table)), as_df=True)\n",
    "\n",
    "        if buoys_datas_raw is not None:\n",
    "            print(\"📦 Données récupérées pour 'buoys_datas'.\")\n",
    "\n",
    "            # Conversion JSON → dict si nécessaire\n",
    "            if isinstance(buoys_datas_raw, str):\n",
    "                buoys_datas_raw = json.loads(buoys_datas_raw)\n",
    "\n",
    "            elif isinstance(buoys_datas_raw, pd.DataFrame) and \"Station ID\" in buoys_datas_raw.columns:\n",
    "                # Convertir en dictionnaire avec \"Station ID\" comme clé\n",
    "                buoys_datas_raw = buoys_datas_raw.set_index(\"Station ID\").to_dict(orient=\"index\")\n",
    "\n",
    "            # Ajouter au dictionnaire principal directement avec les Station ID comme clés\n",
    "            buoys_datas.update(buoys_datas_raw)\n",
    "            buoys_data_count += 1\n",
    "            total_buoys_rows += len(buoys_datas_raw)  # Compter le nombre de bouées\n",
    "            print(f\"✅ Table 'buoys_datas' chargée avec succès! Nombre de bouées (lignes) : {total_buoys_rows}\\n\")\n",
    "        else:\n",
    "            print(\"⚠️ Aucun résultat trouvé dans 'buoys_datas'.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du chargement de 'buoys_datas': {e}\\n\")\n",
    "\n",
    "# Associer les tables marine et meteo en fonction du station_id et récupérer leurs données\n",
    "for table_set, label, icon, counter, total_rows in [\n",
    "    (marine_tables, \"Marine\", \"🌊\", marine_data_count, total_marine_rows),\n",
    "    (meteo_tables, \"Meteo\", \"🌧️\", meteo_data_count, total_meteo_rows)\n",
    "]:\n",
    "    print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "    for table_name in table_set:\n",
    "        print(f\"🔄 Chargement des données pour la table {label} : {table_name}...\")\n",
    "\n",
    "        try:\n",
    "            station_id = table_name.split(\"_\")[1]\n",
    "\n",
    "            # Vérifier si la station existe déjà dans buoys_datas, sinon initialiser un dictionnaire\n",
    "            if station_id not in buoys_datas:\n",
    "                buoys_datas[station_id] = {}\n",
    "\n",
    "            # Récupérer les données\n",
    "            data = fetch_table_data(schema=schema_bronze, conn=conn, table_name=table_name, as_df=True)\n",
    "\n",
    "            if data is not None:\n",
    "                print(f\"📦 Données récupérées pour la station {station_id} ({label}).\")\n",
    "\n",
    "                if isinstance(data, str):\n",
    "                    data = pd.DataFrame(json.loads(data))\n",
    "                elif isinstance(data, dict):\n",
    "                    data = pd.DataFrame(data)\n",
    "                # Ajouter les données au dictionnaire de bouées sous la station_id\n",
    "                buoys_datas[station_id][f\"{label} DataFrame\"] = data\n",
    "                counter += 1\n",
    "                total_rows += len(data)  # Ajouter le nombre de lignes collectées\n",
    "                print(f\"{icon} Données {label} chargées pour la station {station_id}! Nombre de lignes collectées : {len(data)}\\n\")\n",
    "            else:\n",
    "                print(f\"⚠️ Aucun résultat trouvé pour la station {station_id} ({label}).\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lors du chargement des données {label} pour {table_name} : {e}\\n\")\n",
    "\n",
    "    # Mise à jour des compteurs après le chargement des données pour chaque catégorie\n",
    "    if label == \"Marine\":\n",
    "        marine_data_count = counter\n",
    "        total_marine_rows = total_rows\n",
    "    elif label == \"Meteo\":\n",
    "        meteo_data_count = counter\n",
    "        total_meteo_rows = total_rows\n",
    "\n",
    "# Finalement, afficher un récapitulatif global\n",
    "print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n",
    "print(f\"🏆 Chargement des données terminé avec succès !\")\n",
    "print(f\"🐋 Total des données bouées chargées : {buoys_data_count} - Nombre de bouées (lignes) : {total_buoys_rows}\")\n",
    "print(f\"🌊 Total des données marines chargées : {marine_data_count} - Nombre total de lignes : {total_marine_rows}\")\n",
    "print(f\"🌧️ Total des données météorologiques chargées : {meteo_data_count} - Nombre total de lignes : {total_meteo_rows}\")\n",
    "print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoys_datas[\"42058\"][\"Marine DataFrame\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoys_datas[\"42058\"][\"Meteo DataFrame\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_silver_merged_df = []  \n",
    "list_failed_dfs = []        \n",
    "\n",
    "number_marine_data = 0\n",
    "number_meteo_data = 0\n",
    "number_merged_data = 0\n",
    "\n",
    "marine_data_conversion = 0\n",
    "meteo_data_conversion = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n",
      "Colonne 'soil_temperature_0cm' Supprimée\n",
      "Colonne 'rain' Supprimée\n",
      "Colonne 'showers' Supprimée\n",
      "Colonne 'is_day' Supprimée\n",
      "Colonne 'soil_moisture_0_to_1cm' Supprimée\n"
     ]
    }
   ],
   "source": [
    "marine_cols = [\n",
    "    \"wind_direction\", \"wind_speed\", \"wind_gust\", \"wave_height\",\n",
    "    \"dominant_wave_period\", \"average_wave_period\", \"dominant_wave_direction\",\n",
    "    \"pressure\", \"air_temperature\", \"water_temperature\", \"dewpoint\",\n",
    "    \"visibility\", \"3hr_pressure_tendency\", \"water_level_above_mean\"\n",
    "]\n",
    "\n",
    "meteo_cols = [\n",
    "    \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"precipitation\", \"rain\",\n",
    "    \"showers\", \"pressure_msl\", \"surface_pressure\", \"cloud_cover\", \"cloud_cover_low\",\n",
    "    \"cloud_cover_mid\", \"cloud_cover_high\", \"visibility\", \"wind_speed_10m\",\n",
    "    \"soil_temperature_0cm\", \"soil_moisture_0_to_1cm\"\n",
    "]\n",
    "\n",
    "col_to_rename={'temperature_2m': 'T°(C°)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (°C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (%)',  'wind_direction': 'Wind Direction (°)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (°)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air T°','water_temperature': 'Water T°'}\n",
    "\n",
    "meteo_cols_to_delete = ['soil_temperature_0cm','rain', 'showers', 'is_day',\n",
    "                  'soil_moisture_0_to_1cm']\n",
    "\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    marine_df = tables[\"Marine DataFrame\"]\n",
    "    marine_df = rename_columns(marine_df, col_to_rename)\n",
    "\n",
    "    marine_df = drop_columns_if_exist\n",
    "\n",
    "    meteo_df = tables[\"Meteo DataFrame\"]\n",
    "    meteo_df = rename_columns(meteo_df,col_to_rename)\n",
    "    meteo_df = drop_columns_if_exist(meteo_df, meteo_cols_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOUR RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Processing and resampling marine data for station 41008...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 41008...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 41044...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 41044...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42001...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42001...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42002...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42002...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42012...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42012...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42036...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42036...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42056...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42056...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 42058...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 42058...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 44020...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 44020...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 44025...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 44025...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 44027...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 44027...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 44065...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 44065...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46001...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46001...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46006...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46006...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46014...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46014...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46022...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46022...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46025...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46025...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46027...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46027...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46029...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46029...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46053...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46053...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46069...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46069...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46071...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46071...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46072...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46072...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46078...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46078...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46084...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46084...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46086...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46086...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46087...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46087...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 46088...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 46088...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 51000...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 51000...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 51001...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 51001...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station 51002...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station 51002...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station BURL1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station BURL1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station FFIA2...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station FFIA2...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station LONF1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station LONF1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station MDRM1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station MDRM1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station MRKA2...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station MRKA2...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station POTA2...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station POTA2...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station SANF1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station SANF1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling marine data for station SBIO1...\n",
      "📌 La colonne 'time' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'time' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n",
      "🔁 Processing and resampling weather data for station SBIO1...\n",
      "📌 La colonne 'date' est maintenant convertie en chaîne de caractères.\n",
      "📌 Conversion réussie de 'date' en datetime.\n",
      "✅ Successfully renamed column to \"Datetime\"!\n"
     ]
    }
   ],
   "source": [
    "# Resampling des données et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"🔁 Processing and resampling marine data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Marine DataFrame\"] = process_datetime_column(tables[\"Marine DataFrame\"], column='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Marine Data for {station_id}: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"🔁 Processing and resampling weather data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Meteo DataFrame\"] = process_datetime_column(tables[\"Meteo DataFrame\"], column='date')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Meteo Data for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌐 Coordinates (Lat/Lon) added for station 41008.\n",
      "🌐 Coordinates (Lat/Lon) added for station 41044.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42001.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42002.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42012.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42036.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42056.\n",
      "🌐 Coordinates (Lat/Lon) added for station 42058.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44020.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44025.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44027.\n",
      "🌐 Coordinates (Lat/Lon) added for station 44065.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46001.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46006.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46014.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46022.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46025.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46027.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46029.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46053.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46069.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46071.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46072.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46078.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46084.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46086.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46087.\n",
      "🌐 Coordinates (Lat/Lon) added for station 46088.\n",
      "🌐 Coordinates (Lat/Lon) added for station 51000.\n",
      "🌐 Coordinates (Lat/Lon) added for station 51001.\n",
      "🌐 Coordinates (Lat/Lon) added for station 51002.\n",
      "🌐 Coordinates (Lat/Lon) added for station BURL1.\n",
      "🌐 Coordinates (Lat/Lon) added for station FFIA2.\n",
      "🌐 Coordinates (Lat/Lon) added for station LONF1.\n",
      "🌐 Coordinates (Lat/Lon) added for station MDRM1.\n",
      "🌐 Coordinates (Lat/Lon) added for station MRKA2.\n",
      "🌐 Coordinates (Lat/Lon) added for station POTA2.\n",
      "🌐 Coordinates (Lat/Lon) added for station SANF1.\n",
      "🌐 Coordinates (Lat/Lon) added for station SBIO1.\n"
     ]
    }
   ],
   "source": [
    "# Ajout des coordonnées\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        tables[\"Marine DataFrame\"][\"Lat\"] = tables[\"Lat\"]\n",
    "        tables[\"Marine DataFrame\"][\"Lon\"] = tables[\"Lon\"]\n",
    "        print(f\"🌐 Coordinates (Lat/Lon) added for station {station_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding coordinates for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Based on Station ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Merging marine and weather data for station 41008...\n",
      "🔗 Merging marine and weather data for station 41044...\n",
      "🔗 Merging marine and weather data for station 42001...\n",
      "🔗 Merging marine and weather data for station 42002...\n",
      "🔗 Merging marine and weather data for station 42012...\n",
      "🔗 Merging marine and weather data for station 42036...\n",
      "🔗 Merging marine and weather data for station 42056...\n",
      "🔗 Merging marine and weather data for station 42058...\n",
      "🔗 Merging marine and weather data for station 44020...\n",
      "🔗 Merging marine and weather data for station 44025...\n",
      "🔗 Merging marine and weather data for station 44027...\n",
      "🔗 Merging marine and weather data for station 44065...\n",
      "🔗 Merging marine and weather data for station 46001...\n",
      "🔗 Merging marine and weather data for station 46006...\n",
      "🔗 Merging marine and weather data for station 46014...\n",
      "🔗 Merging marine and weather data for station 46022...\n",
      "🔗 Merging marine and weather data for station 46025...\n",
      "🔗 Merging marine and weather data for station 46027...\n",
      "🔗 Merging marine and weather data for station 46029...\n",
      "🔗 Merging marine and weather data for station 46053...\n",
      "🔗 Merging marine and weather data for station 46069...\n",
      "🔗 Merging marine and weather data for station 46071...\n",
      "🔗 Merging marine and weather data for station 46072...\n",
      "🔗 Merging marine and weather data for station 46078...\n",
      "🔗 Merging marine and weather data for station 46084...\n",
      "🔗 Merging marine and weather data for station 46086...\n",
      "🔗 Merging marine and weather data for station 46087...\n",
      "🔗 Merging marine and weather data for station 46088...\n",
      "🔗 Merging marine and weather data for station 51000...\n",
      "🔗 Merging marine and weather data for station 51001...\n",
      "🔗 Merging marine and weather data for station 51002...\n",
      "🔗 Merging marine and weather data for station BURL1...\n",
      "🔗 Merging marine and weather data for station FFIA2...\n",
      "🔗 Merging marine and weather data for station LONF1...\n",
      "🔗 Merging marine and weather data for station MDRM1...\n",
      "🔗 Merging marine and weather data for station MRKA2...\n",
      "🔗 Merging marine and weather data for station POTA2...\n",
      "🔗 Merging marine and weather data for station SANF1...\n",
      "🔗 Merging marine and weather data for station SBIO1...\n",
      "39 DataFrames Merged :\n",
      "246782 rows in total !\n"
     ]
    }
   ],
   "source": [
    "number_merged_data = 0\n",
    "list_silver_merged_df=[]\n",
    "# Fusion des DataFrames\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"🔗 Merging marine and weather data for station {station_id}...\")\n",
    "        df_merged = pd.merge(\n",
    "            tables[\"Marine DataFrame\"], tables[\"Meteo DataFrame\"], on='Datetime', how='inner'\n",
    "        )\n",
    "        tables[\"Merged DataFrame\"] = df_merged\n",
    "        number_merged_data += df_merged.shape[0]\n",
    "        list_silver_merged_df.append(df_merged)\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging data for station {station_id}: {e}\")\n",
    "\n",
    "print(f'{len(list_silver_merged_df)} DataFrames Merged :\\n{number_merged_data} rows in total !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Changing Data Types  for station 41008...\n",
      "Successfully Changed Data Types for Station 41008\n",
      "🔗 Changing Data Types  for station 41044...\n",
      "Successfully Changed Data Types for Station 41044\n",
      "🔗 Changing Data Types  for station 42001...\n",
      "Successfully Changed Data Types for Station 42001\n",
      "🔗 Changing Data Types  for station 42002...\n",
      "Successfully Changed Data Types for Station 42002\n",
      "🔗 Changing Data Types  for station 42012...\n",
      "Successfully Changed Data Types for Station 42012\n",
      "🔗 Changing Data Types  for station 42036...\n",
      "Successfully Changed Data Types for Station 42036\n",
      "🔗 Changing Data Types  for station 42056...\n",
      "Successfully Changed Data Types for Station 42056\n",
      "🔗 Changing Data Types  for station 42058...\n",
      "Successfully Changed Data Types for Station 42058\n",
      "🔗 Changing Data Types  for station 44020...\n",
      "Successfully Changed Data Types for Station 44020\n",
      "🔗 Changing Data Types  for station 44025...\n",
      "Successfully Changed Data Types for Station 44025\n",
      "🔗 Changing Data Types  for station 44027...\n",
      "Successfully Changed Data Types for Station 44027\n",
      "🔗 Changing Data Types  for station 44065...\n",
      "Successfully Changed Data Types for Station 44065\n",
      "🔗 Changing Data Types  for station 46001...\n",
      "Successfully Changed Data Types for Station 46001\n",
      "🔗 Changing Data Types  for station 46006...\n",
      "Successfully Changed Data Types for Station 46006\n",
      "🔗 Changing Data Types  for station 46014...\n",
      "Successfully Changed Data Types for Station 46014\n",
      "🔗 Changing Data Types  for station 46022...\n",
      "Successfully Changed Data Types for Station 46022\n",
      "🔗 Changing Data Types  for station 46025...\n",
      "Successfully Changed Data Types for Station 46025\n",
      "🔗 Changing Data Types  for station 46027...\n",
      "Successfully Changed Data Types for Station 46027\n",
      "🔗 Changing Data Types  for station 46029...\n",
      "Successfully Changed Data Types for Station 46029\n",
      "🔗 Changing Data Types  for station 46053...\n",
      "Successfully Changed Data Types for Station 46053\n",
      "🔗 Changing Data Types  for station 46069...\n",
      "Successfully Changed Data Types for Station 46069\n",
      "🔗 Changing Data Types  for station 46071...\n",
      "Successfully Changed Data Types for Station 46071\n",
      "🔗 Changing Data Types  for station 46072...\n",
      "Successfully Changed Data Types for Station 46072\n",
      "🔗 Changing Data Types  for station 46078...\n",
      "Successfully Changed Data Types for Station 46078\n",
      "🔗 Changing Data Types  for station 46084...\n",
      "Successfully Changed Data Types for Station 46084\n",
      "🔗 Changing Data Types  for station 46086...\n",
      "Successfully Changed Data Types for Station 46086\n",
      "🔗 Changing Data Types  for station 46087...\n",
      "Successfully Changed Data Types for Station 46087\n",
      "🔗 Changing Data Types  for station 46088...\n",
      "Successfully Changed Data Types for Station 46088\n",
      "🔗 Changing Data Types  for station 51000...\n",
      "Successfully Changed Data Types for Station 51000\n",
      "🔗 Changing Data Types  for station 51001...\n",
      "Successfully Changed Data Types for Station 51001\n",
      "🔗 Changing Data Types  for station 51002...\n",
      "Successfully Changed Data Types for Station 51002\n",
      "🔗 Changing Data Types  for station BURL1...\n",
      "Successfully Changed Data Types for Station BURL1\n",
      "🔗 Changing Data Types  for station FFIA2...\n",
      "Successfully Changed Data Types for Station FFIA2\n",
      "🔗 Changing Data Types  for station LONF1...\n",
      "Successfully Changed Data Types for Station LONF1\n",
      "🔗 Changing Data Types  for station MDRM1...\n",
      "Successfully Changed Data Types for Station MDRM1\n",
      "🔗 Changing Data Types  for station MRKA2...\n",
      "Successfully Changed Data Types for Station MRKA2\n",
      "🔗 Changing Data Types  for station POTA2...\n",
      "Successfully Changed Data Types for Station POTA2\n",
      "🔗 Changing Data Types  for station SANF1...\n",
      "Successfully Changed Data Types for Station SANF1\n",
      "🔗 Changing Data Types  for station SBIO1...\n",
      "Successfully Changed Data Types for Station SBIO1\n"
     ]
    }
   ],
   "source": [
    "def convert_df_columns(df):\n",
    "    \"\"\"\n",
    "    Convertit chaque colonne en son type approprié sans modifier les données\n",
    "    ou introduire des NaN.\n",
    "    \n",
    "    Args:\n",
    "    - df: pd.DataFrame. Le DataFrame à traiter.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Le DataFrame avec les types de données convertis.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Traitement des colonnes avec les types appropriés\n",
    "    for col in df.columns:\n",
    "        # Convertir les colonnes numériques\n",
    "        if df[col].dtype == 'object':\n",
    "            # Tenter de convertir en float si c'est un nombre représenté par des strings\n",
    "            try:\n",
    "                # Convertir en float pour les colonnes qui peuvent l'être (ex: \"Wind Speed (km/h)\", \"Pressure (hPa)\", etc.)\n",
    "                df[col] = pd.to_numeric(df[col], errors='raise')\n",
    "            except ValueError:\n",
    "                # Si la conversion échoue, laisser la colonne intacte\n",
    "                pass\n",
    "                \n",
    "        # Convertir des dates si la colonne contient des chaînes de caractères représentant des dates\n",
    "        if df[col].dtype == 'object' and 'date' in col.lower():\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], errors='raise')\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # Convertir les booléens (is_day) en int\n",
    "        if col == \"is_day\":\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Assurer les types numériques pour les colonnes déjà numériques mais mal typées\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        df[col] = df[col].astype(pd.Float64Dtype())  # Garantir une gestion correcte des NaN dans les colonnes numériques\n",
    "\n",
    "    return df\n",
    "\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        df_merged = tables[\"Merged DataFrame\"]\n",
    "        print(f\"🔗 Changing Data Types  for station {station_id}...\")\n",
    "        df_converted = convert_df_columns(df_merged)\n",
    "        tables[\"Converted DataFrame\"] = df_converted\n",
    "        print(f\"Successfully Changed Data Types for Station {station_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error changing data types for station {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7452, 37)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buoys_datas[\"42058\"][\"Converted DataFrame\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    for column in df.columns:\n",
    "        # Calculer le pourcentage de valeurs manquantes\n",
    "        missing_percentage = df[column].isnull().mean() * 100\n",
    "        \n",
    "        # Supprimer la colonne si elle est totalement nulle\n",
    "        if df[column].isnull().sum() == len(df[column]):\n",
    "            df = df.drop(columns=[column])\n",
    "            continue\n",
    "        \n",
    "        # Si plus de 50% des valeurs sont manquantes, on retire la colonne sauf si c'est numérique\n",
    "        if missing_percentage > 50:\n",
    "            if df[column].dtype not in ['float64', 'int64']:  # Ne pas supprimer les colonnes numériques\n",
    "                df = df.drop(columns=[column])\n",
    "        else:\n",
    "            # Si la colonne est numérique, on remplace les NaN par la médiane\n",
    "            if df[column].dtype in ['float64', 'int64']:  # vérifier si c'est une colonne numérique\n",
    "                median_value = df[column].median()\n",
    "                df[column].fillna(median_value, inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Cleaning DataFrame for station 41008...\n",
      "Successfully DataFrame for Station 41008\n",
      "🔗 Cleaning DataFrame for station 41044...\n",
      "Successfully DataFrame for Station 41044\n",
      "🔗 Cleaning DataFrame for station 42001...\n",
      "Successfully DataFrame for Station 42001\n",
      "🔗 Cleaning DataFrame for station 42002...\n",
      "Successfully DataFrame for Station 42002\n",
      "🔗 Cleaning DataFrame for station 42012...\n",
      "Successfully DataFrame for Station 42012\n",
      "🔗 Cleaning DataFrame for station 42036...\n",
      "Successfully DataFrame for Station 42036\n",
      "🔗 Cleaning DataFrame for station 42056...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully DataFrame for Station 42056\n",
      "🔗 Cleaning DataFrame for station 42058...\n",
      "Successfully DataFrame for Station 42058\n",
      "🔗 Cleaning DataFrame for station 44020...\n",
      "Successfully DataFrame for Station 44020\n",
      "🔗 Cleaning DataFrame for station 44025...\n",
      "Successfully DataFrame for Station 44025\n",
      "🔗 Cleaning DataFrame for station 44027...\n",
      "Successfully DataFrame for Station 44027\n",
      "🔗 Cleaning DataFrame for station 44065...\n",
      "Successfully DataFrame for Station 44065\n",
      "🔗 Cleaning DataFrame for station 46001...\n",
      "Successfully DataFrame for Station 46001\n",
      "🔗 Cleaning DataFrame for station 46006...\n",
      "Successfully DataFrame for Station 46006\n",
      "🔗 Cleaning DataFrame for station 46014...\n",
      "Successfully DataFrame for Station 46014\n",
      "🔗 Cleaning DataFrame for station 46022...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully DataFrame for Station 46022\n",
      "🔗 Cleaning DataFrame for station 46025...\n",
      "Successfully DataFrame for Station 46025\n",
      "🔗 Cleaning DataFrame for station 46027...\n",
      "Successfully DataFrame for Station 46027\n",
      "🔗 Cleaning DataFrame for station 46029...\n",
      "Successfully DataFrame for Station 46029\n",
      "🔗 Cleaning DataFrame for station 46053...\n",
      "Successfully DataFrame for Station 46053\n",
      "🔗 Cleaning DataFrame for station 46069...\n",
      "Successfully DataFrame for Station 46069\n",
      "🔗 Cleaning DataFrame for station 46071...\n",
      "Successfully DataFrame for Station 46071\n",
      "🔗 Cleaning DataFrame for station 46072...\n",
      "Successfully DataFrame for Station 46072\n",
      "🔗 Cleaning DataFrame for station 46078...\n",
      "Successfully DataFrame for Station 46078\n",
      "🔗 Cleaning DataFrame for station 46084...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully DataFrame for Station 46084\n",
      "🔗 Cleaning DataFrame for station 46086...\n",
      "Successfully DataFrame for Station 46086\n",
      "🔗 Cleaning DataFrame for station 46087...\n",
      "Successfully DataFrame for Station 46087\n",
      "🔗 Cleaning DataFrame for station 46088...\n",
      "Successfully DataFrame for Station 46088\n",
      "🔗 Cleaning DataFrame for station 51000...\n",
      "Successfully DataFrame for Station 51000\n",
      "🔗 Cleaning DataFrame for station 51001...\n",
      "Successfully DataFrame for Station 51001\n",
      "🔗 Cleaning DataFrame for station 51002...\n",
      "Successfully DataFrame for Station 51002\n",
      "🔗 Cleaning DataFrame for station BURL1...\n",
      "Successfully DataFrame for Station BURL1\n",
      "🔗 Cleaning DataFrame for station FFIA2...\n",
      "Successfully DataFrame for Station FFIA2\n",
      "🔗 Cleaning DataFrame for station LONF1...\n",
      "Successfully DataFrame for Station LONF1\n",
      "🔗 Cleaning DataFrame for station MDRM1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully DataFrame for Station MDRM1\n",
      "🔗 Cleaning DataFrame for station MRKA2...\n",
      "Successfully DataFrame for Station MRKA2\n",
      "🔗 Cleaning DataFrame for station POTA2...\n",
      "Successfully DataFrame for Station POTA2\n",
      "🔗 Cleaning DataFrame for station SANF1...\n",
      "Successfully DataFrame for Station SANF1\n",
      "🔗 Cleaning DataFrame for station SBIO1...\n",
      "Successfully DataFrame for Station SBIO1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "\n",
    "        print(f\"🔗 Cleaning DataFrame for station {station_id}...\")\n",
    "        df_converted = tables[\"Converted DataFrame\"]\n",
    "        \n",
    "        df_cleaned = handle_null_values(df_converted)\n",
    "\n",
    "        tables[\"Cleaned DataFrame\"] = df_cleaned\n",
    "\n",
    "        print(f\"Successfully DataFrame for Station {station_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error Cleaning DataFrame for station {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔀 Merging all DataFrames into a final DataFrame...\n",
      "\n",
      "⭐🏆 Processing complete!\n",
      "🔢 Total stations processed: 39\n",
      "📝 Final merged DataFrame size: (246782, 37)\n"
     ]
    }
   ],
   "source": [
    "# Fusion finale de tous les DataFrames\n",
    "try:\n",
    "    print(\"🔀 Merging all DataFrames into a final DataFrame...\")\n",
    "    dataframes_to_concat = [tables[\"Merged DataFrame\"] for tables in buoys_datas.values()]\n",
    "\n",
    "    df_final = pd.concat(dataframes_to_concat, ignore_index=True)\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during final merge: {e}\")\n",
    "    df_final = None\n",
    "\n",
    "# Résumé final\n",
    "print(\"\\n⭐🏆 Processing complete!\")\n",
    "print(f\"🔢 Total stations processed: {len(buoys_datas)}\")\n",
    "\n",
    "if df_final is not None and not df_final.empty:\n",
    "    print(f\"📝 Final merged DataFrame size: {df_final.shape}\")\n",
    "else:\n",
    "    print(\"The DataFrame is either None or empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_x                                    int64\n",
       "Wind Direction (°)                    float64\n",
       "Wind Speed (km/h)                     float64\n",
       "Wind Gusts (km/h)                     float64\n",
       "Wave Height (m)                       float64\n",
       "dominant_wave_period                  float64\n",
       "Average Wave Period (s)               float64\n",
       "Dominant Wave Direction (°)           float64\n",
       "Pressure (hPA)                        float64\n",
       "Air T°                                float64\n",
       "Water T°                              float64\n",
       "dewpoint                              float64\n",
       " Visibility (%)_x                      object\n",
       "3hr_pressure_tendency                 float64\n",
       "water_level_above_mean                 object\n",
       "Datetime                       datetime64[ns]\n",
       "Station ID                             object\n",
       "Lat                                    object\n",
       "Lon                                    object\n",
       "id_y                                    int64\n",
       "T°(C°)                                 object\n",
       "Relative Humidity (%)                  object\n",
       "Dew Point (°C)                         object\n",
       "Precipitation (mm)                     object\n",
       "rain                                   object\n",
       "showers                                object\n",
       " Sea Level Pressure (hPa)              object\n",
       "surface_pressure                       object\n",
       "cloud_cover                            object\n",
       "Low Clouds (%)                         object\n",
       "Middle Clouds (%)                      object\n",
       "High Clouds (%)                        object\n",
       " Visibility (%)_y                      object\n",
       "wind_speed_10m                         object\n",
       "soil_temperature_0cm                   object\n",
       "soil_moisture_0_to_1cm                 object\n",
       "is_day                                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = convert_final_df_columns(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_x                                  Float64\n",
       "Wind Direction (°)                    Float64\n",
       "Wind Speed (km/h)                     Float64\n",
       "Wind Gusts (km/h)                     Float64\n",
       "Wave Height (m)                       Float64\n",
       "dominant_wave_period                  Float64\n",
       "Average Wave Period (s)               Float64\n",
       "Dominant Wave Direction (°)           Float64\n",
       "Pressure (hPA)                        Float64\n",
       "Air T°                                Float64\n",
       "Water T°                              Float64\n",
       "dewpoint                              Float64\n",
       " Visibility (%)_x                     Float64\n",
       "3hr_pressure_tendency                 Float64\n",
       "water_level_above_mean                Float64\n",
       "Datetime                       datetime64[ns]\n",
       "Station ID                             object\n",
       "Lat                                    object\n",
       "Lon                                    object\n",
       "id_y                                  Float64\n",
       "T°(C°)                                Float64\n",
       "Relative Humidity (%)                 Float64\n",
       "Dew Point (°C)                        Float64\n",
       "Precipitation (mm)                    Float64\n",
       "rain                                  Float64\n",
       "showers                               Float64\n",
       " Sea Level Pressure (hPa)             Float64\n",
       "surface_pressure                      Float64\n",
       "cloud_cover                           Float64\n",
       "Low Clouds (%)                        Float64\n",
       "Middle Clouds (%)                     Float64\n",
       "High Clouds (%)                       Float64\n",
       " Visibility (%)_y                     Float64\n",
       "wind_speed_10m                        Float64\n",
       "soil_temperature_0cm                  Float64\n",
       "soil_moisture_0_to_1cm                Float64\n",
       "is_day                                Float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(buoys_datas[\"42058\"][\"Marine DataFrame\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HANDLING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " clean_dataframe(meteo_df, meteo_cols, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(buoys_datas[\"42058\"][\"Cleaned Marine DataFrame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(buoys_datas[\"42058\"][\"Cleaned Meteo DataFrame\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Dataframes Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_columns_to_numeric(df, cols_to_convert):\n",
    "\n",
    "    df = df.copy()  # Ne pas modifier l'original\n",
    "\n",
    "    for col in cols_to_convert:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                # Essayer de convertir la colonne en numérique\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"raise\")  # 'raise' lève une erreur si la conversion échoue\n",
    "            except ValueError:\n",
    "                print(f\"⚠️ Impossible de convertir la colonne {col}, elle reste inchangée.\")\n",
    "\n",
    "    # Si 'is_day' existe, convertissons-le en entier proprement\n",
    "    if \"is_day\" in df.columns:\n",
    "        try:\n",
    "            df[\"is_day\"] = pd.to_numeric(df[\"is_day\"], errors=\"raise\").astype(int)\n",
    "        except ValueError:\n",
    "            print(\"⚠️ Impossible de convertir 'is_day' en entier, elle reste inchangée.\")\n",
    "\n",
    "    print(\"Columns after conversion:\", df.dtypes)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, tables in buoys_datas.items():\n",
    "    \n",
    "    try:\n",
    "        cleaned_meteo_df = tables[\"Cleaned Meteo DataFrame\"]\n",
    "        converted_meteo_df = convert_columns_to_numeric(cleaned_meteo_df, meteo_cols)\n",
    "        tables[\"Converted Meteo DataFrame\"] = converted_meteo_df\n",
    "        print(f'Successfully Converted {station_id} Meteo Dataframe Types!')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error converting Meteo Dataframe Types for {station_id}!')\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        cleaned_marine_df = tables[\"Cleaned Marine DataFrame\"]\n",
    "        converted_marine_df = convert_columns_to_numeric(cleaned_marine_df, meteo_cols)\n",
    "        tables[\"Converted Marine DataFrame\"] = converted_marine_df\n",
    "        print(f'Successfully Converted {station_id} Marine Dataframe Types!')\n",
    "    except Exception as e:\n",
    "        print(f'Error converting Marine Dataframe Types for {station_id}!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{converted_marine_df.shape}\\n{converted_marine_df.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(converted_marine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling des données et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"🔁 Processing and resampling marine data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Resampled Marine DataFrame\"] = process_datetime_column(tables[\"Marine DataFrame\"], column='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Marine Data for {station_id}: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"🔁 Processing and resampling weather data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Resampled Meteo DataFrame\"] = process_datetime_column(tables[\"Meteo DataFrame\"], column='date')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Meteo Data for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_none=0\n",
    "meteo_none=0\n",
    "\n",
    "# Resampling des données et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    meteo_df = tables[\"Meteo DataFrame\"]\n",
    "    if meteo_df is None:\n",
    "        meteo_none +=1\n",
    "    marine_df = tables[\"Marine DataFrame\"]\n",
    "    if marine_df is None:\n",
    "        marine_none +=1\n",
    "\n",
    "print(f\"Meteo None number :{meteo_none}\\nMarine None number :{marine_none}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_df = buoys_datas[\"42058\"][\"Marine DataFrame\"]\n",
    "marine_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoys_datas[\"42058\"][\"Meteo DataFrame\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling des données et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    meteo_df = tables[\"Meteo DataFrame\"]\n",
    "    marine_df = tables[\"Marine DataFrame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoys_datas[\"41008\"][\"Merged DataFrame\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating all DataFrames into a Final one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[['Daytime', 'Month']] = df_cleaned['Datetime'].apply(lambda x: get_day_time(x)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_42058 = df_cleaned[df_cleaned[\"Station ID\"] == 41008]\n",
    "df_42058.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de contrôle des appels API\n",
    "vc_api_key_path = r\"c:\\Credentials\\visual_crossing_weather_api.json\"\n",
    "with open(vc_api_key_path, 'r') as file:\n",
    "    content = json.load(file)\n",
    "    vc_api_key = content[\"api_key\"]\n",
    "\n",
    "df_42058 = df_cleaned[df_cleaned[\"Station ID\"] == 42058]\n",
    "lat = df_42058[\"Lat\"].iloc[0]  # Récupérer la première valeur de la colonne \"Lat\"\n",
    "lon = df_42058[\"Lon\"].iloc[0]  # Récupérer la première valeur de la colonne \"Lon\"\n",
    "\n",
    "lat, lon = convert_coordinates(lat, lon)\n",
    "\n",
    "# Définition des dates dynamiques\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")  # Hier pour éviter les données incomplètes d'aujourd'hui\n",
    "start_date = (datetime.now() - timedelta(days=31)).strftime(\"%Y-%m-%d\")  # 31 jours avant aujourd'hui\n",
    "last_call_time = None\n",
    "vc_meteo_data = None\n",
    "\n",
    "# Construction de l'URL\n",
    "url_last_month = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{lat},{lon}/{start_date}/{today}?unitGroup=metric&key={vc_api_key}&contentType=json\"\n",
    "try :\n",
    "    response = requests.get(url_last_month)\n",
    "    vc_meteo_data = response.json()  # Essayer de décoder le JSON\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming the df_cleaned DataFrame already exists and contains the required data\n",
    "\n",
    "# First, load your Visual Crossing Weather Data (example, you may already have it)\n",
    "# Assuming vc_meteo_data is the JSON response from Visual Crossing\n",
    "# Example of flattening the JSON\n",
    "df_vc_meteo = pd.json_normalize(vc_meteo_data, record_path=[\"days\", \"hours\"], meta=[\"days\"])\n",
    "\n",
    "# Convert the datetimeEpoch from Visual Crossing Weather data into Date and Hour columns\n",
    "df_vc_meteo[\"Date\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%Y-%m-%d\")\n",
    "df_vc_meteo[\"Hour\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%H\")\n",
    "\n",
    "# Filter data from df_vc_meteo for the last 30 days\n",
    "today = datetime.now()\n",
    "thirty_days_ago = today - timedelta(days=30)\n",
    "\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "thirty_days_ago_str = thirty_days_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Filter df_vc_meteo for the last 30 days\n",
    "df_test_last_month = df_vc_meteo[['Date', 'Hour', 'windspeed']]\n",
    "df_test_last_month = df_test_last_month[(df_test_last_month['Date'] >= thirty_days_ago_str) & \n",
    "                                        (df_test_last_month['Date'] <= today_str)]\n",
    "\n",
    "# Prepare df_cleaned for merging (add Date and Hour columns)\n",
    "df_cleaned['Date'] = df_cleaned['Datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "df_cleaned['Hour'] = df_cleaned['Datetime'].dt.strftime(\"%H\")\n",
    "\n",
    "# Filter df_cleaned for the last 30 days\n",
    "df_cleaned_last_month = df_cleaned[(df_cleaned['Date'] >= thirty_days_ago_str) & \n",
    "                                   (df_cleaned['Date'] <= today_str)]\n",
    "\n",
    "# Merge df_vc_meteo and df_cleaned based on Date and Hour\n",
    "df_merged = df_test_last_month.merge(df_cleaned_last_month[['Date', 'Hour', 'Wind Speed (km/h)', 'wind_speed_10m']], \n",
    "                                    on=['Date', 'Hour'], \n",
    "                                    how='inner')\n",
    "\n",
    "# Display the merged dataframe\n",
    "print(df_merged.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_rename={'temperature_2m': 'T°(C°)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (°C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (%)',  'wind_direction': 'Wind Direction (°)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (°)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air T°','water_temperature': 'Water T°'}\n",
    "\n",
    "df_cleaned = rename_columns(df_cleaned, col_to_rename)\n",
    "df_cleaned = drop_columns_if_exist(df_cleaned,['soil_temperature_0cm','rain', 'showers', 'is_day', 'id_x', 'id_y','soil_moisture_0_to_1cm'])\n",
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les données de l'API\n",
    "vc_meteo_data = response.json()\n",
    "print(vc_meteo_data)  # Vérifiez les données récupérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les données JSON en DataFrame\n",
    "df_vc_meteo = pd.json_normalize(vc_meteo_data, record_path=[\"days\", \"hours\"], meta=[\"days\"])\n",
    "\n",
    "# Afficher la première ligne des données\n",
    "df_vc_meteo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion du timestamp en datetime\n",
    "df_vc_meteo[\"Date\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%Y-%m-%d\")\n",
    "df_vc_meteo[\"Hour\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les dates de filtrage pour les 30 derniers jours\n",
    "today = datetime.now()\n",
    "thirty_days_ago = today - timedelta(days=30)\n",
    "\n",
    "# Convertir les dates en format YYYY-MM-DD\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "thirty_days_ago_str = thirty_days_ago.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données des 30 derniers jours de df_vc_meteo\n",
    "df_test_last_month = df_vc_meteo[['Date', 'Hour', 'windspeed']]\n",
    "df_test_last_month = df_test_last_month[(df_test_last_month['Date'] >= thirty_days_ago_str) & \n",
    "                                        (df_test_last_month['Date'] <= today_str)]\n",
    "\n",
    "# Ajouter les colonnes Date et Hour à df_42058\n",
    "df_42058.loc[:, 'Date'] = df_42058['Datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "df_42058.loc[:, 'Hour'] = df_42058['Datetime'].dt.strftime(\"%H\")\n",
    "\n",
    "# Filtrer les données des 30 derniers jours dans df_42058\n",
    "df_42058_last_month = df_42058[(df_42058['Date'] >= thirty_days_ago_str) & \n",
    "                                (df_42058['Date'] <= today_str)]\n",
    "\n",
    "# Fusionner les deux DataFrames sur Date et Hour\n",
    "df_test_merged = df_test_last_month.merge(df_42058_last_month[['Date', 'Hour', 'Wind Speed (km/h)', 'wind_speed_10m']], \n",
    "                                     on=['Date', 'Hour'], \n",
    "                                     how='inner')\n",
    "\n",
    "df_test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def handle_null_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     row_count = df.shape[0]\n",
    "    \n",
    "#     # Initialisation des listes pour suivre les colonnes supprimées\n",
    "#     removed_columns = []\n",
    "#     non_numeric_columns_to_drop = []\n",
    "    \n",
    "#     # Utiliser lambda et apply() pour calculer le nombre de valeurs nulles dans chaque colonne\n",
    "#     null_counts = df.apply(lambda col: int(col.isnull().sum()))  # Calculer le nombre de NaN par colonne\n",
    "    \n",
    "#     # Condition : 1. Colonnes avec toutes les valeurs nulles ou 2. Plus de 50% de valeurs nulles et colonne non numérique\n",
    "#     columns_to_drop = null_counts[\n",
    "#         (null_counts == row_count) | \n",
    "#         ((null_counts > row_count * 0.5) & ~df.apply(lambda col: pd.api.types.is_numeric_dtype(col)))\n",
    "#     ].index\n",
    "    \n",
    "#     # Ajouter les noms des colonnes supprimées dans les listes appropriées\n",
    "#     for col in columns_to_drop:\n",
    "#         if null_counts[col] == row_count:\n",
    "#             removed_columns.append(col)  # Colonnes entièrement vides\n",
    "#         elif null_counts[col] > row_count * 0.5 and not pd.api.types.is_numeric_dtype(df[col]):\n",
    "#             non_numeric_columns_to_drop.append(col)  # Colonnes > 50% nulles et non numériques\n",
    "    \n",
    "#     # Supprimer les colonnes identifiées\n",
    "#     df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "#     # Afficher les résultats\n",
    "#     print(\"Colonnes supprimées pour avoir toutes les valeurs nulles:\")\n",
    "#     print(removed_columns)\n",
    "    \n",
    "#     print(\"\\nColonnes supprimées pour avoir plus de 50% de valeurs nulles et être non numériques:\")\n",
    "#     print(non_numeric_columns_to_drop)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# # df_final = pd.read_csv('ton_fichier.csv') # Assure-toi que df_final est bien un DataFrame valide avant d'appeler la fonction\n",
    "# df_final = handle_null_values(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = df_final.round(2)\n",
    "# print(df_final.columns)\n",
    "# df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def explore_dict_keys(d, parent_key='', sep='_'):\n",
    "#     \"\"\"\n",
    "#     Explore un dictionnaire récursivement pour obtenir toutes les clés, y compris les sous-clés,\n",
    "#     mais ne retourne pas les valeurs finales.\n",
    "\n",
    "#     :param d: Le dictionnaire à explorer\n",
    "#     :param parent_key: La clé parent qui est utilisée pour concaténer les sous-clés\n",
    "#     :param sep: Le séparateur utilisé pour concaténer les clés (par défaut '_')\n",
    "#     :return: Une liste des clés (et sous-clés)\n",
    "#     \"\"\"\n",
    "#     keys = []\n",
    "#     for k, v in d.items():\n",
    "#         new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "#         if isinstance(v, dict):  # Si la valeur est un dictionnaire, on explore récursivement\n",
    "#             keys.append(new_key)  # Ajouter la clé, mais ne pas inclure la valeur\n",
    "#             keys.extend(explore_dict_keys(v, new_key, sep=sep))  # Continuer l'exploration\n",
    "#         else:\n",
    "#             keys.append(new_key)  # Ajouter la clé finale\n",
    "#     return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_key_path(d, target_key, path=[]):\n",
    "#     \"\"\"\n",
    "#     Recherche récursive d'une clé dans un dictionnaire et retourne son chemin.\n",
    "#     :param d: dictionnaire\n",
    "#     :param target_key: clé recherchée\n",
    "#     :param path: liste pour stocker le chemin jusqu'à la clé\n",
    "#     :return: chemin sous forme de liste\n",
    "#     \"\"\"\n",
    "#     if isinstance(d, dict):  # Si le dictionnaire est encore imbriqué\n",
    "#         for key, value in d.items():\n",
    "#             new_path = path + [key]\n",
    "#             if key == target_key:\n",
    "#                 return new_path\n",
    "#             elif isinstance(value, dict):\n",
    "#                 result = find_key_path(value, target_key, new_path)\n",
    "#                 if result:  # Si la clé est trouvée, retourner le chemin\n",
    "#                     return result\n",
    "#     return None  # Retourne None si la clé n'a pas été trouvée\n",
    "\n",
    "\n",
    "\n",
    "# # Recherche du chemin pour la clé 'marine_data'\n",
    "# path = find_key_path(table_dict, \"Marine Dataframe\")\n",
    "# print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto_convert Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, (buoy_id, tables) in enumerate(table_dict.items()):  # Utilisation de .items() pour obtenir (clé, valeur)\n",
    "#     if isinstance(tables, dict):\n",
    "#         if idx == 1:  # Vérifier si l'index est égal à 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Rows of all Dataframes in total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
