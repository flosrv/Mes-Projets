{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connection to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_postgresql_creds = r\"C:\\Users\\f.gionnane\\Documents\\Data Engineering\\Credentials\\postgresql_creds.json\"\n",
    "\n",
    "with open(path_postgresql_creds, 'r') as file:\n",
    "    content = json.load(file)\n",
    "    user = content[\"user\"]\n",
    "    password = content[\"password\"]\n",
    "    host = content[\"host\"]\n",
    "    port = content[\"port\"]\n",
    "\n",
    "db = \"Oceanography_ML_Project\"\n",
    "schema_bronze = \"Bronze\"\n",
    "schema_silver = \"Silver\"\n",
    "\n",
    "# CrÃ©er l'engine PostgreSQL\n",
    "engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{db}\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger les DonnÃ©es des Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Chargement des mÃ©tadonnÃ©es du schÃ©ma...\n",
      "âœ… MÃ©tadonnÃ©es chargÃ©es avec succÃ¨s.\n",
      "\n",
      "ğŸ”¢ Nombre total de tables dans le schÃ©ma : 79\n",
      "\n",
      "ğŸŒŠ Tables marines trouvÃ©es : 39\n",
      "ğŸŒ§ï¸ Tables mÃ©tÃ©o trouvÃ©es : 39\n",
      "ğŸ‹ Tables de bouÃ©es trouvÃ©es : 1\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ”„ Chargement des donnÃ©es de la table 'buoys_datas'...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour 'buoys_datas'.\n",
      "âœ… Table 'buoys_datas' chargÃ©e avec succÃ¨s! Nombre de bouÃ©es (lignes) : 39\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_42001_marine_mid gulf...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42001 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 42001! Nombre de lignes collectÃ©es : 2322\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46088_marine_new dungeness...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46088 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46088! Nombre de lignes collectÃ©es : 7520\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_POTA2_marine_potato point, ak...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station POTA2 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station POTA2! Nombre de lignes collectÃ©es : 2511\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_51002_marine_southwest hawaii...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 51002 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 51002! Nombre de lignes collectÃ©es : 7464\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46086_marine_san clemente basin...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46086 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46086! Nombre de lignes collectÃ©es : 7520\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_SBIO1_marine_south bass island, oh...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station SBIO1 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station SBIO1! Nombre de lignes collectÃ©es : 1256\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_42056_marine_yucatan basin...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42056 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 42056! Nombre de lignes collectÃ©es : 7471\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_41008_marine_grays reef...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 41008 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 41008! Nombre de lignes collectÃ©es : 7502\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_51001_marine_northwestern hawaii one...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 51001 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 51001! Nombre de lignes collectÃ©es : 7468\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_SANF1_marine_sand key, fl...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station SANF1 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station SANF1! Nombre de lignes collectÃ©es : 7431\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46022_marine_eel river...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46022 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46022! Nombre de lignes collectÃ©es : 7536\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46071_marine_western aleutians...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46071 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46071! Nombre de lignes collectÃ©es : 7472\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_41044_marine_ne st martin...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 41044 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 41044! Nombre de lignes collectÃ©es : 7465\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46053_marine_east santa barbara...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46053 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46053! Nombre de lignes collectÃ©es : 7519\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46025_marine_santa monica basin...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46025 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46025! Nombre de lignes collectÃ©es : 7515\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_42058_marine_central caribbean...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42058 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 42058! Nombre de lignes collectÃ©es : 7452\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46029_marine_columbia river bar...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46029 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46029! Nombre de lignes collectÃ©es : 7520\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_LONF1_marine_long key, fl...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station LONF1 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station LONF1! Nombre de lignes collectÃ©es : 7392\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46078_marine_albatross bank...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46078 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46078! Nombre de lignes collectÃ©es : 7467\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46027_marine_st georges...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46027 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46027! Nombre de lignes collectÃ©es : 7521\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_FFIA2_marine_five fingers, ak...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station FFIA2 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station FFIA2! Nombre de lignes collectÃ©es : 1258\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46087_marine_neah bay...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46087 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46087! Nombre de lignes collectÃ©es : 7526\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_BURL1_marine_southwest pass, la...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station BURL1 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station BURL1! Nombre de lignes collectÃ©es : 1255\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_44027_marine_jonesport, me...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 44027 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 44027! Nombre de lignes collectÃ©es : 7470\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46084_marine_cape edgecumbe...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46084 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46084! Nombre de lignes collectÃ©es : 7474\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_42036_marine_west tampa...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42036 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 42036! Nombre de lignes collectÃ©es : 7443\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_44020_marine_nantucket sound...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 44020 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 44020! Nombre de lignes collectÃ©es : 7476\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46069_marine_south santa rosa...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46069 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46069! Nombre de lignes collectÃ©es : 7494\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_44025_marine_long island...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 44025 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 44025! Nombre de lignes collectÃ©es : 7492\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_51000_marine_northern hawaii one...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 51000 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 51000! Nombre de lignes collectÃ©es : 7475\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46001_marine_western gulf of alaska...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46001 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46001! Nombre de lignes collectÃ©es : 7465\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46006_marine_southeast papa...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46006 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46006! Nombre de lignes collectÃ©es : 7474\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_MRKA2_marine_middle rock light, ak...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station MRKA2 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station MRKA2! Nombre de lignes collectÃ©es : 2512\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46072_marine_central aleutians 230 nm sw dutch harbor...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46072 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46072! Nombre de lignes collectÃ©es : 7476\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_42002_marine_west gulf...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42002 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 42002! Nombre de lignes collectÃ©es : 2475\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_44065_marine_new york harbor entrance...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 44065 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 44065! Nombre de lignes collectÃ©es : 7457\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_MDRM1_marine_mt_ desert rock, me...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station MDRM1 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station MDRM1! Nombre de lignes collectÃ©es : 1257\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_46014_marine_pt arena...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46014 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 46014! Nombre de lignes collectÃ©es : 7523\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Marine : station_42012_marine_orange beach...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42012 (Marine).\n",
      "ğŸŒŠ DonnÃ©es Marine chargÃ©es pour la station 42012! Nombre de lignes collectÃ©es : 7456\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_44027_meteo_jonesport, me...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 44027 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 44027! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_42012_meteo_orange beach...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42012 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 42012! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_44025_meteo_long island...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 44025 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 44025! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46014_meteo_pt arena...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46014 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46014! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_MRKA2_meteo_middle rock light, ak...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station MRKA2 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station MRKA2! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46022_meteo_eel river...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46022 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46022! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46006_meteo_southeast papa...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46006 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46006! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_51001_meteo_northwestern hawaii one...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 51001 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 51001! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46025_meteo_santa monica basin...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46025 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46025! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_44020_meteo_nantucket sound...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 44020 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 44020! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_41008_meteo_grays reef...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 41008 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 41008! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_42058_meteo_central caribbean...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42058 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 42058! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46071_meteo_western aleutians...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46071 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46071! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46072_meteo_central aleutians 230 nm sw dutch harbor...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46072 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46072! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46053_meteo_east santa barbara...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46053 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46053! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46029_meteo_columbia river bar...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46029 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46029! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_POTA2_meteo_potato point, ak...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station POTA2 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station POTA2! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_42036_meteo_west tampa...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42036 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 42036! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46084_meteo_cape edgecumbe...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46084 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46084! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_FFIA2_meteo_five fingers, ak...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station FFIA2 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station FFIA2! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_SBIO1_meteo_south bass island, oh...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station SBIO1 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station SBIO1! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_44065_meteo_new york harbor entrance...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 44065 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 44065! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46027_meteo_st georges...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46027 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46027! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_51002_meteo_southwest hawaii...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 51002 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 51002! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46088_meteo_new dungeness...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46088 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46088! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46086_meteo_san clemente basin...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46086 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46086! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_41044_meteo_ne st martin...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 41044 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 41044! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_42002_meteo_west gulf...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42002 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 42002! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_42001_meteo_mid gulf...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42001 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 42001! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46069_meteo_south santa rosa...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46069 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46069! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_42056_meteo_yucatan basin...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 42056 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 42056! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_MDRM1_meteo_mt_ desert rock, me...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station MDRM1 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station MDRM1! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_51000_meteo_northern hawaii one...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 51000 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 51000! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46001_meteo_western gulf of alaska...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46001 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46001! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46087_meteo_neah bay...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46087 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46087! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_SANF1_meteo_sand key, fl...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station SANF1 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station SANF1! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_BURL1_meteo_southwest pass, la...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station BURL1 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station BURL1! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_46078_meteo_albatross bank...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station 46078 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station 46078! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "ğŸ”„ Chargement des donnÃ©es pour la table Meteo : station_LONF1_meteo_long key, fl...\n",
      "ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station LONF1 (Meteo).\n",
      "ğŸŒ§ï¸ DonnÃ©es Meteo chargÃ©es pour la station LONF1! Nombre de lignes collectÃ©es : 2448\n",
      "\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "ğŸ† Chargement des donnÃ©es terminÃ© avec succÃ¨s !\n",
      "ğŸ‹ Total des donnÃ©es bouÃ©es chargÃ©es : 1 - Nombre de bouÃ©es (lignes) : 39\n",
      "ğŸŒŠ Total des donnÃ©es marines chargÃ©es : 39 - Nombre total de lignes : 246782\n",
      "ğŸŒ§ï¸ Total des donnÃ©es mÃ©tÃ©orologiques chargÃ©es : 39 - Nombre total de lignes : 95472\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
     ]
    }
   ],
   "source": [
    "# Charger les mÃ©tadonnÃ©es du schÃ©ma existant\n",
    "metadata = MetaData(schema=schema_bronze)\n",
    "\n",
    "print(\"\\nğŸ” Chargement des mÃ©tadonnÃ©es du schÃ©ma...\")\n",
    "metadata.reflect(bind=conn)\n",
    "print(\"âœ… MÃ©tadonnÃ©es chargÃ©es avec succÃ¨s.\\n\")\n",
    "\n",
    "# RÃ©cupÃ©rer les noms des tables\n",
    "table_names = [t.name for t in metadata.sorted_tables]\n",
    "print(f\"ğŸ”¢ Nombre total de tables dans le schÃ©ma : {len(table_names)}\\n\")\n",
    "\n",
    "# Filtrer les tables en fonction du contenu de leur nom\n",
    "marine_tables = {t for t in table_names if \"marine\" in t.lower()}\n",
    "meteo_tables = {t for t in table_names if \"meteo\" in t.lower()}\n",
    "buoys_data_table = {t for t in table_names if \"buoy\" in t.lower()}\n",
    "\n",
    "print(f\"ğŸŒŠ Tables marines trouvÃ©es : {len(marine_tables)}\")\n",
    "print(f\"ğŸŒ§ï¸ Tables mÃ©tÃ©o trouvÃ©es : {len(meteo_tables)}\")\n",
    "print(f\"ğŸ‹ Tables de bouÃ©es trouvÃ©es : {len(buoys_data_table)}\\n\")\n",
    "\n",
    "# Initialiser le dictionnaire des rÃ©sultats\n",
    "buoys_datas = {}\n",
    "\n",
    "# Compteurs pour suivre le nombre de tables chargÃ©es avec succÃ¨s\n",
    "marine_data_count = 0\n",
    "meteo_data_count = 0\n",
    "buoys_data_count = 0\n",
    "\n",
    "# Compteur pour le nombre total de lignes\n",
    "total_marine_rows = 0\n",
    "total_meteo_rows = 0\n",
    "total_buoys_rows = 0  # Changer ici pour compter le nombre de lignes (bouÃ©es)\n",
    "\n",
    "# VÃ©rifier et rÃ©cupÃ©rer les donnÃ©es de la table \"buoys_datas\"\n",
    "if buoys_data_table:\n",
    "    print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "    print(\"ğŸ”„ Chargement des donnÃ©es de la table 'buoys_datas'...\")\n",
    "\n",
    "    try:\n",
    "        buoys_datas_raw = fetch_table_data(schema=schema_bronze, conn=conn, table_name=next(iter(buoys_data_table)), as_df=True)\n",
    "\n",
    "        if buoys_datas_raw is not None:\n",
    "            print(\"ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour 'buoys_datas'.\")\n",
    "\n",
    "            # Conversion JSON â†’ dict si nÃ©cessaire\n",
    "            if isinstance(buoys_datas_raw, str):\n",
    "                buoys_datas_raw = json.loads(buoys_datas_raw)\n",
    "\n",
    "            elif isinstance(buoys_datas_raw, pd.DataFrame) and \"Station ID\" in buoys_datas_raw.columns:\n",
    "                # Convertir en dictionnaire avec \"Station ID\" comme clÃ©\n",
    "                buoys_datas_raw = buoys_datas_raw.set_index(\"Station ID\").to_dict(orient=\"index\")\n",
    "\n",
    "            # Ajouter au dictionnaire principal directement avec les Station ID comme clÃ©s\n",
    "            buoys_datas.update(buoys_datas_raw)\n",
    "            buoys_data_count += 1\n",
    "            total_buoys_rows += len(buoys_datas_raw)  # Compter le nombre de bouÃ©es\n",
    "            print(f\"âœ… Table 'buoys_datas' chargÃ©e avec succÃ¨s! Nombre de bouÃ©es (lignes) : {total_buoys_rows}\\n\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Aucun rÃ©sultat trouvÃ© dans 'buoys_datas'.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors du chargement de 'buoys_datas': {e}\\n\")\n",
    "\n",
    "# Associer les tables marine et meteo en fonction du station_id et rÃ©cupÃ©rer leurs donnÃ©es\n",
    "for table_set, label, icon, counter, total_rows in [\n",
    "    (marine_tables, \"Marine\", \"ğŸŒŠ\", marine_data_count, total_marine_rows),\n",
    "    (meteo_tables, \"Meteo\", \"ğŸŒ§ï¸\", meteo_data_count, total_meteo_rows)\n",
    "]:\n",
    "    print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "    for table_name in table_set:\n",
    "        print(f\"ğŸ”„ Chargement des donnÃ©es pour la table {label} : {table_name}...\")\n",
    "\n",
    "        try:\n",
    "            station_id = table_name.split(\"_\")[1]\n",
    "\n",
    "            # VÃ©rifier si la station existe dÃ©jÃ  dans buoys_datas, sinon initialiser un dictionnaire\n",
    "            if station_id not in buoys_datas:\n",
    "                buoys_datas[station_id] = {}\n",
    "\n",
    "            # RÃ©cupÃ©rer les donnÃ©es\n",
    "            data = fetch_table_data(schema=schema_bronze, conn=conn, table_name=table_name, as_df=True)\n",
    "\n",
    "            if data is not None:\n",
    "                print(f\"ğŸ“¦ DonnÃ©es rÃ©cupÃ©rÃ©es pour la station {station_id} ({label}).\")\n",
    "\n",
    "                if isinstance(data, str):\n",
    "                    data = pd.DataFrame(json.loads(data))\n",
    "                elif isinstance(data, dict):\n",
    "                    data = pd.DataFrame(data)\n",
    "                # Ajouter les donnÃ©es au dictionnaire de bouÃ©es sous la station_id\n",
    "                buoys_datas[station_id][f\"{label} DataFrame\"] = data\n",
    "                counter += 1\n",
    "                total_rows += len(data)  # Ajouter le nombre de lignes collectÃ©es\n",
    "                print(f\"{icon} DonnÃ©es {label} chargÃ©es pour la station {station_id}! Nombre de lignes collectÃ©es : {len(data)}\\n\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ Aucun rÃ©sultat trouvÃ© pour la station {station_id} ({label}).\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erreur lors du chargement des donnÃ©es {label} pour {table_name} : {e}\\n\")\n",
    "\n",
    "    # Mise Ã  jour des compteurs aprÃ¨s le chargement des donnÃ©es pour chaque catÃ©gorie\n",
    "    if label == \"Marine\":\n",
    "        marine_data_count = counter\n",
    "        total_marine_rows = total_rows\n",
    "    elif label == \"Meteo\":\n",
    "        meteo_data_count = counter\n",
    "        total_meteo_rows = total_rows\n",
    "\n",
    "# Finalement, afficher un rÃ©capitulatif global\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")\n",
    "print(f\"ğŸ† Chargement des donnÃ©es terminÃ© avec succÃ¨s !\")\n",
    "print(f\"ğŸ‹ Total des donnÃ©es bouÃ©es chargÃ©es : {buoys_data_count} - Nombre de bouÃ©es (lignes) : {total_buoys_rows}\")\n",
    "print(f\"ğŸŒŠ Total des donnÃ©es marines chargÃ©es : {marine_data_count} - Nombre total de lignes : {total_marine_rows}\")\n",
    "print(f\"ğŸŒ§ï¸ Total des donnÃ©es mÃ©tÃ©orologiques chargÃ©es : {meteo_data_count} - Nombre total de lignes : {total_meteo_rows}\")\n",
    "print(\"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoys_datas[\"42058\"][\"Marine DataFrame\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoys_datas[\"42058\"][\"Meteo DataFrame\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_silver_merged_df = []  \n",
    "list_failed_dfs = []        \n",
    "\n",
    "number_marine_data = 0\n",
    "number_meteo_data = 0\n",
    "number_merged_data = 0\n",
    "\n",
    "marine_data_conversion = 0\n",
    "meteo_data_conversion = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n",
      "Colonne 'soil_temperature_0cm' SupprimÃ©e\n",
      "Colonne 'rain' SupprimÃ©e\n",
      "Colonne 'showers' SupprimÃ©e\n",
      "Colonne 'is_day' SupprimÃ©e\n",
      "Colonne 'soil_moisture_0_to_1cm' SupprimÃ©e\n"
     ]
    }
   ],
   "source": [
    "marine_cols = [\n",
    "    \"wind_direction\", \"wind_speed\", \"wind_gust\", \"wave_height\",\n",
    "    \"dominant_wave_period\", \"average_wave_period\", \"dominant_wave_direction\",\n",
    "    \"pressure\", \"air_temperature\", \"water_temperature\", \"dewpoint\",\n",
    "    \"visibility\", \"3hr_pressure_tendency\", \"water_level_above_mean\"\n",
    "]\n",
    "\n",
    "meteo_cols = [\n",
    "    \"temperature_2m\", \"relative_humidity_2m\", \"dew_point_2m\", \"precipitation\", \"rain\",\n",
    "    \"showers\", \"pressure_msl\", \"surface_pressure\", \"cloud_cover\", \"cloud_cover_low\",\n",
    "    \"cloud_cover_mid\", \"cloud_cover_high\", \"visibility\", \"wind_speed_10m\",\n",
    "    \"soil_temperature_0cm\", \"soil_moisture_0_to_1cm\"\n",
    "]\n",
    "\n",
    "col_to_rename={'temperature_2m': 'TÂ°(CÂ°)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (Â°C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (%)',  'wind_direction': 'Wind Direction (Â°)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (Â°)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air TÂ°','water_temperature': 'Water TÂ°'}\n",
    "\n",
    "meteo_cols_to_delete = ['soil_temperature_0cm','rain', 'showers', 'is_day',\n",
    "                  'soil_moisture_0_to_1cm']\n",
    "\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    marine_df = tables[\"Marine DataFrame\"]\n",
    "    marine_df = rename_columns(marine_df, col_to_rename)\n",
    "\n",
    "    marine_df = drop_columns_if_exist\n",
    "\n",
    "    meteo_df = tables[\"Meteo DataFrame\"]\n",
    "    meteo_df = rename_columns(meteo_df,col_to_rename)\n",
    "    meteo_df = drop_columns_if_exist(meteo_df, meteo_cols_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOUR RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Processing and resampling marine data for station 41008...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 41008...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 41044...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 41044...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 42001...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 42001...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 42002...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 42002...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 42012...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 42012...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 42036...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 42036...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 42056...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 42056...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 42058...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 42058...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 44020...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 44020...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 44025...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 44025...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 44027...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 44027...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 44065...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 44065...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46001...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46001...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46006...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46006...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46014...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46014...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46022...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46022...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46025...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46025...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46027...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46027...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46029...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46029...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46053...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46053...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46069...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46069...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46071...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46071...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46072...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46072...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46078...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46078...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46084...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46084...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46086...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46086...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46087...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46087...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 46088...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 46088...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 51000...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 51000...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 51001...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 51001...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station 51002...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station 51002...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station BURL1...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station BURL1...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station FFIA2...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station FFIA2...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station LONF1...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station LONF1...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station MDRM1...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station MDRM1...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station MRKA2...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station MRKA2...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station POTA2...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station POTA2...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station SANF1...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station SANF1...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling marine data for station SBIO1...\n",
      "ğŸ“Œ La colonne 'time' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'time' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n",
      "ğŸ” Processing and resampling weather data for station SBIO1...\n",
      "ğŸ“Œ La colonne 'date' est maintenant convertie en chaÃ®ne de caractÃ¨res.\n",
      "ğŸ“Œ Conversion rÃ©ussie de 'date' en datetime.\n",
      "âœ… Successfully renamed column to \"Datetime\"!\n"
     ]
    }
   ],
   "source": [
    "# Resampling des donnÃ©es et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"ğŸ” Processing and resampling marine data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Marine DataFrame\"] = process_datetime_column(tables[\"Marine DataFrame\"], column='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Marine Data for {station_id}: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ” Processing and resampling weather data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Meteo DataFrame\"] = process_datetime_column(tables[\"Meteo DataFrame\"], column='date')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Meteo Data for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ Coordinates (Lat/Lon) added for station 41008.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 41044.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 42001.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 42002.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 42012.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 42036.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 42056.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 42058.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 44020.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 44025.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 44027.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 44065.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46001.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46006.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46014.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46022.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46025.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46027.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46029.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46053.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46069.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46071.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46072.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46078.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46084.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46086.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46087.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 46088.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 51000.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 51001.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station 51002.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station BURL1.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station FFIA2.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station LONF1.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station MDRM1.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station MRKA2.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station POTA2.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station SANF1.\n",
      "ğŸŒ Coordinates (Lat/Lon) added for station SBIO1.\n"
     ]
    }
   ],
   "source": [
    "# Ajout des coordonnÃ©es\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        tables[\"Marine DataFrame\"][\"Lat\"] = tables[\"Lat\"]\n",
    "        tables[\"Marine DataFrame\"][\"Lon\"] = tables[\"Lon\"]\n",
    "        print(f\"ğŸŒ Coordinates (Lat/Lon) added for station {station_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding coordinates for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Based on Station ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Merging marine and weather data for station 41008...\n",
      "ğŸ”— Merging marine and weather data for station 41044...\n",
      "ğŸ”— Merging marine and weather data for station 42001...\n",
      "ğŸ”— Merging marine and weather data for station 42002...\n",
      "ğŸ”— Merging marine and weather data for station 42012...\n",
      "ğŸ”— Merging marine and weather data for station 42036...\n",
      "ğŸ”— Merging marine and weather data for station 42056...\n",
      "ğŸ”— Merging marine and weather data for station 42058...\n",
      "ğŸ”— Merging marine and weather data for station 44020...\n",
      "ğŸ”— Merging marine and weather data for station 44025...\n",
      "ğŸ”— Merging marine and weather data for station 44027...\n",
      "ğŸ”— Merging marine and weather data for station 44065...\n",
      "ğŸ”— Merging marine and weather data for station 46001...\n",
      "ğŸ”— Merging marine and weather data for station 46006...\n",
      "ğŸ”— Merging marine and weather data for station 46014...\n",
      "ğŸ”— Merging marine and weather data for station 46022...\n",
      "ğŸ”— Merging marine and weather data for station 46025...\n",
      "ğŸ”— Merging marine and weather data for station 46027...\n",
      "ğŸ”— Merging marine and weather data for station 46029...\n",
      "ğŸ”— Merging marine and weather data for station 46053...\n",
      "ğŸ”— Merging marine and weather data for station 46069...\n",
      "ğŸ”— Merging marine and weather data for station 46071...\n",
      "ğŸ”— Merging marine and weather data for station 46072...\n",
      "ğŸ”— Merging marine and weather data for station 46078...\n",
      "ğŸ”— Merging marine and weather data for station 46084...\n",
      "ğŸ”— Merging marine and weather data for station 46086...\n",
      "ğŸ”— Merging marine and weather data for station 46087...\n",
      "ğŸ”— Merging marine and weather data for station 46088...\n",
      "ğŸ”— Merging marine and weather data for station 51000...\n",
      "ğŸ”— Merging marine and weather data for station 51001...\n",
      "ğŸ”— Merging marine and weather data for station 51002...\n",
      "ğŸ”— Merging marine and weather data for station BURL1...\n",
      "ğŸ”— Merging marine and weather data for station FFIA2...\n",
      "ğŸ”— Merging marine and weather data for station LONF1...\n",
      "ğŸ”— Merging marine and weather data for station MDRM1...\n",
      "ğŸ”— Merging marine and weather data for station MRKA2...\n",
      "ğŸ”— Merging marine and weather data for station POTA2...\n",
      "ğŸ”— Merging marine and weather data for station SANF1...\n",
      "ğŸ”— Merging marine and weather data for station SBIO1...\n",
      "39 DataFrames Merged :\n",
      "246782 rows in total !\n"
     ]
    }
   ],
   "source": [
    "number_merged_data = 0\n",
    "list_silver_merged_df=[]\n",
    "# Fusion des DataFrames\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"ğŸ”— Merging marine and weather data for station {station_id}...\")\n",
    "        df_merged = pd.merge(\n",
    "            tables[\"Marine DataFrame\"], tables[\"Meteo DataFrame\"], on='Datetime', how='inner'\n",
    "        )\n",
    "        tables[\"Merged DataFrame\"] = df_merged\n",
    "        number_merged_data += df_merged.shape[0]\n",
    "        list_silver_merged_df.append(df_merged)\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging data for station {station_id}: {e}\")\n",
    "\n",
    "print(f'{len(list_silver_merged_df)} DataFrames Merged :\\n{number_merged_data} rows in total !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Changing Data Types  for station 41008...\n",
      "Successfully Changed Data Types for Station 41008\n",
      "ğŸ”— Changing Data Types  for station 41044...\n",
      "Successfully Changed Data Types for Station 41044\n",
      "ğŸ”— Changing Data Types  for station 42001...\n",
      "Successfully Changed Data Types for Station 42001\n",
      "ğŸ”— Changing Data Types  for station 42002...\n",
      "Successfully Changed Data Types for Station 42002\n",
      "ğŸ”— Changing Data Types  for station 42012...\n",
      "Successfully Changed Data Types for Station 42012\n",
      "ğŸ”— Changing Data Types  for station 42036...\n",
      "Successfully Changed Data Types for Station 42036\n",
      "ğŸ”— Changing Data Types  for station 42056...\n",
      "Successfully Changed Data Types for Station 42056\n",
      "ğŸ”— Changing Data Types  for station 42058...\n",
      "Successfully Changed Data Types for Station 42058\n",
      "ğŸ”— Changing Data Types  for station 44020...\n",
      "Successfully Changed Data Types for Station 44020\n",
      "ğŸ”— Changing Data Types  for station 44025...\n",
      "Successfully Changed Data Types for Station 44025\n",
      "ğŸ”— Changing Data Types  for station 44027...\n",
      "Successfully Changed Data Types for Station 44027\n",
      "ğŸ”— Changing Data Types  for station 44065...\n",
      "Successfully Changed Data Types for Station 44065\n",
      "ğŸ”— Changing Data Types  for station 46001...\n",
      "Successfully Changed Data Types for Station 46001\n",
      "ğŸ”— Changing Data Types  for station 46006...\n",
      "Successfully Changed Data Types for Station 46006\n",
      "ğŸ”— Changing Data Types  for station 46014...\n",
      "Successfully Changed Data Types for Station 46014\n",
      "ğŸ”— Changing Data Types  for station 46022...\n",
      "Successfully Changed Data Types for Station 46022\n",
      "ğŸ”— Changing Data Types  for station 46025...\n",
      "Successfully Changed Data Types for Station 46025\n",
      "ğŸ”— Changing Data Types  for station 46027...\n",
      "Successfully Changed Data Types for Station 46027\n",
      "ğŸ”— Changing Data Types  for station 46029...\n",
      "Successfully Changed Data Types for Station 46029\n",
      "ğŸ”— Changing Data Types  for station 46053...\n",
      "Successfully Changed Data Types for Station 46053\n",
      "ğŸ”— Changing Data Types  for station 46069...\n",
      "Successfully Changed Data Types for Station 46069\n",
      "ğŸ”— Changing Data Types  for station 46071...\n",
      "Successfully Changed Data Types for Station 46071\n",
      "ğŸ”— Changing Data Types  for station 46072...\n",
      "Successfully Changed Data Types for Station 46072\n",
      "ğŸ”— Changing Data Types  for station 46078...\n",
      "Successfully Changed Data Types for Station 46078\n",
      "ğŸ”— Changing Data Types  for station 46084...\n",
      "Successfully Changed Data Types for Station 46084\n",
      "ğŸ”— Changing Data Types  for station 46086...\n",
      "Successfully Changed Data Types for Station 46086\n",
      "ğŸ”— Changing Data Types  for station 46087...\n",
      "Successfully Changed Data Types for Station 46087\n",
      "ğŸ”— Changing Data Types  for station 46088...\n",
      "Successfully Changed Data Types for Station 46088\n",
      "ğŸ”— Changing Data Types  for station 51000...\n",
      "Successfully Changed Data Types for Station 51000\n",
      "ğŸ”— Changing Data Types  for station 51001...\n",
      "Successfully Changed Data Types for Station 51001\n",
      "ğŸ”— Changing Data Types  for station 51002...\n",
      "Successfully Changed Data Types for Station 51002\n",
      "ğŸ”— Changing Data Types  for station BURL1...\n",
      "Successfully Changed Data Types for Station BURL1\n",
      "ğŸ”— Changing Data Types  for station FFIA2...\n",
      "Successfully Changed Data Types for Station FFIA2\n",
      "ğŸ”— Changing Data Types  for station LONF1...\n",
      "Successfully Changed Data Types for Station LONF1\n",
      "ğŸ”— Changing Data Types  for station MDRM1...\n",
      "Successfully Changed Data Types for Station MDRM1\n",
      "ğŸ”— Changing Data Types  for station MRKA2...\n",
      "Successfully Changed Data Types for Station MRKA2\n",
      "ğŸ”— Changing Data Types  for station POTA2...\n",
      "Successfully Changed Data Types for Station POTA2\n",
      "ğŸ”— Changing Data Types  for station SANF1...\n",
      "Successfully Changed Data Types for Station SANF1\n",
      "ğŸ”— Changing Data Types  for station SBIO1...\n",
      "Successfully Changed Data Types for Station SBIO1\n"
     ]
    }
   ],
   "source": [
    "def convert_df_columns(df):\n",
    "    \"\"\"\n",
    "    Convertit chaque colonne en son type appropriÃ© sans modifier les donnÃ©es\n",
    "    ou introduire des NaN.\n",
    "    \n",
    "    Args:\n",
    "    - df: pd.DataFrame. Le DataFrame Ã  traiter.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Le DataFrame avec les types de donnÃ©es convertis.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Traitement des colonnes avec les types appropriÃ©s\n",
    "    for col in df.columns:\n",
    "        # Convertir les colonnes numÃ©riques\n",
    "        if df[col].dtype == 'object':\n",
    "            # Tenter de convertir en float si c'est un nombre reprÃ©sentÃ© par des strings\n",
    "            try:\n",
    "                # Convertir en float pour les colonnes qui peuvent l'Ãªtre (ex: \"Wind Speed (km/h)\", \"Pressure (hPa)\", etc.)\n",
    "                df[col] = pd.to_numeric(df[col], errors='raise')\n",
    "            except ValueError:\n",
    "                # Si la conversion Ã©choue, laisser la colonne intacte\n",
    "                pass\n",
    "                \n",
    "        # Convertir des dates si la colonne contient des chaÃ®nes de caractÃ¨res reprÃ©sentant des dates\n",
    "        if df[col].dtype == 'object' and 'date' in col.lower():\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], errors='raise')\n",
    "            except ValueError:\n",
    "                pass\n",
    "        \n",
    "        # Convertir les boolÃ©ens (is_day) en int\n",
    "        if col == \"is_day\":\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Assurer les types numÃ©riques pour les colonnes dÃ©jÃ  numÃ©riques mais mal typÃ©es\n",
    "    for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "        df[col] = df[col].astype(pd.Float64Dtype())  # Garantir une gestion correcte des NaN dans les colonnes numÃ©riques\n",
    "\n",
    "    return df\n",
    "\n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        df_merged = tables[\"Merged DataFrame\"]\n",
    "        print(f\"ğŸ”— Changing Data Types  for station {station_id}...\")\n",
    "        df_converted = convert_df_columns(df_merged)\n",
    "        tables[\"Converted DataFrame\"] = df_converted\n",
    "        print(f\"Successfully Changed Data Types for Station {station_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"Error changing data types for station {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7452, 37)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buoys_datas[\"42058\"][\"Converted DataFrame\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\n",
    "    for column in df.columns:\n",
    "        # Calculer le pourcentage de valeurs manquantes\n",
    "        missing_percentage = df[column].isnull().mean() * 100\n",
    "        \n",
    "        # Supprimer la colonne si elle est totalement nulle\n",
    "        if df[column].isnull().sum() == len(df[column]):\n",
    "            df = df.drop(columns=[column])\n",
    "            continue\n",
    "        \n",
    "        # Si plus de 50% des valeurs sont manquantes, on retire la colonne sauf si c'est numÃ©rique\n",
    "        if missing_percentage > 50:\n",
    "            if df[column].dtype not in ['float64', 'int64']:  # Ne pas supprimer les colonnes numÃ©riques\n",
    "                df = df.drop(columns=[column])\n",
    "        else:\n",
    "            # Si la colonne est numÃ©rique, on remplace les NaN par la mÃ©diane\n",
    "            if df[column].dtype in ['float64', 'int64']:  # vÃ©rifier si c'est une colonne numÃ©rique\n",
    "                median_value = df[column].median()\n",
    "                df[column].fillna(median_value, inplace=True)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Cleaning DataFrame for station 41008...\n",
      "Successfully DataFrame for Station 41008\n",
      "ğŸ”— Cleaning DataFrame for station 41044...\n",
      "Successfully DataFrame for Station 41044\n",
      "ğŸ”— Cleaning DataFrame for station 42001...\n",
      "Successfully DataFrame for Station 42001\n",
      "ğŸ”— Cleaning DataFrame for station 42002...\n",
      "Successfully DataFrame for Station 42002\n",
      "ğŸ”— Cleaning DataFrame for station 42012...\n",
      "Successfully DataFrame for Station 42012\n",
      "ğŸ”— Cleaning DataFrame for station 42036...\n",
      "Successfully DataFrame for Station 42036\n",
      "ğŸ”— Cleaning DataFrame for station 42056...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully DataFrame for Station 42056\n",
      "ğŸ”— Cleaning DataFrame for station 42058...\n",
      "Successfully DataFrame for Station 42058\n",
      "ğŸ”— Cleaning DataFrame for station 44020...\n",
      "Successfully DataFrame for Station 44020\n",
      "ğŸ”— Cleaning DataFrame for station 44025...\n",
      "Successfully DataFrame for Station 44025\n",
      "ğŸ”— Cleaning DataFrame for station 44027...\n",
      "Successfully DataFrame for Station 44027\n",
      "ğŸ”— Cleaning DataFrame for station 44065...\n",
      "Successfully DataFrame for Station 44065\n",
      "ğŸ”— Cleaning DataFrame for station 46001...\n",
      "Successfully DataFrame for Station 46001\n",
      "ğŸ”— Cleaning DataFrame for station 46006...\n",
      "Successfully DataFrame for Station 46006\n",
      "ğŸ”— Cleaning DataFrame for station 46014...\n",
      "Successfully DataFrame for Station 46014\n",
      "ğŸ”— Cleaning DataFrame for station 46022...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully DataFrame for Station 46022\n",
      "ğŸ”— Cleaning DataFrame for station 46025...\n",
      "Successfully DataFrame for Station 46025\n",
      "ğŸ”— Cleaning DataFrame for station 46027...\n",
      "Successfully DataFrame for Station 46027\n",
      "ğŸ”— Cleaning DataFrame for station 46029...\n",
      "Successfully DataFrame for Station 46029\n",
      "ğŸ”— Cleaning DataFrame for station 46053...\n",
      "Successfully DataFrame for Station 46053\n",
      "ğŸ”— Cleaning DataFrame for station 46069...\n",
      "Successfully DataFrame for Station 46069\n",
      "ğŸ”— Cleaning DataFrame for station 46071...\n",
      "Successfully DataFrame for Station 46071\n",
      "ğŸ”— Cleaning DataFrame for station 46072...\n",
      "Successfully DataFrame for Station 46072\n",
      "ğŸ”— Cleaning DataFrame for station 46078...\n",
      "Successfully DataFrame for Station 46078\n",
      "ğŸ”— Cleaning DataFrame for station 46084...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully DataFrame for Station 46084\n",
      "ğŸ”— Cleaning DataFrame for station 46086...\n",
      "Successfully DataFrame for Station 46086\n",
      "ğŸ”— Cleaning DataFrame for station 46087...\n",
      "Successfully DataFrame for Station 46087\n",
      "ğŸ”— Cleaning DataFrame for station 46088...\n",
      "Successfully DataFrame for Station 46088\n",
      "ğŸ”— Cleaning DataFrame for station 51000...\n",
      "Successfully DataFrame for Station 51000\n",
      "ğŸ”— Cleaning DataFrame for station 51001...\n",
      "Successfully DataFrame for Station 51001\n",
      "ğŸ”— Cleaning DataFrame for station 51002...\n",
      "Successfully DataFrame for Station 51002\n",
      "ğŸ”— Cleaning DataFrame for station BURL1...\n",
      "Successfully DataFrame for Station BURL1\n",
      "ğŸ”— Cleaning DataFrame for station FFIA2...\n",
      "Successfully DataFrame for Station FFIA2\n",
      "ğŸ”— Cleaning DataFrame for station LONF1...\n",
      "Successfully DataFrame for Station LONF1\n",
      "ğŸ”— Cleaning DataFrame for station MDRM1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully DataFrame for Station MDRM1\n",
      "ğŸ”— Cleaning DataFrame for station MRKA2...\n",
      "Successfully DataFrame for Station MRKA2\n",
      "ğŸ”— Cleaning DataFrame for station POTA2...\n",
      "Successfully DataFrame for Station POTA2\n",
      "ğŸ”— Cleaning DataFrame for station SANF1...\n",
      "Successfully DataFrame for Station SANF1\n",
      "ğŸ”— Cleaning DataFrame for station SBIO1...\n",
      "Successfully DataFrame for Station SBIO1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\f.gionnane\\Documents\\Data Engineering\\Oceanography-Project-WIP\\env\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "\n",
    "        print(f\"ğŸ”— Cleaning DataFrame for station {station_id}...\")\n",
    "        df_converted = tables[\"Converted DataFrame\"]\n",
    "        \n",
    "        df_cleaned = handle_null_values(df_converted)\n",
    "\n",
    "        tables[\"Cleaned DataFrame\"] = df_cleaned\n",
    "\n",
    "        print(f\"Successfully DataFrame for Station {station_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error Cleaning DataFrame for station {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”€ Merging all DataFrames into a final DataFrame...\n",
      "\n",
      "â­ğŸ† Processing complete!\n",
      "ğŸ”¢ Total stations processed: 39\n",
      "ğŸ“ Final merged DataFrame size: (246782, 37)\n"
     ]
    }
   ],
   "source": [
    "# Fusion finale de tous les DataFrames\n",
    "try:\n",
    "    print(\"ğŸ”€ Merging all DataFrames into a final DataFrame...\")\n",
    "    dataframes_to_concat = [tables[\"Merged DataFrame\"] for tables in buoys_datas.values()]\n",
    "\n",
    "    df_final = pd.concat(dataframes_to_concat, ignore_index=True)\n",
    "\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during final merge: {e}\")\n",
    "    df_final = None\n",
    "\n",
    "# RÃ©sumÃ© final\n",
    "print(\"\\nâ­ğŸ† Processing complete!\")\n",
    "print(f\"ğŸ”¢ Total stations processed: {len(buoys_datas)}\")\n",
    "\n",
    "if df_final is not None and not df_final.empty:\n",
    "    print(f\"ğŸ“ Final merged DataFrame size: {df_final.shape}\")\n",
    "else:\n",
    "    print(\"The DataFrame is either None or empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_x                                    int64\n",
       "Wind Direction (Â°)                    float64\n",
       "Wind Speed (km/h)                     float64\n",
       "Wind Gusts (km/h)                     float64\n",
       "Wave Height (m)                       float64\n",
       "dominant_wave_period                  float64\n",
       "Average Wave Period (s)               float64\n",
       "Dominant Wave Direction (Â°)           float64\n",
       "Pressure (hPA)                        float64\n",
       "Air TÂ°                                float64\n",
       "Water TÂ°                              float64\n",
       "dewpoint                              float64\n",
       " Visibility (%)_x                      object\n",
       "3hr_pressure_tendency                 float64\n",
       "water_level_above_mean                 object\n",
       "Datetime                       datetime64[ns]\n",
       "Station ID                             object\n",
       "Lat                                    object\n",
       "Lon                                    object\n",
       "id_y                                    int64\n",
       "TÂ°(CÂ°)                                 object\n",
       "Relative Humidity (%)                  object\n",
       "Dew Point (Â°C)                         object\n",
       "Precipitation (mm)                     object\n",
       "rain                                   object\n",
       "showers                                object\n",
       " Sea Level Pressure (hPa)              object\n",
       "surface_pressure                       object\n",
       "cloud_cover                            object\n",
       "Low Clouds (%)                         object\n",
       "Middle Clouds (%)                      object\n",
       "High Clouds (%)                        object\n",
       " Visibility (%)_y                      object\n",
       "wind_speed_10m                         object\n",
       "soil_temperature_0cm                   object\n",
       "soil_moisture_0_to_1cm                 object\n",
       "is_day                                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = convert_final_df_columns(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_x                                  Float64\n",
       "Wind Direction (Â°)                    Float64\n",
       "Wind Speed (km/h)                     Float64\n",
       "Wind Gusts (km/h)                     Float64\n",
       "Wave Height (m)                       Float64\n",
       "dominant_wave_period                  Float64\n",
       "Average Wave Period (s)               Float64\n",
       "Dominant Wave Direction (Â°)           Float64\n",
       "Pressure (hPA)                        Float64\n",
       "Air TÂ°                                Float64\n",
       "Water TÂ°                              Float64\n",
       "dewpoint                              Float64\n",
       " Visibility (%)_x                     Float64\n",
       "3hr_pressure_tendency                 Float64\n",
       "water_level_above_mean                Float64\n",
       "Datetime                       datetime64[ns]\n",
       "Station ID                             object\n",
       "Lat                                    object\n",
       "Lon                                    object\n",
       "id_y                                  Float64\n",
       "TÂ°(CÂ°)                                Float64\n",
       "Relative Humidity (%)                 Float64\n",
       "Dew Point (Â°C)                        Float64\n",
       "Precipitation (mm)                    Float64\n",
       "rain                                  Float64\n",
       "showers                               Float64\n",
       " Sea Level Pressure (hPa)             Float64\n",
       "surface_pressure                      Float64\n",
       "cloud_cover                           Float64\n",
       "Low Clouds (%)                        Float64\n",
       "Middle Clouds (%)                     Float64\n",
       "High Clouds (%)                       Float64\n",
       " Visibility (%)_y                     Float64\n",
       "wind_speed_10m                        Float64\n",
       "soil_temperature_0cm                  Float64\n",
       "soil_moisture_0_to_1cm                Float64\n",
       "is_day                                Float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(buoys_datas[\"42058\"][\"Marine DataFrame\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HANDLING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " clean_dataframe(meteo_df, meteo_cols, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(buoys_datas[\"42058\"][\"Cleaned Marine DataFrame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(buoys_datas[\"42058\"][\"Cleaned Meteo DataFrame\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Dataframes Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_columns_to_numeric(df, cols_to_convert):\n",
    "\n",
    "    df = df.copy()  # Ne pas modifier l'original\n",
    "\n",
    "    for col in cols_to_convert:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                # Essayer de convertir la colonne en numÃ©rique\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"raise\")  # 'raise' lÃ¨ve une erreur si la conversion Ã©choue\n",
    "            except ValueError:\n",
    "                print(f\"âš ï¸ Impossible de convertir la colonne {col}, elle reste inchangÃ©e.\")\n",
    "\n",
    "    # Si 'is_day' existe, convertissons-le en entier proprement\n",
    "    if \"is_day\" in df.columns:\n",
    "        try:\n",
    "            df[\"is_day\"] = pd.to_numeric(df[\"is_day\"], errors=\"raise\").astype(int)\n",
    "        except ValueError:\n",
    "            print(\"âš ï¸ Impossible de convertir 'is_day' en entier, elle reste inchangÃ©e.\")\n",
    "\n",
    "    print(\"Columns after conversion:\", df.dtypes)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_id, tables in buoys_datas.items():\n",
    "    \n",
    "    try:\n",
    "        cleaned_meteo_df = tables[\"Cleaned Meteo DataFrame\"]\n",
    "        converted_meteo_df = convert_columns_to_numeric(cleaned_meteo_df, meteo_cols)\n",
    "        tables[\"Converted Meteo DataFrame\"] = converted_meteo_df\n",
    "        print(f'Successfully Converted {station_id} Meteo Dataframe Types!')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error converting Meteo Dataframe Types for {station_id}!')\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        cleaned_marine_df = tables[\"Cleaned Marine DataFrame\"]\n",
    "        converted_marine_df = convert_columns_to_numeric(cleaned_marine_df, meteo_cols)\n",
    "        tables[\"Converted Marine DataFrame\"] = converted_marine_df\n",
    "        print(f'Successfully Converted {station_id} Marine Dataframe Types!')\n",
    "    except Exception as e:\n",
    "        print(f'Error converting Marine Dataframe Types for {station_id}!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{converted_marine_df.shape}\\n{converted_marine_df.isnull().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(converted_marine_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling des donnÃ©es et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    try:\n",
    "        print(f\"ğŸ” Processing and resampling marine data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Resampled Marine DataFrame\"] = process_datetime_column(tables[\"Marine DataFrame\"], column='time')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Marine Data for {station_id}: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"ğŸ” Processing and resampling weather data for station {station_id}...\")\n",
    "        # Convert columns to numeric types (float or int) excluding datetime columns using pandas to_numeric\n",
    "        tables[\"Resampled Meteo DataFrame\"] = process_datetime_column(tables[\"Meteo DataFrame\"], column='date')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Meteo Data for {station_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_none=0\n",
    "meteo_none=0\n",
    "\n",
    "# Resampling des donnÃ©es et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    meteo_df = tables[\"Meteo DataFrame\"]\n",
    "    if meteo_df is None:\n",
    "        meteo_none +=1\n",
    "    marine_df = tables[\"Marine DataFrame\"]\n",
    "    if marine_df is None:\n",
    "        marine_none +=1\n",
    "\n",
    "print(f\"Meteo None number :{meteo_none}\\nMarine None number :{marine_none}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_df = buoys_datas[\"42058\"][\"Marine DataFrame\"]\n",
    "marine_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoys_datas[\"42058\"][\"Meteo DataFrame\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling des donnÃ©es et stockage dans un nouveau compartiment du dictionnaire \n",
    "for station_id, tables in buoys_datas.items():\n",
    "    meteo_df = tables[\"Meteo DataFrame\"]\n",
    "    marine_df = tables[\"Marine DataFrame\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buoys_datas[\"41008\"][\"Merged DataFrame\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating all DataFrames into a Final one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_first_row(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[['Daytime', 'Month']] = df_cleaned['Datetime'].apply(lambda x: get_day_time(x)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_42058 = df_cleaned[df_cleaned[\"Station ID\"] == 41008]\n",
    "df_42058.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de contrÃ´le des appels API\n",
    "vc_api_key_path = r\"c:\\Credentials\\visual_crossing_weather_api.json\"\n",
    "with open(vc_api_key_path, 'r') as file:\n",
    "    content = json.load(file)\n",
    "    vc_api_key = content[\"api_key\"]\n",
    "\n",
    "df_42058 = df_cleaned[df_cleaned[\"Station ID\"] == 42058]\n",
    "lat = df_42058[\"Lat\"].iloc[0]  # RÃ©cupÃ©rer la premiÃ¨re valeur de la colonne \"Lat\"\n",
    "lon = df_42058[\"Lon\"].iloc[0]  # RÃ©cupÃ©rer la premiÃ¨re valeur de la colonne \"Lon\"\n",
    "\n",
    "lat, lon = convert_coordinates(lat, lon)\n",
    "\n",
    "# DÃ©finition des dates dynamiques\n",
    "today = datetime.now().strftime(\"%Y-%m-%d\")  # Hier pour Ã©viter les donnÃ©es incomplÃ¨tes d'aujourd'hui\n",
    "start_date = (datetime.now() - timedelta(days=31)).strftime(\"%Y-%m-%d\")  # 31 jours avant aujourd'hui\n",
    "last_call_time = None\n",
    "vc_meteo_data = None\n",
    "\n",
    "# Construction de l'URL\n",
    "url_last_month = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{lat},{lon}/{start_date}/{today}?unitGroup=metric&key={vc_api_key}&contentType=json\"\n",
    "try :\n",
    "    response = requests.get(url_last_month)\n",
    "    vc_meteo_data = response.json()  # Essayer de dÃ©coder le JSON\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming the df_cleaned DataFrame already exists and contains the required data\n",
    "\n",
    "# First, load your Visual Crossing Weather Data (example, you may already have it)\n",
    "# Assuming vc_meteo_data is the JSON response from Visual Crossing\n",
    "# Example of flattening the JSON\n",
    "df_vc_meteo = pd.json_normalize(vc_meteo_data, record_path=[\"days\", \"hours\"], meta=[\"days\"])\n",
    "\n",
    "# Convert the datetimeEpoch from Visual Crossing Weather data into Date and Hour columns\n",
    "df_vc_meteo[\"Date\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%Y-%m-%d\")\n",
    "df_vc_meteo[\"Hour\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%H\")\n",
    "\n",
    "# Filter data from df_vc_meteo for the last 30 days\n",
    "today = datetime.now()\n",
    "thirty_days_ago = today - timedelta(days=30)\n",
    "\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "thirty_days_ago_str = thirty_days_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Filter df_vc_meteo for the last 30 days\n",
    "df_test_last_month = df_vc_meteo[['Date', 'Hour', 'windspeed']]\n",
    "df_test_last_month = df_test_last_month[(df_test_last_month['Date'] >= thirty_days_ago_str) & \n",
    "                                        (df_test_last_month['Date'] <= today_str)]\n",
    "\n",
    "# Prepare df_cleaned for merging (add Date and Hour columns)\n",
    "df_cleaned['Date'] = df_cleaned['Datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "df_cleaned['Hour'] = df_cleaned['Datetime'].dt.strftime(\"%H\")\n",
    "\n",
    "# Filter df_cleaned for the last 30 days\n",
    "df_cleaned_last_month = df_cleaned[(df_cleaned['Date'] >= thirty_days_ago_str) & \n",
    "                                   (df_cleaned['Date'] <= today_str)]\n",
    "\n",
    "# Merge df_vc_meteo and df_cleaned based on Date and Hour\n",
    "df_merged = df_test_last_month.merge(df_cleaned_last_month[['Date', 'Hour', 'Wind Speed (km/h)', 'wind_speed_10m']], \n",
    "                                    on=['Date', 'Hour'], \n",
    "                                    how='inner')\n",
    "\n",
    "# Display the merged dataframe\n",
    "print(df_merged.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_rename={'temperature_2m': 'TÂ°(CÂ°)',  'relative_humidity_2m': 'Relative Humidity (%)',\n",
    " 'dew_point_2m': 'Dew Point (Â°C)', 'precipitation': 'Precipitation (mm)',  'pressure_msl':' Sea Level Pressure (hPa)', \n",
    " 'cloud_cover_low':'Low Clouds (%)', 'cloud_cover_mid' : 'Middle Clouds (%)',\t 'cloud_cover_high' : 'High Clouds (%)', \n",
    " 'visibility' : ' Visibility (%)',  'wind_direction': 'Wind Direction (Â°)',\n",
    " 'wind_speed': 'Wind Speed (km/h)','wind_gust': 'Wind Gusts (km/h)', 'wave_height': 'Wave Height (m)',  'average_wave_period': 'Average Wave Period (s)',\n",
    " 'dominant_wave_direction': 'Dominant Wave Direction (Â°)','pressure': 'Pressure (hPA)',\n",
    " 'air_temperature': 'Air TÂ°','water_temperature': 'Water TÂ°'}\n",
    "\n",
    "df_cleaned = rename_columns(df_cleaned, col_to_rename)\n",
    "df_cleaned = drop_columns_if_exist(df_cleaned,['soil_temperature_0cm','rain', 'showers', 'is_day', 'id_x', 'id_y','soil_moisture_0_to_1cm'])\n",
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÃ©cupÃ©rer les donnÃ©es de l'API\n",
    "vc_meteo_data = response.json()\n",
    "print(vc_meteo_data)  # VÃ©rifiez les donnÃ©es rÃ©cupÃ©rÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les donnÃ©es JSON en DataFrame\n",
    "df_vc_meteo = pd.json_normalize(vc_meteo_data, record_path=[\"days\", \"hours\"], meta=[\"days\"])\n",
    "\n",
    "# Afficher la premiÃ¨re ligne des donnÃ©es\n",
    "df_vc_meteo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion du timestamp en datetime\n",
    "df_vc_meteo[\"Date\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%Y-%m-%d\")\n",
    "df_vc_meteo[\"Hour\"] = pd.to_datetime(df_vc_meteo[\"datetimeEpoch\"], unit=\"s\").dt.strftime(\"%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©finir les dates de filtrage pour les 30 derniers jours\n",
    "today = datetime.now()\n",
    "thirty_days_ago = today - timedelta(days=30)\n",
    "\n",
    "# Convertir les dates en format YYYY-MM-DD\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "thirty_days_ago_str = thirty_days_ago.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les donnÃ©es des 30 derniers jours de df_vc_meteo\n",
    "df_test_last_month = df_vc_meteo[['Date', 'Hour', 'windspeed']]\n",
    "df_test_last_month = df_test_last_month[(df_test_last_month['Date'] >= thirty_days_ago_str) & \n",
    "                                        (df_test_last_month['Date'] <= today_str)]\n",
    "\n",
    "# Ajouter les colonnes Date et Hour Ã  df_42058\n",
    "df_42058.loc[:, 'Date'] = df_42058['Datetime'].dt.strftime(\"%Y-%m-%d\")\n",
    "df_42058.loc[:, 'Hour'] = df_42058['Datetime'].dt.strftime(\"%H\")\n",
    "\n",
    "# Filtrer les donnÃ©es des 30 derniers jours dans df_42058\n",
    "df_42058_last_month = df_42058[(df_42058['Date'] >= thirty_days_ago_str) & \n",
    "                                (df_42058['Date'] <= today_str)]\n",
    "\n",
    "# Fusionner les deux DataFrames sur Date et Hour\n",
    "df_test_merged = df_test_last_month.merge(df_42058_last_month[['Date', 'Hour', 'Wind Speed (km/h)', 'wind_speed_10m']], \n",
    "                                     on=['Date', 'Hour'], \n",
    "                                     how='inner')\n",
    "\n",
    "df_test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def handle_null_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "#     row_count = df.shape[0]\n",
    "    \n",
    "#     # Initialisation des listes pour suivre les colonnes supprimÃ©es\n",
    "#     removed_columns = []\n",
    "#     non_numeric_columns_to_drop = []\n",
    "    \n",
    "#     # Utiliser lambda et apply() pour calculer le nombre de valeurs nulles dans chaque colonne\n",
    "#     null_counts = df.apply(lambda col: int(col.isnull().sum()))  # Calculer le nombre de NaN par colonne\n",
    "    \n",
    "#     # Condition : 1. Colonnes avec toutes les valeurs nulles ou 2. Plus de 50% de valeurs nulles et colonne non numÃ©rique\n",
    "#     columns_to_drop = null_counts[\n",
    "#         (null_counts == row_count) | \n",
    "#         ((null_counts > row_count * 0.5) & ~df.apply(lambda col: pd.api.types.is_numeric_dtype(col)))\n",
    "#     ].index\n",
    "    \n",
    "#     # Ajouter les noms des colonnes supprimÃ©es dans les listes appropriÃ©es\n",
    "#     for col in columns_to_drop:\n",
    "#         if null_counts[col] == row_count:\n",
    "#             removed_columns.append(col)  # Colonnes entiÃ¨rement vides\n",
    "#         elif null_counts[col] > row_count * 0.5 and not pd.api.types.is_numeric_dtype(df[col]):\n",
    "#             non_numeric_columns_to_drop.append(col)  # Colonnes > 50% nulles et non numÃ©riques\n",
    "    \n",
    "#     # Supprimer les colonnes identifiÃ©es\n",
    "#     df = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "#     # Afficher les rÃ©sultats\n",
    "#     print(\"Colonnes supprimÃ©es pour avoir toutes les valeurs nulles:\")\n",
    "#     print(removed_columns)\n",
    "    \n",
    "#     print(\"\\nColonnes supprimÃ©es pour avoir plus de 50% de valeurs nulles et Ãªtre non numÃ©riques:\")\n",
    "#     print(non_numeric_columns_to_drop)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Exemple d'utilisation\n",
    "# # df_final = pd.read_csv('ton_fichier.csv') # Assure-toi que df_final est bien un DataFrame valide avant d'appeler la fonction\n",
    "# df_final = handle_null_values(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final = df_final.round(2)\n",
    "# print(df_final.columns)\n",
    "# df_final.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def explore_dict_keys(d, parent_key='', sep='_'):\n",
    "#     \"\"\"\n",
    "#     Explore un dictionnaire rÃ©cursivement pour obtenir toutes les clÃ©s, y compris les sous-clÃ©s,\n",
    "#     mais ne retourne pas les valeurs finales.\n",
    "\n",
    "#     :param d: Le dictionnaire Ã  explorer\n",
    "#     :param parent_key: La clÃ© parent qui est utilisÃ©e pour concatÃ©ner les sous-clÃ©s\n",
    "#     :param sep: Le sÃ©parateur utilisÃ© pour concatÃ©ner les clÃ©s (par dÃ©faut '_')\n",
    "#     :return: Une liste des clÃ©s (et sous-clÃ©s)\n",
    "#     \"\"\"\n",
    "#     keys = []\n",
    "#     for k, v in d.items():\n",
    "#         new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "#         if isinstance(v, dict):  # Si la valeur est un dictionnaire, on explore rÃ©cursivement\n",
    "#             keys.append(new_key)  # Ajouter la clÃ©, mais ne pas inclure la valeur\n",
    "#             keys.extend(explore_dict_keys(v, new_key, sep=sep))  # Continuer l'exploration\n",
    "#         else:\n",
    "#             keys.append(new_key)  # Ajouter la clÃ© finale\n",
    "#     return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_key_path(d, target_key, path=[]):\n",
    "#     \"\"\"\n",
    "#     Recherche rÃ©cursive d'une clÃ© dans un dictionnaire et retourne son chemin.\n",
    "#     :param d: dictionnaire\n",
    "#     :param target_key: clÃ© recherchÃ©e\n",
    "#     :param path: liste pour stocker le chemin jusqu'Ã  la clÃ©\n",
    "#     :return: chemin sous forme de liste\n",
    "#     \"\"\"\n",
    "#     if isinstance(d, dict):  # Si le dictionnaire est encore imbriquÃ©\n",
    "#         for key, value in d.items():\n",
    "#             new_path = path + [key]\n",
    "#             if key == target_key:\n",
    "#                 return new_path\n",
    "#             elif isinstance(value, dict):\n",
    "#                 result = find_key_path(value, target_key, new_path)\n",
    "#                 if result:  # Si la clÃ© est trouvÃ©e, retourner le chemin\n",
    "#                     return result\n",
    "#     return None  # Retourne None si la clÃ© n'a pas Ã©tÃ© trouvÃ©e\n",
    "\n",
    "\n",
    "\n",
    "# # Recherche du chemin pour la clÃ© 'marine_data'\n",
    "# path = find_key_path(table_dict, \"Marine Dataframe\")\n",
    "# print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto_convert Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, (buoy_id, tables) in enumerate(table_dict.items()):  # Utilisation de .items() pour obtenir (clÃ©, valeur)\n",
    "#     if isinstance(tables, dict):\n",
    "#         if idx == 1:  # VÃ©rifier si l'index est Ã©gal Ã  1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Rows of all Dataframes in total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
