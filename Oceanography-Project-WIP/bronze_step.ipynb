{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize PostgreSQL Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_postgresql_creds = r\"C:\\Users\\f.gionnane\\Documents\\Data Engineering\\Credentials\\postgresql_creds.json\"\n",
    "\n",
    "with open(path_postgresql_creds, 'r') as file:\n",
    "    content = json.load(file)\n",
    "    user = content[\"user\"]\n",
    "    password = content[\"password\"]\n",
    "    host = content[\"host\"]\n",
    "    port = content[\"port\"]\n",
    "\n",
    "db = \"Oceanography_ML_Project\"\n",
    "schema = \"Bronze\"\n",
    "\n",
    "# Cr√©er l'engine PostgreSQL\n",
    "engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{db}\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Available Stations ID List\n",
    "\n",
    "Filter Dysfunctional Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all stations and some metadata as a Pandas DataFrame\n",
    "stations_df = api.stations()\n",
    "# parse the response as a dictionary\n",
    "stations_df = api.stations(as_df=True)\n",
    "\n",
    "print(len(stations_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_error_url_list = []\n",
    "\n",
    "# Liste de mots √† rechercher dans la colonne \"Remark\"\n",
    "blacklist = [\"Failure\", \"ceased\", \"failed\", \"recovered\", \"stopped\", 'adrift']\n",
    "stations_id_set = set()\n",
    "\n",
    "print(f'Avant Filtre: {stations_df.shape[0]}')\n",
    "\n",
    "# Liste pour collecter les indices √† supprimer\n",
    "indices_a_supprimer = []\n",
    "\n",
    "# Parcours des lignes de la DataFrame\n",
    "for idx, row in stations_df.iterrows():\n",
    "    station_id = row[\"Station\"]\n",
    "    station_Location = row[\"Hull No./Config and Location\"]  # Extraire la valeur de la cellule pour chaque ligne\n",
    "    \n",
    "    # Extraction du nom de la station si un \")\" est trouv√©\n",
    "    if \")\" in station_Location:\n",
    "        station_name = station_Location.split(')')[1].rstrip(\" )\")  # On enl√®ve l'espace et la parenth√®se en fin de cha√Æne\n",
    "    else:\n",
    "        station_name = station_Location.strip()  # Si pas de \")\", on garde toute la cha√Æne\n",
    "\n",
    "    station_name = station_name.rstrip(\" )\").replace(\"(\", \"\").replace(\")\", \"\").strip()\n",
    "\n",
    "    # Nettoyage final pour enlever toute parenth√®se ou espace en fin de nom\n",
    "    station_name = station_name.rstrip(\" )\")\n",
    "\n",
    "    # V√©rifier si \"Remark\" n'est pas NaN et si un des √©l√©ments de blacklist est dans \"Remark\"\n",
    "    if isinstance(row[\"Remark\"], str) and any(blacklist_word.lower() in row[\"Remark\"].lower() for blacklist_word in blacklist):\n",
    "        # Ajouter l'index √† la liste\n",
    "        indices_a_supprimer.append(idx)\n",
    "    else:\n",
    "        try:\n",
    "            # Effectuer l'appel API\n",
    "            buoy_data = NDBC.realtime_observations(station_id)\n",
    "            \n",
    "            # V√©rifier si les donn√©es de l'API sont valides (si le DataFrame n'est pas vide)\n",
    "            if not buoy_data.empty:\n",
    "                print(f'Buoy {station_id}: {station_name} passed the Remarks and API Test!')\n",
    "                stations_id_set.add(station_id)\n",
    "            else:\n",
    "                print(f'Buoy {station_id}: {station_name} did not return valid data. Deleting.')\n",
    "                indices_a_supprimer.append(idx)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Si l'erreur est un HTTPError, on peut essayer d'afficher le code d'erreur\n",
    "            if isinstance(e, HTTPError):\n",
    "                print(f'Buoy {station_id}: {station_name} API Call returned {e.code}. Deleting.')\n",
    "            else:\n",
    "                # Dans tous les autres cas d'exception, on affiche le message d'erreur complet\n",
    "                print(f'Buoy {station_id}: {station_name} API Call encountered an error. Deleting.')\n",
    "                \n",
    "                if str(e).startswith(\"Error accessing\"):\n",
    "                    url = f\"https://www.ndbc.noaa.gov/station_page.php?station={station_id}\"\n",
    "                    access_error_url_list.append([station_id, url])\n",
    "            # Ajouter l'index √† la liste en cas d'erreur\n",
    "            indices_a_supprimer.append(idx)\n",
    "\n",
    "# Supprimer les lignes apr√®s la boucle\n",
    "stations_df.drop(index=indices_a_supprimer, inplace=True)\n",
    "\n",
    "print(f'Apr√®s Filtre: {stations_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in access_error_url_list:\n",
    "    print(f\"Access error for buoy {item[0]}\")\n",
    "    print(f\"{item[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing get_station_metadata and parse_buoy_json Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parcourir les lignes du DataFrame\n",
    "for idx, row in stations_df.iterrows():\n",
    "    station_id_from_df = row[\"Station\"]  # Renommer la variable ici\n",
    "    metadata = get_station_metadata(station_id_from_df)\n",
    "    print(f\"Metadata pour la station {station_id_from_df}: {metadata}\")  # V√©rification de la valeur de metadata\n",
    "    Name = metadata[\"Name\"]\n",
    "    # Changer le nom de la variable retourn√©e par parse_buoy_json\n",
    "    parsed_station_id, station_zone, lat_buoy, lon_buoy = parse_buoy_json(metadata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in metadata.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_check=[]\n",
    "\n",
    "# stations_sans_zone = [\n",
    "#     \"44020\",\n",
    "#     \"46072\",\n",
    "#     \"BURL1\",\n",
    "#     \"FFIA2\",\n",
    "#     \"LONF1\",\n",
    "#     \"MDRM1\",\n",
    "#     \"MRKA2\",\n",
    "#     \"POTA2\",\n",
    "#     \"SANF1\",\n",
    "#     \"SBIO1\"\n",
    "# ]\n",
    "\n",
    "# # Parcourir les lignes du DataFrame\n",
    "# for id in stations_sans_zone:\n",
    "#     metadata = get_station_metadata(id)\n",
    "#     Name = metadata[\"Name\"]\n",
    "\n",
    "#     station_id, station_zone, lat_buoy, lon_buoy, marine_data_table_name = parse_buoy_json(metadata)\n",
    "#     message = f\"Station {station_id}: \\nNom: {Name}\\nZone: {station_zone}\"\n",
    "#     list_check.append(message)\n",
    "\n",
    "# for msg in list_check:\n",
    "#     print(f\"{msg}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Dictionary of Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker les DataFrames, cl√© : ID de la bou√©e, valeur : DataFrame\n",
    "buoy_datas = {}\n",
    "buoy_list = []\n",
    "\n",
    "# Parcours de chaque bou√©e dans stations_df\n",
    "for index, row in stations_df.iterrows():\n",
    "    buoy_id = row['Station']\n",
    "\n",
    "    metadata = get_station_metadata(buoy_id)  # Utilise buoy_id au lieu de station_id_from_df\n",
    "    # Changer le nom de la variable retourn√©e par parse_buoy_json\n",
    "    parsed_station_id, station_zone, lat_buoy, lon_buoy = parse_buoy_json(metadata)\n",
    "\n",
    "    # Initialiser le dictionnaire pour chaque bou√©e s'il n'est pas encore cr√©√©\n",
    "    if buoy_id not in buoy_datas:\n",
    "        buoy_datas[buoy_id] = {}\n",
    "\n",
    "    # Ajouter les informations de la bou√©e\n",
    "    buoy_datas[buoy_id][\"Zone\"] = station_zone\n",
    "    buoy_datas[buoy_id][\"Lat\"] = lat_buoy\n",
    "    buoy_datas[buoy_id][\"Lon\"] = lon_buoy\n",
    "\n",
    "    # Ajouter la bou√©e √† la liste\n",
    "    buoy_list.append(buoy_id)\n",
    "\n",
    "# Affichage du nombre de bou√©es r√©ussies et √©chou√©es\n",
    "print(f\"Nombre de bou√©es trait√©es : {len(buoy_datas)}\\n\")\n",
    "\n",
    "# Afficher le contenu de buoy_datas\n",
    "buoy_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_problem = 46072\n",
    "metadata = get_station_metadata(id_problem)  # Utilise buoy_id au lieu de station_id_from_df\n",
    "    # Changer le nom de la variable retourn√©e par parse_buoy_json\n",
    "parsed_station_id, station_zone, lat_buoy, lon_buoy = parse_buoy_json(metadata)\n",
    "\n",
    "print(f'{metadata}\\n {lat_buoy}\\n {lon_buoy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir le dictionnaire en DataFrame, en utilisant 'buoy_id' comme index\n",
    "df_buoy_datas = pd.DataFrame.from_dict(buoy_datas, orient='index')\n",
    "\n",
    "# R√©initialiser l'index et renommer la colonne\n",
    "df_buoy_datas = df_buoy_datas.reset_index(drop=False)\n",
    "df_buoy_datas.rename(columns={\"index\": \"Station ID\"}, inplace=True)\n",
    "\n",
    "# Charger les donn√©es dans la table\n",
    "try:\n",
    "    load_data_in_table(conn=conn, schema=schema, df=df_buoy_datas, table_name=\"buoy_datas\", key_column=\"Station ID\")\n",
    "    print(\"Donn√©es charg√©es avec succ√®s dans la table 'buoy_datas'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des donn√©es : {e}\")\n",
    "\n",
    "# Affichage du DataFrame\n",
    "df_buoy_datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_coords=[]\n",
    "\n",
    "for id in buoy_list:\n",
    "    metadata = get_station_metadata(id)\n",
    "    \n",
    "    station_id, station_zone, lat_buoy, lon_buoy = parse_buoy_json(metadata)\n",
    "    lat_buoy, lon_buoy = convert_coordinates(lat_buoy,lon_buoy)\n",
    "    coords = [station_id, station_zone, lat_buoy, lon_buoy]\n",
    "    list_coords.append(coords)\n",
    "\n",
    "def barycentre(coords):\n",
    "    x_coords = [item[2] for item in coords]\n",
    "    y_coords = [item[3] for item in coords]\n",
    "\n",
    "    x_barycentre = sum(x_coords) / len(coords)\n",
    "    y_barycentre = sum(y_coords) / len(coords)\n",
    "\n",
    "    return [x_barycentre, y_barycentre]\n",
    "\n",
    "# Exemple d'utilisation\n",
    "coords = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "centre = barycentre(list_coords)\n",
    "print(list_coords)\n",
    "print(\"Coordonn√©es du barycentre :\", centre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=(centre[0],centre[1]), \n",
    "                 tiles=\"Esri.WorldImagery\", \n",
    "                 zoom_start=2.5, attr=\"Donn√©es fournies par Esri\")\n",
    "for loc in list_coords:\n",
    "    lat = loc[2]\n",
    "    lon = loc[3]\n",
    "    station_id = loc[0]\n",
    "    station_zone = loc[1]\n",
    "    folium.Marker(\n",
    "    location=[lat, lon],\n",
    "    popup=f\"Station ID: {station_id}\\n\\nZone: {station_zone}\\nLat: {lat}\\n\\nLon: {lon}\",\n",
    "    icon=folium.Icon(icon=\"cloud\"),\n",
    ").add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns Check Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = random.choice(buoy_list)\n",
    "choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marine_test = NDBC.realtime_observations(choice)\n",
    "print(f'{df_marine_test.shape[0]} rows \\n\\n{df_marine_test.isna().sum()}')\n",
    "df_marine_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check test API Open-Meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meteo_test = meteo_api_request(coordinates=[12, 23])\n",
    "print(f'{df_meteo_test.shape[0]} rows \\n{df_meteo_test.isna().sum()}')\n",
    "df_meteo_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_extracted = get_station_metadata(choice)\n",
    "metadata_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id, station_zone, lat_buoy, lon_buoy = parse_buoy_json(metadata_extracted)\n",
    "print(f'{station_name}\\n{station_id}\\n{station_zone}\\n{lat_buoy}\\n{lon_buoy}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big API Call Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = {}\n",
    "\n",
    "# D√©finir le dossier o√π sauvegarder les fichiers\n",
    "marine_output_dir = r\"marine_tables\"\n",
    "meteo_output_dir = r\"meteo_tables\"\n",
    "# S'assurer que le dossier existe (le cr√©er s'il n'existe pas)\n",
    "os.makedirs(marine_output_dir, exist_ok=True)\n",
    "os.makedirs(meteo_output_dir, exist_ok=True)\n",
    "\n",
    "count = 1\n",
    "total = len(buoy_datas)\n",
    "for buoy_id in buoy_datas:  # Boucle sur les bou√©es dans le dictionnaire\n",
    "    dict_df[buoy_id] = {}\n",
    "\n",
    "    # R√©cup√©rer les m√©tadonn√©es de la bou√©e\n",
    "    metadata_extracted = get_station_metadata(buoy_id)\n",
    "    \n",
    "    station_id, station_zone, lat_buoy, lon_buoy = parse_buoy_json(metadata_extracted)\n",
    "    \n",
    "    buoy_datas[buoy_id][\"Station Name\"] = station_name\n",
    "    buoy_datas[buoy_id][\"Station ID\"] = station_id\n",
    "    buoy_datas[buoy_id][\"Zone\"] = station_zone\n",
    "    buoy_datas[buoy_id][\"Lat\"] = lat\n",
    "    buoy_datas[buoy_id][\"Lon\"] = lon\n",
    "\n",
    "    Bronze_Marine_Table_Name =f\"station_{station_id}_marine_data_{station_zone}\"\n",
    "    Bronze_Marine_Table_Name = Bronze_Marine_Table_Name.replace('.', '_').replace('-', '_')\n",
    "\n",
    "    Bronze_Meteo_Table_Name =f\"station_{station_id}_meteo_data_{station_zone}\"\n",
    "    Bronze_Meteo_Table_Name = Bronze_Meteo_Table_Name.replace('.', '_').replace('-', '_')\n",
    "\n",
    "    # Construire le chemin complet du fichier\n",
    "    marine_csv_path = os.path.join(marine_output_dir, Bronze_Marine_Table_Name + \".csv\")\n",
    "    meteo_csv_path = os.path.join(meteo_output_dir, Bronze_Meteo_Table_Name + \".csv\")\n",
    "\n",
    "    duo = [Bronze_Marine_Table_Name, Bronze_Meteo_Table_Name]\n",
    "\n",
    "    print(f\"\\n{'='*50}\\nIteration: {count}/{total} | Bou√©e ID: {buoy_id}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # NOAA API CALL\n",
    "    try:\n",
    "        df_marine = NDBC.realtime_observations(buoy_id)\n",
    "        \n",
    "        if df_marine is None or df_marine.empty:\n",
    "            print(f\"‚ö†Ô∏è Marine Data is empty for buoy {buoy_id}\")\n",
    "        else: \n",
    "            df_marine[\"Station ID\"] = buoy_id\n",
    "            buoy_datas[buoy_id][\"Marine Dataframe\"] = df_marine\n",
    "            print(f\"üåä Marine Data Successfully collected for buoy {buoy_id}\")\n",
    "            dict_df[buoy_id][\"Marine DataFrame\"] = df_marine\n",
    "            df_marine.to_csv(marine_csv_path , mode='w', index=True, index_label=\"time\")\n",
    "\n",
    "            load_data_in_table(conn, schema, table_name=Bronze_Marine_Table_Name, df=df_marine, key_column=\"time\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to collect Marine Data for buoy {buoy_id}: \\n{e}\\n\")\n",
    "        \n",
    "    # Open-Meteo API Call \n",
    "    try:\n",
    "        df_meteo = meteo_api_request(coordinates=[lat, lon])\n",
    "        if df_meteo is None or df_meteo.empty:\n",
    "            print(f\"‚ö†Ô∏è Meteo Data is empty for buoy {buoy_id}\")\n",
    "        else:\n",
    "            buoy_datas[buoy_id][\"Meteo DataFrame\"] = df_meteo\n",
    "            print(f\"üå¶Ô∏è Meteo Data Successfully collected for buoy {buoy_id}\")\n",
    "            dict_df[buoy_id][\"Meteo DataFrame\"] = df_meteo\n",
    "            df_meteo.to_csv(meteo_csv_path , mode='w', index=True, index_label=\"date\")\n",
    "\n",
    "            load_data_in_table(conn, schema, table_name=Bronze_Meteo_Table_Name, df=df_meteo, key_column=\"date\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Bou√©e {buoy_id} : Erreur √† l'insertion des donn√©es:\\n{e}\\n\")\n",
    "\n",
    "    count += 1\n",
    "\n",
    "# Final summary\n",
    "print('\\n' + '='*50)\n",
    "list_tables_info(conn=conn, schema=schema)\n",
    "print('\\n' + '='*50)\n",
    "count_files_in_directory(meteo_output_dir)\n",
    "print('\\n' + '='*50)\n",
    "count_files_in_directory(marine_output_dir)\n",
    "\n",
    "text = \"Processus Bronze Du Projet Oceanography ML termin√© !\"\n",
    "show_popup(text=text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_schema_force(schema_name=schema,conn=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def explore_dict(d, indent=0):\n",
    "#     \"\"\" Fonction r√©cursive pour afficher toute la structure du dictionnaire \"\"\"\n",
    "#     for key, value in d.items():\n",
    "#         print(\" \" * indent + f\"- {key}: {type(value)}\")\n",
    "#         if isinstance(value, dict):\n",
    "#             explore_dict(value, indent + 4)  # Explorer r√©cursivement avec une indentation\n",
    "#         elif isinstance(value, list):\n",
    "#             if len(value) > 0:\n",
    "#                 print(\" \" * (indent + 4) + f\"Liste ({len(value)} √©l√©ments), type du premier √©l√©ment: {type(value[0])}\")\n",
    "#                 if isinstance(value[0], dict):\n",
    "#                     explore_dict(value[0], indent + 8)  # Explorer si c'est une liste de dicts\n",
    "#         else:\n",
    "#             print(\" \" * (indent + 4) + f\"Valeur: {value}\")\n",
    "\n",
    "# # R√©cup√©rer la premi√®re cl√© du dictionnaire\n",
    "# first_key = next(iter(buoy_datas))\n",
    "# print(f\"Exploration de la premi√®re cl√©: {first_key}\\n\")\n",
    "\n",
    "# # Ex√©cuter la fonction sur le premier √©l√©ment uniquement\n",
    "# explore_dict({first_key: buoy_datas[first_key]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openmongo_creds = r'C:\\Users\\f.gionnane\\Documents\\Data Engineering\\Credentials\\mongo_creds.json'\n",
    "\n",
    "# with open(openmongo_creds, 'r') as file:\n",
    "#     content = json.load(file)\n",
    "#     mongo_user = content[\"user\"]\n",
    "#     mongo_password = content[\"password\"]\n",
    "#     mongo_string = content[\"connection_string\"]\n",
    "\n",
    "# uri = mongo_string\n",
    "# # Create a new client and connect to the server\n",
    "# client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# # Send a ping to confirm a successful connection\n",
    "# try:\n",
    "#     client.admin.command('ping')\n",
    "#     print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "#     print(f'{mongo_user}\\n{mongo_password}\\n{mongo_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier GeoJSON depuis l'URL\n",
    "url = \"https://gist.githubusercontent.com/jrrickard/8755532505a40f3b8317/raw/ecd98849d3a5f4502b773b986254f19af3b8d8fb/oceans.json\"\n",
    "geojson_data = requests.get(url).json()\n",
    "\n",
    "# Cr√©er une carte avec un fond satellite ESRI\n",
    "m = folium.Map(location=[0, 0], zoom_start=3, tiles=\"Esri.WorldImagery\")\n",
    "\n",
    "# Ajouter le GeoJSON (les oc√©ans) √† la carte\n",
    "folium.GeoJson(geojson_data, name=\"Oceans\").add_to(m)\n",
    "\n",
    "# Fonction pour g√©n√©rer des coordonn√©es al√©atoires dans l'oc√©an\n",
    "def random_ocean_coords():\n",
    "    lat = random.uniform(-60, 60)  # Latitude dans les eaux de l'oc√©an\n",
    "    lon = random.uniform(-180, 180)  # Longitude dans les eaux de l'oc√©an\n",
    "    return lat, lon\n",
    "\n",
    "# G√©n√©rer un DataFrame avec des coordonn√©es, temp√©ratures, hauteur des vagues, vitesse du vent, etc.\n",
    "data = {\n",
    "    \"Coordinates\": [],\n",
    "    \"Temperature (¬∞C)\": [],\n",
    "    \"Wave Height (m)\": [],\n",
    "    \"Wind Speed (km/h)\": []\n",
    "}\n",
    "\n",
    "# G√©n√©rer 10 marqueurs avec des valeurs al√©atoires\n",
    "for _ in range(10):\n",
    "    lat, lon = random_ocean_coords()\n",
    "    \n",
    "    # G√©n√©rer des valeurs al√©atoires pour la temp√©rature, la hauteur des vagues et la vitesse du vent\n",
    "    temperature = random.uniform(15, 30)  # Temp√©rature entre 15 et 30¬∞C\n",
    "    wave_height = random.uniform(0.5, 5)  # Hauteur des vagues entre 0.5m et 5m\n",
    "    wind_speed = random.uniform(10, 50)  # Vitesse du vent entre 10 km/h et 50 km/h\n",
    "    \n",
    "    # Ajouter ces valeurs dans le DataFrame\n",
    "    data[\"Coordinates\"].append((lat, lon))\n",
    "    data[\"Temperature (¬∞C)\"].append(temperature)\n",
    "    data[\"Wave Height (m)\"].append(wave_height)\n",
    "    data[\"Wind Speed (km/h)\"].append(wind_speed)\n",
    "\n",
    "# Cr√©er un DataFrame pandas avec ces donn√©es\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ajouter les marqueurs et cercles √† la carte avec des couleurs d√©pendant de la temp√©rature\n",
    "for index, row in df.iterrows():\n",
    "    lat, lon = row[\"Coordinates\"]\n",
    "    temperature = row[\"Temperature (¬∞C)\"]\n",
    "    \n",
    "    # D√©terminer la couleur du cercle en fonction de la temp√©rature\n",
    "    if temperature < 20:\n",
    "        fill_color = \"blue\"\n",
    "    elif temperature < 25:\n",
    "        fill_color = \"green\"\n",
    "    else:\n",
    "        fill_color = \"red\"\n",
    "    \n",
    "    # Ajouter un marqueur\n",
    "    folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
    "    ).add_to(m)\n",
    "    \n",
    "    # Ajouter un cercle autour du marqueur\n",
    "    folium.CircleMarker(\n",
    "        location=[lat, lon],\n",
    "        radius=15,  # Rayon du cercle\n",
    "        color=\"black\",\n",
    "        fill=True,\n",
    "        fill_color=fill_color,\n",
    "        fill_opacity=0.5\n",
    "    ).add_to(m)\n",
    "\n",
    "# Ajouter une couche de contr√¥le pour la carte\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Sauvegarder la carte dans un fichier HTML\n",
    "m.save(\"ocean_markers_map.html\")\n",
    "\n",
    "# Affichage de la carte dans l'environnement interactif (si vous √™tes dans un environnement Jupyter)\n",
    "m\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
