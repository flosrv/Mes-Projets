{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier téléchargé avec succès : data\\Affinity - City - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\Affinity - County - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\Affinity - National - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\Affinity - State - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\Affinity Daily Total Spending - National.csv\n",
      "Fichier téléchargé avec succès : data\\Affinity Income Shares - National - 2019.csv\n",
      "Fichier téléchargé avec succès : data\\Affinity Income Shares - National - 2020.csv\n",
      "Fichier téléchargé avec succès : data\\Affinity Industry Composition - National - 2020.csv\n",
      "Fichier téléchargé avec succès : data\\COVID - City - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\COVID - County - Daily 2020.csv\n",
      "Fichier téléchargé avec succès : data\\COVID - County - Daily 2023.csv\n",
      "Fichier téléchargé avec succès : data\\COVID - National - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\COVID - State - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\Earnin - ZCTA - 2020.csv\n",
      "Fichier téléchargé avec succès : data\\Employment - City - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Employment - County - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Employment - National - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Employment - State - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\GeoIDs - City.csv\n",
      "Fichier téléchargé avec succès : data\\GeoIDs - County.csv\n",
      "Fichier téléchargé avec succès : data\\GeoIDs - State.csv\n",
      "Fichier téléchargé avec succès : data\\Google Mobility - City - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\Google Mobility - National - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\Google Mobility - State - Daily.csv\n",
      "Fichier téléchargé avec succès : data\\Job Postings - City - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Job Postings - County - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Job Postings - National - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Job Postings - State - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Job Postings Industry Shares - National - 2020.csv\n",
      "Fichier téléchargé avec succès : data\\Policy Milestones - State.csv\n",
      "Fichier téléchargé avec succès : data\\UI Claims - City - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\UI Claims - County - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\UI Claims - National - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\UI Claims - State - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Womply - City - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Womply - County - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Womply - National - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Womply - State - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Womply - ZCTA - 2020.csv\n",
      "Fichier téléchargé avec succès : data\\Zearn - City - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Zearn - County - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Zearn - National - Weekly.csv\n",
      "Fichier téléchargé avec succès : data\\Zearn - State - Weekly.csv\n"
     ]
    }
   ],
   "source": [
    "repo_url = \"https://api.github.com/repos/OpportunityInsights/EconomicTracker/contents/data\"\n",
    "\n",
    "# Fonction pour télécharger les fichiers depuis un dossier GitHub, avec des filtres de formats\n",
    "def download_files_from_github(repo_url, download_folder=\"destination\",file_formats=None):\n",
    "    \"\"\"\n",
    "    Télécharge les fichiers depuis un dossier GitHub en filtrant par extension de fichier.\n",
    "    \n",
    "    :param repo_url: URL API GitHub pour accéder au contenu d'un dossier\n",
    "    :param file_formats: Liste ou string d'extensions de fichiers à télécharger (par exemple: ['.csv', '.json']),\n",
    "                          Si None, tous les fichiers seront téléchargés.\n",
    "    :param download_folder: Dossier où les fichiers seront stockés localement.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Créer le dossier de destination si nécessaire\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "    \n",
    "    # Fonction pour télécharger un fichier depuis une URL\n",
    "    def download_file(url, file_path):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Fichier téléchargé avec succès : {file_path}\")\n",
    "        else:\n",
    "            print(f\"Erreur lors du téléchargement de {file_path}, code : {response.status_code}\")\n",
    "    \n",
    "    # Récupérer la liste des fichiers dans le dossier GitHub\n",
    "    response = requests.get(repo_url)\n",
    "    if response.status_code == 200:\n",
    "        files = response.json()\n",
    "        \n",
    "        # Si file_formats est une string, la convertir en liste\n",
    "        if isinstance(file_formats, str):\n",
    "            file_formats = [file_formats]\n",
    "        \n",
    "        # Télécharger uniquement les fichiers filtrés et ceux qui ne sont pas déjà présents\n",
    "        for file in files:\n",
    "            file_name = file['name']\n",
    "            file_download_url = file['download_url']\n",
    "            file_extension = os.path.splitext(file_name)[1]\n",
    "            \n",
    "            # Vérifier si l'extension de fichier est acceptée, ou si aucun filtre n'est spécifié\n",
    "            if file_formats is None or file_extension in file_formats:\n",
    "                file_path = os.path.join(download_folder, file_name)\n",
    "                \n",
    "                # Si le fichier est déjà présent, l'ignorer\n",
    "                if not os.path.exists(file_path):\n",
    "                    download_file(file_download_url, file_path)\n",
    "                else:\n",
    "                    print(f\"Le fichier {file_name} existe déjà, il est ignoré.\")\n",
    "    else:\n",
    "        print(f\"Erreur lors de la récupération des fichiers : {response.status_code}\")\n",
    "\n",
    "# avec la fonction on collecte les data\n",
    "# on crée un dask dataframe à partir des données téléchargées\n",
    "# et on met chaque dataframe dans un dico dont le nom de la cle fait reference au nom du fichier\n",
    "#mais on check d'abord si les data sont déjà présentes\n",
    "\n",
    "download_files_from_github(repo_url, download_folder=\"data\", file_formats=['.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du dataframe de Affinity - City - Daily réussi\n",
      "Chargement du dataframe de Affinity - County - Daily réussi\n",
      "Chargement du dataframe de Affinity - National - Daily réussi\n",
      "Chargement du dataframe de Affinity - State - Daily réussi\n",
      "Chargement du dataframe de Affinity Daily Total Spending - National réussi\n",
      "Chargement du dataframe de Affinity Income Shares - National - 2019 réussi\n",
      "Chargement du dataframe de Affinity Income Shares - National - 2020 réussi\n",
      "Chargement du dataframe de Affinity Industry Composition - National - 2020 réussi\n",
      "Chargement du dataframe de COVID - City - Daily réussi\n",
      "Chargement du dataframe de COVID - County - Daily 2020 réussi\n",
      "Chargement du dataframe de COVID - County - Daily 2023 réussi\n",
      "Chargement du dataframe de COVID - National - Daily réussi\n",
      "Chargement du dataframe de COVID - State - Daily réussi\n",
      "Chargement du dataframe de Earnin - ZCTA - 2020 réussi\n",
      "Chargement du dataframe de Employment - City - Weekly réussi\n",
      "Chargement du dataframe de Employment - County - Weekly réussi\n",
      "Chargement du dataframe de Employment - National - Weekly réussi\n",
      "Chargement du dataframe de Employment - State - Weekly réussi\n",
      "Chargement du dataframe de GeoIDs - City réussi\n",
      "Chargement du dataframe de GeoIDs - County réussi\n",
      "Chargement du dataframe de GeoIDs - State réussi\n",
      "Chargement du dataframe de Google Mobility - City - Daily réussi\n",
      "Chargement du dataframe de Google Mobility - National - Daily réussi\n",
      "Chargement du dataframe de Google Mobility - State - Daily réussi\n",
      "Chargement du dataframe de Job Postings - City - Weekly réussi\n",
      "Chargement du dataframe de Job Postings - County - Weekly réussi\n",
      "Chargement du dataframe de Job Postings - National - Weekly réussi\n",
      "Chargement du dataframe de Job Postings - State - Weekly réussi\n",
      "Chargement du dataframe de Job Postings Industry Shares - National - 2020 réussi\n",
      "Chargement du dataframe de Policy Milestones - State réussi\n",
      "Chargement du dataframe de UI Claims - City - Weekly réussi\n",
      "Chargement du dataframe de UI Claims - County - Weekly réussi\n",
      "Chargement du dataframe de UI Claims - National - Weekly réussi\n",
      "Chargement du dataframe de UI Claims - State - Weekly réussi\n",
      "Chargement du dataframe de Womply - City - Weekly réussi\n",
      "Chargement du dataframe de Womply - County - Weekly réussi\n",
      "Chargement du dataframe de Womply - National - Weekly réussi\n",
      "Chargement du dataframe de Womply - State - Weekly réussi\n",
      "Chargement du dataframe de Womply - ZCTA - 2020 réussi\n",
      "Chargement du dataframe de Zearn - City - Weekly réussi\n",
      "Chargement du dataframe de Zearn - County - Weekly réussi\n",
      "Chargement du dataframe de Zearn - National - Weekly réussi\n",
      "Chargement du dataframe de Zearn - State - Weekly réussi\n"
     ]
    }
   ],
   "source": [
    "files_dict = {}\n",
    "\n",
    "for file_name in os.listdir(\"data\"):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        #verification si le dataframe existe déjà\n",
    "        if file_name not in files_dict:\n",
    "            #virer l'extension pour le nom de la clé\n",
    "            file_name_for_dict = file_name.split(\".\")[0]\n",
    "            \n",
    "            files_dict[file_name_for_dict] = dd.read_csv(os.path.join(\"data\", file_name))\n",
    "            \n",
    "            print(f\"Chargement du dataframe de {file_name_for_dict} réussi\")\n",
    "        else : \n",
    "            print(f\"Le dataframe de {file_name_for_dict} existe déjà, il n'est pas chargé\")\n",
    "\n",
    "    if file_name.endswith(\".csv.gz\"):\n",
    "        # verification si le dataframe existe déjà\n",
    "        if file_name not in files_dict:\n",
    "            #virer l'extension pour le nom de la clé\n",
    "            file_name_for_dict = file_name.split(\".\")[0]\n",
    "            files_dict[file_name_for_dict] = dd.read_csv(os.path.join(\"data\", file_name), compression='gzip')\n",
    "            print(f\"Chargement du dataframe de {file_name} réussi\")\n",
    "        else:\n",
    "            print(f\"Le dataframe de {file_name} existe déjà, il n'est pas chargé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 24 entries, year to provisional\n",
      "dtypes: int64(5), string(19)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAffinity - City - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 7 entries, year to provisional\n",
      "dtypes: int64(5), string(2)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAffinity - County - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 142 entries, year to provisional\n",
      "dtypes: int64(4), string(138)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAffinity - National - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 29 entries, year to provisional\n",
      "dtypes: int64(5), string(24)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAffinity - State - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 8 entries, day to daily_spend_19_q4\n",
      "dtypes: float64(5), int64(3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAffinity Daily Total Spending - National\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 2 entries, income_quartile to share_jan2019\n",
      "dtypes: float64(1), int64(1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAffinity Income Shares - National - 2019\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 2 entries, income_quartile to share_jan2020\n",
      "dtypes: float64(1), int64(1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAffinity Income Shares - National - 2020\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 3 entries, industry to share_jan2020\n",
      "dtypes: float64(2), string(1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAffinity Industry Composition - National - 2020\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 28 entries, year to booster_first_rate\n",
      "dtypes: int64(4), string(24)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nCOVID - City - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 28 entries, year to booster_first_rate\n",
      "dtypes: int64(5), string(23)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nCOVID - County - Daily 2020\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 28 entries, year to booster_first_rate\n",
      "dtypes: float64(6), int64(18), string(4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nCOVID - County - Daily 2023\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 29 entries, year to hospitalized_rate\n",
      "dtypes: int64(5), string(24)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nCOVID - National - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 30 entries, year to hospitalized_rate\n",
      "dtypes: int64(6), string(24)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nCOVID - State - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 3 entries, zcta to emp_incq1_jul2020\n",
      "dtypes: float64(1), int64(1), string(1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nEarnin - ZCTA - 2020\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 12 entries, year to emp_incabovemed\n",
      "dtypes: float64(8), int64(4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nEmployment - City - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 12 entries, year to emp_incabovemed\n",
      "dtypes: int64(4), string(8)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nEmployment - County - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 27 entries, year to emp_ss70\n",
      "dtypes: float64(24), int64(3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nEmployment - National - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 16 entries, year to emp_ss70\n",
      "dtypes: float64(12), int64(4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nEmployment - State - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 8 entries, cityid to city_pop2019\n",
      "dtypes: float64(2), int64(3), string(3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nGeoIDs - City\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 10 entries, countyfips to county_pop2019\n",
      "dtypes: float64(2), int64(4), string(4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nGeoIDs - County\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 4 entries, statefips to state_pop2019\n",
      "dtypes: int64(2), string(2)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nGeoIDs - State\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 11 entries, year to gps_away_from_home\n",
      "dtypes: float64(7), int64(4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nGoogle Mobility - City - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 10 entries, year to gps_away_from_home\n",
      "dtypes: float64(7), int64(3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nGoogle Mobility - National - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 11 entries, year to gps_away_from_home\n",
      "dtypes: float64(7), int64(4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nGoogle Mobility - State - Daily\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 17 entries, year to bg_posts_jz5\n",
      "dtypes: int64(4), string(13)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nJob Postings - City - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 7 entries, year to bg_posts_jzgrp345\n",
      "dtypes: int64(4), string(3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nJob Postings - County - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 16 entries, year to bg_posts_jz5\n",
      "dtypes: float64(13), int64(3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nJob Postings - National - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 17 entries, year to bg_posts_jz5\n",
      "dtypes: int64(4), string(13)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nJob Postings - State - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 2 entries, industry to share_jan2020\n",
      "dtypes: float64(1), string(1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nJob Postings Industry Shares - National - 2020\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 7 entries, statefips to stayathome_first_start\n",
      "dtypes: int64(4), string(3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nPolicy Milestones - State\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 6 entries, year to initclaims_rate_regular\n",
      "dtypes: float64(1), int64(5)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nUI Claims - City - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 6 entries, year to initclaims_rate_regular\n",
      "dtypes: int64(4), string(2)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nUI Claims - County - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 17 entries, year to contclaims_rate_combined\n",
      "dtypes: float64(4), int64(13)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nUI Claims - National - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 18 entries, year to contclaims_rate_combined\n",
      "dtypes: float64(4), int64(14)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nUI Claims - State - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 6 entries, year to revenue_all\n",
      "dtypes: float64(2), int64(4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWomply - City - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 6 entries, year to revenue_all\n",
      "dtypes: float64(2), int64(4)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWomply - County - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 21 entries, year to merchants_inchigh\n",
      "dtypes: float64(18), int64(3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWomply - National - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 16 entries, year to revenue_retail\n",
      "dtypes: float64(4), int64(4), string(8)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWomply - State - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 3 entries, zcta to revenue_all_jul2020\n",
      "dtypes: float64(2), int64(1)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nWomply - ZCTA - 2020\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 8 entries, year to break_badges\n",
      "dtypes: float64(2), int64(4), string(2)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nZearn - City - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 9 entries, year to imputed_from_cz\n",
      "dtypes: float64(2), int64(5), string(2)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nZearn - County - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 19 entries, year to break_badges_incmiddle\n",
      "dtypes: float64(8), int64(3), string(8)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nZearn - National - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr.DataFrame'>\n",
      "Columns: 20 entries, year to break_badges_incmiddle\n",
      "dtypes: float64(4), int64(4), string(12)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nZearn - State - Weekly\\nNone'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in files_dict.items():\n",
    "    display(f\"\\n\\n{key}\\n{value.info()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "['Affinity - City - Daily.csv',\n",
    " 'Affinity - County - Daily.csv',\n",
    " 'Affinity - National - Daily.csv',\n",
    " 'Affinity - State - Daily.csv',\n",
    " 'Affinity Daily Total Spending - National.csv',\n",
    " 'Affinity Income Shares - National - 2019.csv',\n",
    " 'Affinity Income Shares - National - 2020.csv',\n",
    " 'Affinity Industry Composition - National - 2020.csv',\n",
    " 'COVID - City - Daily.csv',\n",
    " 'COVID - County - Daily 2020.csv',\n",
    " 'COVID - County - Daily 2023.csv',\n",
    " 'COVID - National - Daily.csv',\n",
    " 'COVID - State - Daily.csv',\n",
    " 'Earnin - ZCTA - 2020.csv',\n",
    " 'Employment - City - Weekly.csv',\n",
    " 'Employment - County - Weekly.csv',\n",
    " 'Employment - National - Weekly.csv',\n",
    " 'Employment - State - Weekly.csv',\n",
    " 'GeoIDs - City.csv',\n",
    " 'GeoIDs - County.csv',\n",
    " 'GeoIDs - State.csv',\n",
    " 'Google Mobility - City - Daily.csv',\n",
    " 'Google Mobility - National - Daily.csv',\n",
    " 'Google Mobility - State - Daily.csv',\n",
    " 'Job Postings - City - Weekly.csv',\n",
    " 'Job Postings - County - Weekly.csv',\n",
    " 'Job Postings - National - Weekly.csv',\n",
    " 'Job Postings - State - Weekly.csv',\n",
    " 'Job Postings Industry Shares - National - 2020.csv',\n",
    " 'Policy Milestones - State.csv',\n",
    " 'UI Claims - City - Weekly.csv',\n",
    " 'UI Claims - County - Weekly.csv',\n",
    " 'UI Claims - National - Weekly.csv',\n",
    " 'UI Claims - State - Weekly.csv',\n",
    " 'Womply - City - Weekly.csv',\n",
    " 'Womply - County - Weekly.csv',\n",
    " 'Womply - National - Weekly.csv',\n",
    " 'Womply - State - Weekly.csv',\n",
    " 'Womply - ZCTA - 2020.csv',\n",
    " 'Zearn - City - Weekly.csv',\n",
    " 'Zearn - County - Weekly.csv',\n",
    " 'Zearn - National - Weekly.csv',\n",
    " 'Zearn - State - Weekly.csv']\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
