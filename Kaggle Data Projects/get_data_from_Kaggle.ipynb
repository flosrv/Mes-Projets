{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q kaggle\n",
    "%pip install -q kagglehub\n",
    "%pip install -q dask\n",
    "%pip install -q ipywidgets --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, requests\n",
    "import kagglehub, re, json, os\n",
    "import requests, subprocess\n",
    "import sys, time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentification réussie avec le fichier 'C:\\Credentials\\kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "# Définis le chemin du fichier kaggle.json\n",
    "path = r\"C:\\Credentials\\kaggle.json\"\n",
    "#json file : {\"username\":\"flosrv\",\"api_key\":\"44c79a4d5d1534092d24ee29f34e6ee3\"}\n",
    "# Charge les credentials depuis le fichier JSON\n",
    "with open(path, 'r') as file:\n",
    "    content = json.load(file)\n",
    "\n",
    "# Récupère les valeurs du fichier\n",
    "username = content[\"username\"]\n",
    "api_key = content[\"key\"]  # ⚠️ Assure-toi que la clé s'appelle bien \"key\" dans ton fichier JSON\n",
    "\n",
    "# ✅ Définis les variables d'environnement avant de les utiliser\n",
    "os.environ['KAGGLE_USERNAME'] = username\n",
    "os.environ['KAGGLE_KEY'] = api_key\n",
    "import kaggle\n",
    "from kaggle import KaggleApi\n",
    "from kaggle import api # import the already authenticated API client\n",
    "# 1. **Authentification avec Kaggle**\n",
    "def authenticate_kaggle():\n",
    "    # Vérifie si le fichier kaggle.json est dans le bon dossier\n",
    "    kaggle_json_path = os.path.expanduser(path)  # pour Linux/macOS\n",
    "    # Pour Windows, utilisez : os.path.expanduser(r'C:\\Users\\<Votre-Nom>\\.kaggle\\kaggle.json')\n",
    "\n",
    "    # Si le fichier n'existe pas, avertir l'utilisateur\n",
    "    if not os.path.exists(kaggle_json_path):\n",
    "        print(\"Le fichier 'kaggle.json' n'est pas trouvé. Téléchargez-le depuis votre compte Kaggle.\")\n",
    "        print(\"Assurez-vous de le placer dans le répertoire ~/.kaggle/ (Linux/macOS) ou C:\\\\Users\\\\<Your-Username>\\\\.kaggle\\\\ (Windows).\")\n",
    "        return False  # L'authentification échoue\n",
    "    else:\n",
    "        print(f\"Authentification réussie avec le fichier '{kaggle_json_path}'\")\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()  # Authentification avec le fichier 'kaggle.json'\n",
    "        return True\n",
    "\n",
    "try:\n",
    "    # Exécuter l'authentification\n",
    "    authenticate_kaggle()\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'authentification : {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\f.gionnane\\Downloads\\Mes-Projets\\Kaggle Data Projects\\data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions For Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lister les datasets correspondant à '['sales', 'marketing', 'customer', 'finance', 'supply chain', 'human resources', 'retail', 'ecommerce', 'operations', 'real estate']' :\n",
      "\n",
      "39 datasets trouvés.\n"
     ]
    }
   ],
   "source": [
    "def list_datasets(keyword=None, usability_min=None, min_mb=None, columns=None):\n",
    "    print(f\"Lister les datasets correspondant à '{keyword if keyword else 'tous les datasets'}' :\")\n",
    "    \n",
    "    \"\"\"\n",
    "    dataset metadata:\n",
    "    'id', 'ref', 'subtitle', 'creatorName', 'creatorUrl', 'totalBytes',\n",
    "        'url', 'lastUpdated', 'downloadCount', 'licenseName', 'description',\n",
    "        'ownerName', 'ownerRef', 'kernelCount', 'title', 'viewCount',\n",
    "        'voteCount', 'currentVersionNumber', 'usabilityRating', 'tags'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Traitement des mots-clés\n",
    "    if keyword:\n",
    "        if isinstance(keyword, str):\n",
    "            keyword = [keyword]\n",
    "        keyword = [re.escape(kw) for kw in keyword]\n",
    "\n",
    "    # Recherche des datasets via l'API Kaggle\n",
    "    datasets = []\n",
    "    for kw in keyword:\n",
    "        datasets.extend(api.dataset_list(search=kw))\n",
    "\n",
    "    result = []\n",
    "    for dataset in datasets:\n",
    "        dataset_dict = dataset.to_dict()  # Convertir le dataset en dictionnaire\n",
    "        \n",
    "        title = dataset_dict.get(\"title\", \"\")\n",
    "        ref = dataset_dict.get(\"ref\", \"\")\n",
    "        description = dataset_dict.get(\"description\", \"\")\n",
    "        lastUpdated = dataset_dict.get(\"lastUpdated\", \"\")\n",
    "        voteCount = dataset_dict.get(\"voteCount\", 0)\n",
    "        tags = dataset_dict.get(\"tags\", [])\n",
    "        usabilityRating = dataset_dict.get(\"usabilityRating\", 0)\n",
    "        size = dataset_dict.get(\"totalBytes\", 0)\n",
    "\n",
    "        # Convertir la taille en Mo\n",
    "        dataset_size = dataset_dict.get(\"totalBytes\", 0)\n",
    "        dataset_size_mb = dataset_size / (1024 * 1024)\n",
    "\n",
    "        # Filtrage selon la taille du dataset\n",
    "        if min_mb is not None and dataset_size_mb < min_mb:\n",
    "            continue\n",
    "\n",
    "        # Filtrage selon la note d'utilisabilité\n",
    "        if usability_min is not None and usabilityRating < usability_min:\n",
    "            continue\n",
    "\n",
    "        # Si des colonnes spécifiques sont demandées\n",
    "        if columns is not None:\n",
    "            dataset_dict = {key: dataset_dict[key] for key in columns if key in dataset_dict}\n",
    "\n",
    "        # Ajouter les informations dans le résultat\n",
    "        result_dict = {\n",
    "            \"title\": title,\n",
    "            \"ref\": ref,\n",
    "            \"description\": description,\n",
    "            \"lastUpdated\": lastUpdated,\n",
    "            \"voteCount\": voteCount,\n",
    "            \"tags\": tags,\n",
    "            \"usabilityRating\": usabilityRating,\n",
    "            \"dataset_size_mb\": round(dataset_size_mb,2),\n",
    "            \"Size (Mb)\" : round(dataset_dict.get(\"totalBytes\", 0) / (1024 * 1024),2)  # Conversion en Mo\n",
    "        }\n",
    "\n",
    "        result.append(result_dict)\n",
    "\n",
    "    # Création du DataFrame\n",
    "    df = pd.DataFrame(result)\n",
    "    \n",
    "    \n",
    "    print(f\"\\n{df.shape[0]} datasets trouvés.\")\n",
    "    return df\n",
    "\n",
    "keywords = [\n",
    "    \"sales\",          # Ventes : analyses de performance commerciale\n",
    "    \"marketing\",      # Campagnes, ROI, funnel, etc.\n",
    "    \"customer\",       # Données clients : segmentation, churn, satisfaction\n",
    "    \"finance\",        # Budgets, prévisions, états financiers\n",
    "    \"supply chain\",   # Logistique, stocks, prévision de demande\n",
    "    \"human resources\",# RH : turnover, performance, recrutement\n",
    "    \"retail\",         # Analyse de produits, points de vente, inventaire\n",
    "    \"ecommerce\",      # Données web, comportement d'achat, panier moyen\n",
    "    \"operations\",     # Optimisation de processus internes\n",
    "    \"real estate\"     # Immobilier : investissements, prévisions de prix\n",
    "]\n",
    "\n",
    "df_consulting_datasets =list_datasets(keyword=keywords, usability_min=0.6, min_mb=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lister les datasets correspondant à '['agriculture', 'food', 'farming', 'vegetable', 'livestock', 'dairy', 'poultry', 'meat', 'fruit', 'fruits', 'nuts', 'seeds', 'grains', 'cereals']' :\n",
      "\n",
      "89 datasets trouvés.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ref</th>\n",
       "      <th>description</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>tags</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>dataset_size_mb</th>\n",
       "      <th>Size (Mb)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agriculture crop images</td>\n",
       "      <td>aman2000jaiswal/agriculture-crop-images</td>\n",
       "      <td></td>\n",
       "      <td>2021-03-10T16:56:50.653Z</td>\n",
       "      <td>252</td>\n",
       "      <td>[{'ref': 'agriculture', 'name': 'agriculture',...</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>59.68</td>\n",
       "      <td>59.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agriculture Crop Yield</td>\n",
       "      <td>samuelotiattakorah/agriculture-crop-yield</td>\n",
       "      <td></td>\n",
       "      <td>2024-09-08T02:06:25.477Z</td>\n",
       "      <td>65</td>\n",
       "      <td>[{'ref': 'agriculture', 'name': 'agriculture',...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.42</td>\n",
       "      <td>33.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global Food &amp; Agriculture Statistics</td>\n",
       "      <td>unitednations/global-food-agriculture-statistics</td>\n",
       "      <td></td>\n",
       "      <td>2017-11-16T19:24:27.387Z</td>\n",
       "      <td>222</td>\n",
       "      <td>[{'ref': 'business', 'name': 'business', 'desc...</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>443.95</td>\n",
       "      <td>443.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Food Images (Food-101)</td>\n",
       "      <td>kmader/food41</td>\n",
       "      <td></td>\n",
       "      <td>2018-05-15T07:40:37.080Z</td>\n",
       "      <td>669</td>\n",
       "      <td>[{'ref': 'popular culture', 'name': 'popular c...</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>5430.04</td>\n",
       "      <td>5430.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Open Food Facts</td>\n",
       "      <td>openfoodfacts/world-food-facts</td>\n",
       "      <td></td>\n",
       "      <td>2017-09-18T12:27:58.027Z</td>\n",
       "      <td>1232</td>\n",
       "      <td>[{'ref': 'alcohol', 'name': 'alcohol', 'descri...</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>108.77</td>\n",
       "      <td>108.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0               Agriculture crop images   \n",
       "1                Agriculture Crop Yield   \n",
       "2  Global Food & Agriculture Statistics   \n",
       "3                Food Images (Food-101)   \n",
       "4                       Open Food Facts   \n",
       "\n",
       "                                                ref description  \\\n",
       "0           aman2000jaiswal/agriculture-crop-images               \n",
       "1         samuelotiattakorah/agriculture-crop-yield               \n",
       "2  unitednations/global-food-agriculture-statistics               \n",
       "3                                     kmader/food41               \n",
       "4                    openfoodfacts/world-food-facts               \n",
       "\n",
       "                lastUpdated  voteCount  \\\n",
       "0  2021-03-10T16:56:50.653Z        252   \n",
       "1  2024-09-08T02:06:25.477Z         65   \n",
       "2  2017-11-16T19:24:27.387Z        222   \n",
       "3  2018-05-15T07:40:37.080Z        669   \n",
       "4  2017-09-18T12:27:58.027Z       1232   \n",
       "\n",
       "                                                tags  usabilityRating  \\\n",
       "0  [{'ref': 'agriculture', 'name': 'agriculture',...         0.941176   \n",
       "1  [{'ref': 'agriculture', 'name': 'agriculture',...         1.000000   \n",
       "2  [{'ref': 'business', 'name': 'business', 'desc...         0.794118   \n",
       "3  [{'ref': 'popular culture', 'name': 'popular c...         0.812500   \n",
       "4  [{'ref': 'alcohol', 'name': 'alcohol', 'descri...         0.764706   \n",
       "\n",
       "   dataset_size_mb  Size (Mb)  \n",
       "0            59.68      59.68  \n",
       "1            33.42      33.42  \n",
       "2           443.95     443.95  \n",
       "3          5430.04    5430.04  \n",
       "4           108.77     108.77  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agriculture_keywords = [\"agriculture\", \"food\", \"farming\", \"vegetable\", \"livestock\", \"dairy\", \"poultry\", \"meat\", \"fruit\", \"fruits\",\"nuts\", \"seeds\", \n",
    "                        \"grains\", \"cereals\"]\n",
    "\n",
    "df_agriculture_datasets = list_datasets(keyword=agriculture_keywords, usability_min=0.6, min_mb=10)\n",
    "\n",
    "df_agriculture_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ref</th>\n",
       "      <th>description</th>\n",
       "      <th>lastUpdated</th>\n",
       "      <th>voteCount</th>\n",
       "      <th>tags</th>\n",
       "      <th>usabilityRating</th>\n",
       "      <th>dataset_size_mb</th>\n",
       "      <th>Size (Mb)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vehicle Sales Data</td>\n",
       "      <td>syedanwarafridi/vehicle-sales-data</td>\n",
       "      <td></td>\n",
       "      <td>2024-02-21T20:16:17.790Z</td>\n",
       "      <td>584</td>\n",
       "      <td>[{'ref': 'transportation', 'name': 'transporta...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.84</td>\n",
       "      <td>18.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telecom customer</td>\n",
       "      <td>abhinav89/telecom-customer</td>\n",
       "      <td></td>\n",
       "      <td>2017-08-27T03:01:50.747Z</td>\n",
       "      <td>207</td>\n",
       "      <td>[{'ref': 'business', 'name': 'business', 'desc...</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>13.57</td>\n",
       "      <td>13.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer Support on Twitter</td>\n",
       "      <td>thoughtvector/customer-support-on-twitter</td>\n",
       "      <td></td>\n",
       "      <td>2017-12-03T23:44:27.157Z</td>\n",
       "      <td>495</td>\n",
       "      <td>[{'ref': 'business', 'name': 'business', 'desc...</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>168.58</td>\n",
       "      <td>168.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US Funds dataset from Yahoo Finance</td>\n",
       "      <td>stefanoleone992/mutual-funds-and-etfs</td>\n",
       "      <td></td>\n",
       "      <td>2021-12-11T16:06:22.453Z</td>\n",
       "      <td>253</td>\n",
       "      <td>[{'ref': 'united states', 'name': 'united stat...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>353.34</td>\n",
       "      <td>353.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Massive Yahoo Finance Dataset</td>\n",
       "      <td>iveeaten3223times/massive-yahoo-finance-dataset</td>\n",
       "      <td></td>\n",
       "      <td>2023-11-29T17:24:31.693Z</td>\n",
       "      <td>52</td>\n",
       "      <td>[{'ref': 'research', 'name': 'research', 'desc...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.78</td>\n",
       "      <td>22.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0                   Vehicle Sales Data   \n",
       "1                     Telecom customer   \n",
       "2          Customer Support on Twitter   \n",
       "3  US Funds dataset from Yahoo Finance   \n",
       "4        Massive Yahoo Finance Dataset   \n",
       "\n",
       "                                               ref description  \\\n",
       "0               syedanwarafridi/vehicle-sales-data               \n",
       "1                       abhinav89/telecom-customer               \n",
       "2        thoughtvector/customer-support-on-twitter               \n",
       "3            stefanoleone992/mutual-funds-and-etfs               \n",
       "4  iveeaten3223times/massive-yahoo-finance-dataset               \n",
       "\n",
       "                lastUpdated  voteCount  \\\n",
       "0  2024-02-21T20:16:17.790Z        584   \n",
       "1  2017-08-27T03:01:50.747Z        207   \n",
       "2  2017-12-03T23:44:27.157Z        495   \n",
       "3  2021-12-11T16:06:22.453Z        253   \n",
       "4  2023-11-29T17:24:31.693Z         52   \n",
       "\n",
       "                                                tags  usabilityRating  \\\n",
       "0  [{'ref': 'transportation', 'name': 'transporta...         1.000000   \n",
       "1  [{'ref': 'business', 'name': 'business', 'desc...         0.705882   \n",
       "2  [{'ref': 'business', 'name': 'business', 'desc...         0.911765   \n",
       "3  [{'ref': 'united states', 'name': 'united stat...         1.000000   \n",
       "4  [{'ref': 'research', 'name': 'research', 'desc...         1.000000   \n",
       "\n",
       "   dataset_size_mb  Size (Mb)  \n",
       "0            18.84      18.84  \n",
       "1            13.57      13.57  \n",
       "2           168.58     168.58  \n",
       "3           353.34     353.34  \n",
       "4            22.78      22.78  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consulting_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Téléchargement de 'vehicle-sales-data' (18.84 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  21%|██        | 4.00/18.8 [00:04<00:14, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'vehicle-sales-data' téléchargé avec succès dans 'downloaded_datasets\\vehicle-sales-data'.\n",
      "✅ Dataset 'syedanwarafridi/vehicle-sales-data' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'telecom-customer' (13.57 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  29%|██▉       | 4.00/13.6 [00:04<00:09, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'telecom-customer' téléchargé avec succès dans 'downloaded_datasets\\telecom-customer'.\n",
      "✅ Dataset 'abhinav89/telecom-customer' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'customer-support-on-twitter' (168.58 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  11%|█▏        | 19.0/169 [00:19<02:29, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'customer-support-on-twitter' téléchargé avec succès dans 'downloaded_datasets\\customer-support-on-twitter'.\n",
      "✅ Dataset 'thoughtvector/customer-support-on-twitter' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'mutual-funds-and-etfs' (353.34 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  11%|█         | 39.0/353 [00:39<05:14, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'mutual-funds-and-etfs' téléchargé avec succès dans 'downloaded_datasets\\mutual-funds-and-etfs'.\n",
      "✅ Dataset 'stefanoleone992/mutual-funds-and-etfs' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\massive-yahoo-finance-dataset'\n",
      "📥 Téléchargement de 'massive-yahoo-finance-dataset' (22.78 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  22%|██▏       | 5.00/22.8 [00:05<00:17, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'massive-yahoo-finance-dataset' téléchargé avec succès dans 'downloaded_datasets\\massive-yahoo-finance-dataset'.\n",
      "✅ Dataset 'iveeaten3223times/massive-yahoo-finance-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\us-educational-finances'\n",
      "📥 Téléchargement de 'us-educational-finances' (85.43 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  19%|█▊        | 16.0/85.4 [00:16<01:09, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'us-educational-finances' téléchargé avec succès dans 'downloaded_datasets\\us-educational-finances'.\n",
      "✅ Dataset 'noriuk/us-educational-finances' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\yahoo-finance-all-stocks-dataset-daily-update'\n",
      "📥 Téléchargement de 'yahoo-finance-all-stocks-dataset-daily-update' (132.48 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  18%|█▊        | 24.0/132 [00:24<01:48, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'yahoo-finance-all-stocks-dataset-daily-update' téléchargé avec succès dans 'downloaded_datasets\\yahoo-finance-all-stocks-dataset-daily-update'.\n",
      "✅ Dataset 'tanavbajaj/yahoo-finance-all-stocks-dataset-daily-update' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\us-campaign-finance-20192020-fec'\n",
      "📥 Téléchargement de 'us-campaign-finance-20192020-fec' (1017.58 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  42%|████▏     | 429/1.02k [07:09<09:49, 1.00s/MB] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'us-campaign-finance-20192020-fec' téléchargé avec succès dans 'downloaded_datasets\\us-campaign-finance-20192020-fec'.\n",
      "✅ Dataset 'jeegarmaru/us-campaign-finance-20192020-fec' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\dataco-smart-supply-chain-for-big-data-analysis'\n",
      "📥 Téléchargement de 'dataco-smart-supply-chain-for-big-data-analysis' (25.67 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  74%|███████▍  | 19.0/25.7 [00:19<00:06, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'dataco-smart-supply-chain-for-big-data-analysis' téléchargé avec succès dans 'downloaded_datasets\\dataco-smart-supply-chain-for-big-data-analysis'.\n",
      "✅ Dataset 'shashwatwork/dataco-smart-supply-chain-for-big-data-analysis' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\ecommerce-order-dataset'\n",
      "📥 Téléchargement de 'ecommerce-order-dataset' (14.46 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  76%|███████▌  | 11.0/14.5 [00:11<00:03, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-order-dataset' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-order-dataset'.\n",
      "✅ Dataset 'bytadit/ecommerce-order-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\us-supply-chain-information-for-covid19'\n",
      "📥 Téléchargement de 'us-supply-chain-information-for-covid19' (100.63 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  64%|██████▎   | 64.0/101 [01:04<00:36, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'us-supply-chain-information-for-covid19' téléchargé avec succès dans 'downloaded_datasets\\us-supply-chain-information-for-covid19'.\n",
      "✅ Dataset 'skeller/us-supply-chain-information-for-covid19' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\data-sets-for-testing-human-resources'\n",
      "📥 Téléchargement de 'data-sets-for-testing-human-resources' (1038.55 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  46%|████▋     | 481/1.04k [08:01<09:18, 1.00s/MB] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'data-sets-for-testing-human-resources' téléchargé avec succès dans 'downloaded_datasets\\data-sets-for-testing-human-resources'.\n",
      "✅ Dataset 'mexwell/data-sets-for-testing-human-resources' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\online-retail-ii-uci'\n",
      "📥 Téléchargement de 'online-retail-ii-uci' (14.51 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  90%|████████▉ | 13.0/14.5 [00:13<00:01, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'online-retail-ii-uci' téléchargé avec succès dans 'downloaded_datasets\\online-retail-ii-uci'.\n",
      "✅ Dataset 'mashlyn/online-retail-ii-uci' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\retail-transactions-dataset'\n",
      "📥 Téléchargement de 'retail-transactions-dataset' (35.60 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  53%|█████▎    | 19.0/35.6 [00:19<00:16, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'retail-transactions-dataset' téléchargé avec succès dans 'downloaded_datasets\\retail-transactions-dataset'.\n",
      "✅ Dataset 'prasad22/retail-transactions-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\ecommerce-dataset'\n",
      "📥 Téléchargement de 'ecommerce-dataset' (290.60 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  56%|█████▌    | 162/291 [02:42<02:08, 1.00s/MB] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-dataset' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-dataset'.\n",
      "✅ Dataset 'retailrocket/ecommerce-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\retail-sales-data'\n",
      "📥 Téléchargement de 'retail-sales-data' (86.52 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  77%|███████▋  | 67.0/86.5 [01:07<00:19, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'retail-sales-data' téléchargé avec succès dans 'downloaded_datasets\\retail-sales-data'.\n",
      "✅ Dataset 'berkayalan/retail-sales-data' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\tata-online-retail-dataset'\n",
      "📥 Téléchargement de 'tata-online-retail-dataset' (29.04 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression: 30.0MB [00:30, 1.00s/MB]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'tata-online-retail-dataset' téléchargé avec succès dans 'downloaded_datasets\\tata-online-retail-dataset'.\n",
      "✅ Dataset 'ishanshrivastava28/tata-online-retail-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\retail-transactional-dataset'\n",
      "📥 Téléchargement de 'retail-transactional-dataset' (24.78 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  89%|████████▉ | 22.0/24.8 [00:22<00:02, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'retail-transactional-dataset' téléchargé avec succès dans 'downloaded_datasets\\retail-transactional-dataset'.\n",
      "✅ Dataset 'bhavikjikadara/retail-transactional-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\online-retail-dataset'\n",
      "📥 Téléchargement de 'online-retail-dataset' (43.48 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  60%|█████▉    | 26.0/43.5 [00:26<00:17, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'online-retail-dataset' téléchargé avec succès dans 'downloaded_datasets\\online-retail-dataset'.\n",
      "✅ Dataset 'sanlian/online-retail-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'online-retail-dataset' (43.30 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  81%|████████  | 35.0/43.3 [00:35<00:08, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'online-retail-dataset' téléchargé avec succès dans 'downloaded_datasets\\online-retail-dataset'.\n",
      "✅ Dataset 'lakshmi25npathi/online-retail-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\ecommerce-behavior-data-from-multi-category-store'\n",
      "📥 Téléchargement de 'ecommerce-behavior-data-from-multi-category-store' (4393.31 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  30%|███       | 1.33k/4.39k [22:11<51:09, 1.00s/MB] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-behavior-data-from-multi-category-store' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-behavior-data-from-multi-category-store'.\n",
      "✅ Dataset 'mkechinov/ecommerce-behavior-data-from-multi-category-store' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\ecommerce-data-analysis'\n",
      "📥 Téléchargement de 'ecommerce-data-analysis' (16.81 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  30%|██▉       | 5.00/16.8 [00:05<00:11, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-data-analysis' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-data-analysis'.\n",
      "✅ Dataset 'mmohaiminulislam/ecommerce-data-analysis' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\flipkart-fasion-products-dataset'\n",
      "📥 Téléchargement de 'flipkart-fasion-products-dataset' (15.05 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  33%|███▎      | 5.00/15.1 [00:05<00:10, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'flipkart-fasion-products-dataset' téléchargé avec succès dans 'downloaded_datasets\\flipkart-fasion-products-dataset'.\n",
      "✅ Dataset 'aaditshukla/flipkart-fasion-products-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\ecommerce-events-history-in-cosmetics-shop'\n",
      "📥 Téléchargement de 'ecommerce-events-history-in-cosmetics-shop' (429.98 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  13%|█▎        | 55.0/430 [00:55<06:15, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-events-history-in-cosmetics-shop' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-events-history-in-cosmetics-shop'.\n",
      "✅ Dataset 'mkechinov/ecommerce-events-history-in-cosmetics-shop' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\ecommerce-purchase-history-from-electronics-store'\n",
      "📥 Téléchargement de 'ecommerce-purchase-history-from-electronics-store' (50.46 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  18%|█▊        | 9.00/50.5 [00:09<00:41, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-purchase-history-from-electronics-store' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-purchase-history-from-electronics-store'.\n",
      "✅ Dataset 'mkechinov/ecommerce-purchase-history-from-electronics-store' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'ecommerce-dataset' (290.60 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  11%|█         | 32.0/291 [00:32<04:18, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-dataset' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-dataset'.\n",
      "✅ Dataset 'retailrocket/ecommerce-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\vietnam-war-bombing-operations'\n",
      "📥 Téléchargement de 'vietnam-war-bombing-operations' (304.86 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  11%|█         | 33.0/305 [00:33<04:32, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'vietnam-war-bombing-operations' téléchargé avec succès dans 'downloaded_datasets\\vietnam-war-bombing-operations'.\n",
      "✅ Dataset 'usaf/vietnam-war-bombing-operations' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\world-bank-projects-operations'\n",
      "📥 Téléchargement de 'world-bank-projects-operations' (31.55 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  22%|██▏       | 7.00/31.6 [00:07<00:24, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'world-bank-projects-operations' téléchargé avec succès dans 'downloaded_datasets\\world-bank-projects-operations'.\n",
      "✅ Dataset 'theworldbank/world-bank-projects-operations' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'retail-transactional-dataset' (24.78 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  20%|██        | 5.00/24.8 [00:05<00:19, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'retail-transactional-dataset' téléchargé avec succès dans 'downloaded_datasets\\retail-transactional-dataset'.\n",
      "✅ Dataset 'bhavikjikadara/retail-transactional-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\airlines-dataset'\n",
      "📥 Téléchargement de 'airlines-dataset' (29.62 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  27%|██▋       | 8.00/29.6 [00:08<00:21, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'airlines-dataset' téléchargé avec succès dans 'downloaded_datasets\\airlines-dataset'.\n",
      "✅ Dataset 'saadharoon27/airlines-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\mars-express-power-hackathon'\n",
      "📥 Téléchargement de 'mars-express-power-hackathon' (58.16 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  17%|█▋        | 10.0/58.2 [00:10<00:48, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'mars-express-power-hackathon' téléchargé avec succès dans 'downloaded_datasets\\mars-express-power-hackathon'.\n",
      "✅ Dataset 'europeanspaceagency/mars-express-power-hackathon' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\target-dataset'\n",
      "📥 Téléchargement de 'target-dataset' (36.19 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  19%|█▉        | 7.00/36.2 [00:07<00:29, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'target-dataset' téléchargé avec succès dans 'downloaded_datasets\\target-dataset'.\n",
      "✅ Dataset 'devarajv88/target-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\usa-real-estate-dataset'\n",
      "📥 Téléchargement de 'usa-real-estate-dataset' (38.23 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  18%|█▊        | 7.00/38.2 [00:07<00:31, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'usa-real-estate-dataset' téléchargé avec succès dans 'downloaded_datasets\\usa-real-estate-dataset'.\n",
      "✅ Dataset 'ahmedshahriarsakib/usa-real-estate-dataset' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\russia-real-estate-20182021'\n",
      "📥 Téléchargement de 'russia-real-estate-20182021' (110.74 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  13%|█▎        | 14.0/111 [00:14<01:36, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'russia-real-estate-20182021' téléchargé avec succès dans 'downloaded_datasets\\russia-real-estate-20182021'.\n",
      "✅ Dataset 'mrdaniilak/russia-real-estate-20182021' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\real-estate-california'\n",
      "📥 Téléchargement de 'real-estate-california' (11.44 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  44%|████▎     | 5.00/11.4 [00:05<00:06, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'real-estate-california' téléchargé avec succès dans 'downloaded_datasets\\real-estate-california'.\n",
      "✅ Dataset 'yellowj4acket/real-estate-california' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\gurgaon-real-estate-99acres-com'\n",
      "📥 Téléchargement de 'gurgaon-real-estate-99acres-com' (14.09 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  35%|███▌      | 5.00/14.1 [00:05<00:09, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'gurgaon-real-estate-99acres-com' téléchargé avec succès dans 'downloaded_datasets\\gurgaon-real-estate-99acres-com'.\n",
      "✅ Dataset 'arvanshul/gurgaon-real-estate-99acres-com' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\real-estate-sales-2001-2020'\n",
      "📥 Téléchargement de 'real-estate-sales-2001-2020' (27.51 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  25%|██▌       | 7.00/27.5 [00:07<00:20, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'real-estate-sales-2001-2020' téléchargé avec succès dans 'downloaded_datasets\\real-estate-sales-2001-2020'.\n",
      "✅ Dataset 'derrekdevon/real-estate-sales-2001-2020' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\russia-real-estate-2021'\n",
      "📥 Téléchargement de 'russia-real-estate-2021' (275.88 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  14%|█▍        | 38.0/276 [00:38<03:58, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'russia-real-estate-2021' téléchargé avec succès dans 'downloaded_datasets\\russia-real-estate-2021'.\n",
      "✅ Dataset 'mrdaniilak/russia-real-estate-2021' téléchargé avec succès.\n",
      "\n",
      "📁 Création du dossier : 'downloaded_datasets\\japan-real-estate-transaction-prices'\n",
      "📥 Téléchargement de 'japan-real-estate-transaction-prices' (97.31 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  22%|██▏       | 21.0/97.3 [00:21<01:16, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'japan-real-estate-transaction-prices' téléchargé avec succès dans 'downloaded_datasets\\japan-real-estate-transaction-prices'.\n",
      "✅ Dataset 'nishiodens/japan-real-estate-transaction-prices' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'vehicle-sales-data' (18.84 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  27%|██▋       | 5.00/18.8 [00:05<00:13, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'vehicle-sales-data' téléchargé avec succès dans 'downloaded_datasets\\vehicle-sales-data'.\n",
      "✅ Dataset 'syedanwarafridi/vehicle-sales-data' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'telecom-customer' (13.57 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  37%|███▋      | 5.00/13.6 [00:05<00:08, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'telecom-customer' téléchargé avec succès dans 'downloaded_datasets\\telecom-customer'.\n",
      "✅ Dataset 'abhinav89/telecom-customer' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'customer-support-on-twitter' (168.58 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  17%|█▋        | 29.0/169 [00:29<02:19, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'customer-support-on-twitter' téléchargé avec succès dans 'downloaded_datasets\\customer-support-on-twitter'.\n",
      "✅ Dataset 'thoughtvector/customer-support-on-twitter' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'mutual-funds-and-etfs' (353.34 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  16%|█▋        | 58.0/353 [00:58<04:55, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'mutual-funds-and-etfs' téléchargé avec succès dans 'downloaded_datasets\\mutual-funds-and-etfs'.\n",
      "✅ Dataset 'stefanoleone992/mutual-funds-and-etfs' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'massive-yahoo-finance-dataset' (22.78 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  22%|██▏       | 5.00/22.8 [00:05<00:17, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'massive-yahoo-finance-dataset' téléchargé avec succès dans 'downloaded_datasets\\massive-yahoo-finance-dataset'.\n",
      "✅ Dataset 'iveeaten3223times/massive-yahoo-finance-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'us-educational-finances' (85.43 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  15%|█▌        | 13.0/85.4 [00:13<01:12, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'us-educational-finances' téléchargé avec succès dans 'downloaded_datasets\\us-educational-finances'.\n",
      "✅ Dataset 'noriuk/us-educational-finances' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'yahoo-finance-all-stocks-dataset-daily-update' (132.48 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  16%|█▌        | 21.0/132 [00:21<01:51, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'yahoo-finance-all-stocks-dataset-daily-update' téléchargé avec succès dans 'downloaded_datasets\\yahoo-finance-all-stocks-dataset-daily-update'.\n",
      "✅ Dataset 'tanavbajaj/yahoo-finance-all-stocks-dataset-daily-update' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'us-campaign-finance-20192020-fec' (1017.58 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  12%|█▏        | 127/1.02k [02:07<14:51, 1.00s/MB] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'us-campaign-finance-20192020-fec' téléchargé avec succès dans 'downloaded_datasets\\us-campaign-finance-20192020-fec'.\n",
      "✅ Dataset 'jeegarmaru/us-campaign-finance-20192020-fec' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'dataco-smart-supply-chain-for-big-data-analysis' (25.67 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  23%|██▎       | 6.00/25.7 [00:06<00:19, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'dataco-smart-supply-chain-for-big-data-analysis' téléchargé avec succès dans 'downloaded_datasets\\dataco-smart-supply-chain-for-big-data-analysis'.\n",
      "✅ Dataset 'shashwatwork/dataco-smart-supply-chain-for-big-data-analysis' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'ecommerce-order-dataset' (14.46 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  28%|██▊       | 4.00/14.5 [00:04<00:10, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-order-dataset' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-order-dataset'.\n",
      "✅ Dataset 'bytadit/ecommerce-order-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'us-supply-chain-information-for-covid19' (100.63 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  15%|█▍        | 15.0/101 [00:15<01:25, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'us-supply-chain-information-for-covid19' téléchargé avec succès dans 'downloaded_datasets\\us-supply-chain-information-for-covid19'.\n",
      "✅ Dataset 'skeller/us-supply-chain-information-for-covid19' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'data-sets-for-testing-human-resources' (1038.55 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  13%|█▎        | 134/1.04k [02:14<15:05, 1.00s/MB] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'data-sets-for-testing-human-resources' téléchargé avec succès dans 'downloaded_datasets\\data-sets-for-testing-human-resources'.\n",
      "✅ Dataset 'mexwell/data-sets-for-testing-human-resources' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'online-retail-ii-uci' (14.51 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  34%|███▍      | 5.00/14.5 [00:05<00:09, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'online-retail-ii-uci' téléchargé avec succès dans 'downloaded_datasets\\online-retail-ii-uci'.\n",
      "✅ Dataset 'mashlyn/online-retail-ii-uci' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'retail-transactions-dataset' (35.60 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  22%|██▏       | 8.00/35.6 [00:08<00:27, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'retail-transactions-dataset' téléchargé avec succès dans 'downloaded_datasets\\retail-transactions-dataset'.\n",
      "✅ Dataset 'prasad22/retail-transactions-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'ecommerce-dataset' (290.60 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  16%|█▌        | 47.0/291 [00:47<04:03, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-dataset' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-dataset'.\n",
      "✅ Dataset 'retailrocket/ecommerce-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'retail-sales-data' (86.52 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  18%|█▊        | 16.0/86.5 [00:16<01:10, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'retail-sales-data' téléchargé avec succès dans 'downloaded_datasets\\retail-sales-data'.\n",
      "✅ Dataset 'berkayalan/retail-sales-data' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'tata-online-retail-dataset' (29.04 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  21%|██        | 6.00/29.0 [00:06<00:23, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'tata-online-retail-dataset' téléchargé avec succès dans 'downloaded_datasets\\tata-online-retail-dataset'.\n",
      "✅ Dataset 'ishanshrivastava28/tata-online-retail-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'retail-transactional-dataset' (24.78 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  20%|██        | 5.00/24.8 [00:05<00:19, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'retail-transactional-dataset' téléchargé avec succès dans 'downloaded_datasets\\retail-transactional-dataset'.\n",
      "✅ Dataset 'bhavikjikadara/retail-transactional-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'online-retail-dataset' (43.48 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  16%|█▌        | 7.00/43.5 [00:07<00:36, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'online-retail-dataset' téléchargé avec succès dans 'downloaded_datasets\\online-retail-dataset'.\n",
      "✅ Dataset 'sanlian/online-retail-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'online-retail-dataset' (43.30 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  16%|█▌        | 7.00/43.3 [00:07<00:36, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'online-retail-dataset' téléchargé avec succès dans 'downloaded_datasets\\online-retail-dataset'.\n",
      "✅ Dataset 'lakshmi25npathi/online-retail-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'ecommerce-behavior-data-from-multi-category-store' (4393.31 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  13%|█▎        | 579/4.39k [09:39<1:03:40, 1.00s/MB] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-behavior-data-from-multi-category-store' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-behavior-data-from-multi-category-store'.\n",
      "✅ Dataset 'mkechinov/ecommerce-behavior-data-from-multi-category-store' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'ecommerce-data-analysis' (16.81 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  36%|███▌      | 6.00/16.8 [00:06<00:10, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-data-analysis' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-data-analysis'.\n",
      "✅ Dataset 'mmohaiminulislam/ecommerce-data-analysis' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'flipkart-fasion-products-dataset' (15.05 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  33%|███▎      | 5.00/15.1 [00:05<00:10, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'flipkart-fasion-products-dataset' téléchargé avec succès dans 'downloaded_datasets\\flipkart-fasion-products-dataset'.\n",
      "✅ Dataset 'aaditshukla/flipkart-fasion-products-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'ecommerce-events-history-in-cosmetics-shop' (429.98 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  14%|█▍        | 60.0/430 [01:00<06:10, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-events-history-in-cosmetics-shop' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-events-history-in-cosmetics-shop'.\n",
      "✅ Dataset 'mkechinov/ecommerce-events-history-in-cosmetics-shop' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'ecommerce-purchase-history-from-electronics-store' (50.46 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  28%|██▊       | 14.0/50.5 [00:14<00:36, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-purchase-history-from-electronics-store' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-purchase-history-from-electronics-store'.\n",
      "✅ Dataset 'mkechinov/ecommerce-purchase-history-from-electronics-store' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'ecommerce-dataset' (290.60 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  15%|█▍        | 43.0/291 [00:43<04:07, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'ecommerce-dataset' téléchargé avec succès dans 'downloaded_datasets\\ecommerce-dataset'.\n",
      "✅ Dataset 'retailrocket/ecommerce-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'vietnam-war-bombing-operations' (304.86 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  12%|█▏        | 38.0/305 [00:38<04:27, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'vietnam-war-bombing-operations' téléchargé avec succès dans 'downloaded_datasets\\vietnam-war-bombing-operations'.\n",
      "✅ Dataset 'usaf/vietnam-war-bombing-operations' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'world-bank-projects-operations' (31.55 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  29%|██▊       | 9.00/31.6 [00:09<00:22, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'world-bank-projects-operations' téléchargé avec succès dans 'downloaded_datasets\\world-bank-projects-operations'.\n",
      "✅ Dataset 'theworldbank/world-bank-projects-operations' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'retail-transactional-dataset' (24.78 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  20%|██        | 5.00/24.8 [00:05<00:19, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'retail-transactional-dataset' téléchargé avec succès dans 'downloaded_datasets\\retail-transactional-dataset'.\n",
      "✅ Dataset 'bhavikjikadara/retail-transactional-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'airlines-dataset' (29.62 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  20%|██        | 6.00/29.6 [00:06<00:23, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'airlines-dataset' téléchargé avec succès dans 'downloaded_datasets\\airlines-dataset'.\n",
      "✅ Dataset 'saadharoon27/airlines-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'mars-express-power-hackathon' (58.16 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  19%|█▉        | 11.0/58.2 [00:11<00:47, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'mars-express-power-hackathon' téléchargé avec succès dans 'downloaded_datasets\\mars-express-power-hackathon'.\n",
      "✅ Dataset 'europeanspaceagency/mars-express-power-hackathon' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'target-dataset' (36.19 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  19%|█▉        | 7.00/36.2 [00:07<00:29, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'target-dataset' téléchargé avec succès dans 'downloaded_datasets\\target-dataset'.\n",
      "✅ Dataset 'devarajv88/target-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'usa-real-estate-dataset' (38.23 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  18%|█▊        | 7.00/38.2 [00:07<00:31, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'usa-real-estate-dataset' téléchargé avec succès dans 'downloaded_datasets\\usa-real-estate-dataset'.\n",
      "✅ Dataset 'ahmedshahriarsakib/usa-real-estate-dataset' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'russia-real-estate-20182021' (110.74 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  14%|█▎        | 15.0/111 [00:15<01:35, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'russia-real-estate-20182021' téléchargé avec succès dans 'downloaded_datasets\\russia-real-estate-20182021'.\n",
      "✅ Dataset 'mrdaniilak/russia-real-estate-20182021' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'real-estate-california' (11.44 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  35%|███▍      | 4.00/11.4 [00:04<00:07, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'real-estate-california' téléchargé avec succès dans 'downloaded_datasets\\real-estate-california'.\n",
      "✅ Dataset 'yellowj4acket/real-estate-california' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'gurgaon-real-estate-99acres-com' (14.09 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  35%|███▌      | 5.00/14.1 [00:05<00:09, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'gurgaon-real-estate-99acres-com' téléchargé avec succès dans 'downloaded_datasets\\gurgaon-real-estate-99acres-com'.\n",
      "✅ Dataset 'arvanshul/gurgaon-real-estate-99acres-com' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'real-estate-sales-2001-2020' (27.51 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  22%|██▏       | 6.00/27.5 [00:06<00:21, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'real-estate-sales-2001-2020' téléchargé avec succès dans 'downloaded_datasets\\real-estate-sales-2001-2020'.\n",
      "✅ Dataset 'derrekdevon/real-estate-sales-2001-2020' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'russia-real-estate-2021' (275.88 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  13%|█▎        | 36.0/276 [00:36<04:00, 1.00s/MB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'russia-real-estate-2021' téléchargé avec succès dans 'downloaded_datasets\\russia-real-estate-2021'.\n",
      "✅ Dataset 'mrdaniilak/russia-real-estate-2021' téléchargé avec succès.\n",
      "\n",
      "📥 Téléchargement de 'japan-real-estate-transaction-prices' (97.31 MB)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📥 Progression:  17%|█▋        | 17.0/97.3 [00:17<01:20, 1.00s/MB]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset 'japan-real-estate-transaction-prices' téléchargé avec succès dans 'downloaded_datasets\\japan-real-estate-transaction-prices'.\n",
      "✅ Dataset 'nishiodens/japan-real-estate-transaction-prices' téléchargé avec succès.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "url_list = []\n",
    "metadata_list = []\n",
    "count = 0\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def check_kaggle_auth():\n",
    "    \"\"\"Vérifie si l'utilisateur est bien authentifié avec l'API Kaggle.\"\"\"\n",
    "    if not os.environ.get('KAGGLE_USERNAME') or not os.environ.get('KAGGLE_KEY'):\n",
    "        print(\"❌ Erreur : L'utilisateur n'est pas authentifié avec Kaggle. Vérifie ta configuration Kaggle.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def download_dataset(dataset_ref: str, path: str = \".\", dataset_size=None):\n",
    "    \"\"\"\n",
    "    Télécharge un dataset Kaggle avec une barre de progression.\n",
    "    \n",
    "    Args:\n",
    "        dataset_ref (str): Référence Kaggle, ex. \"username/dataset-name\".\n",
    "        path (str, optionnel): Répertoire d’enregistrement.\n",
    "        dataset_size (float, optionnel): Taille en Mo, pour la barre de progression.\n",
    "    \"\"\"\n",
    "    if not check_kaggle_auth():\n",
    "        return  # Stoppe la fonction si Kaggle n'est pas authentifié\n",
    "    \n",
    "    dataset_title = dataset_ref.split(\"/\")[-1]  # Extraire le titre du dataset de la référence\n",
    "    dataset_folder = os.path.join(path, dataset_title)  # Chemin complet pour le dataset\n",
    "\n",
    "    # Créer le dossier si il n'existe pas déjà\n",
    "    if not os.path.exists(dataset_folder):\n",
    "        try:\n",
    "            os.makedirs(dataset_folder, exist_ok=True)  # Crée le dossier de destination\n",
    "            print(f\"📁 Création du dossier : '{dataset_folder}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Impossible de créer le dossier '{dataset_folder}'. Erreur : {str(e)}\")\n",
    "            return  # Arrêter l'exécution si on ne peut pas créer le dossier\n",
    "\n",
    "    # Commande de téléchargement via Kaggle CLI\n",
    "    command = [\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_ref, \"-p\", dataset_folder, \"--unzip\"]\n",
    "\n",
    "    # Afficher la taille du dataset si elle est fournie\n",
    "    if dataset_size:\n",
    "        print(f\"📥 Téléchargement de '{dataset_title}' ({dataset_size:.2f} MB)...\")\n",
    "    else:\n",
    "        print(f\"📥 Téléchargement de '{dataset_title}'...\")\n",
    "\n",
    "    try:\n",
    "        # Lancer le processus de téléchargement\n",
    "        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "        # Si la taille du dataset est connue, afficher la progression\n",
    "        with tqdm(total=dataset_size, unit=\"MB\", unit_scale=True, desc=\"📥 Progression\") as pbar:\n",
    "            while process.poll() is None:\n",
    "                time.sleep(1)\n",
    "                pbar.update(1)\n",
    "\n",
    "        # Vérifier si le téléchargement a réussi\n",
    "        if process.returncode == 0:\n",
    "            print(f\"✅ Dataset '{dataset_title}' téléchargé avec succès dans '{dataset_folder}'.\")\n",
    "            # Renommage du fichier téléchargé avec la taille\n",
    "            downloaded_file = os.path.join(dataset_folder, dataset_title + \".zip\")\n",
    "            if os.path.exists(downloaded_file):\n",
    "                size_str = f\"{dataset_size:.2f}\" if dataset_size < 1000 else f\"{dataset_size / 1000:.2f}GB\"\n",
    "                new_name = os.path.join(dataset_folder, f\"{dataset_title}_{size_str}.zip\")\n",
    "                os.rename(downloaded_file, new_name)\n",
    "                print(f\"📦 Fichier renommé : {new_name}\")\n",
    "        else:\n",
    "            print(f\"❌ Erreur lors du téléchargement de '{dataset_title}'. Code de retour : {process.returncode}\")\n",
    "            print(f\"💡 Détails de l'erreur : {process.stderr.read().decode('utf-8')}\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Erreur lors du téléchargement. Code de retour : {e.returncode}\")\n",
    "        print(f\"💡 Détails : {e.stderr.decode('utf-8')}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Erreur : La commande 'kaggle' n'a pas été trouvée. Assurez-vous que l'API Kaggle est installée.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Une erreur inattendue est survenue : {str(e)}\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "download_path = \"downloaded_datasets\"\n",
    "\n",
    "for idx, row in df_consulting_datasets.iterrows():\n",
    "    ref = row[\"ref\"]\n",
    "    size_mb = row.get(\"Size (Mb)\", None)  # Sécurisé même si la colonne est absente\n",
    "\n",
    "    try:\n",
    "        download_dataset(ref, path=download_path, dataset_size=size_mb)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du téléchargement de {ref} : {str(e)}\\n\")\n",
    "        continue\n",
    "\n",
    "# Exemple d'utilisation\n",
    "download_path = \"downloaded_datasets\"\n",
    "\n",
    "for idx, row in df_consulting_datasets.iterrows():\n",
    "    ref = row[\"ref\"]\n",
    "    size_mb = row.get(\"Size (Mb)\", None)  # Sécurisé même si la colonne est absente\n",
    "\n",
    "    try:\n",
    "        download_dataset(ref, path=download_path, dataset_size=size_mb)\n",
    "        print(f\"✅ Dataset '{ref}' téléchargé avec succès.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du téléchargement de {ref} : {str(e)}\\n\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming Datasets with Size Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files_with_size(directory):\n",
    "    \"\"\"\n",
    "    Parcours un dossier et tous ses sous-dossiers, et renomme tous les fichiers de données (CSV, Excel, JSON, etc.)\n",
    "    en ajoutant leur taille à la fin du nom du fichier (avant l'extension).\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Répertoire où chercher les fichiers.\n",
    "    \"\"\"\n",
    "    # Extensions des fichiers de données à vérifier\n",
    "    valid_extensions = ['.csv', '.xml', '.xlsx', '.xls', '.json', '.txt', '.parquet', '.tsv']\n",
    "    \n",
    "    # Parcours du répertoire et de ses sous-dossiers\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            \n",
    "            if any(filename.endswith(ext) for ext in valid_extensions):\n",
    "                file_size = os.path.getsize(file_path) / (1024 * 1024)  # Taille en Mo\n",
    "                \n",
    "                # Si la taille dépasse 1000 MB, on la convertit en GB\n",
    "                if file_size > 1000:\n",
    "                    size_str = f\"{file_size / 1024:.2f}GB\"\n",
    "                else:\n",
    "                    size_str = f\"{file_size:.2f}MB\"\n",
    "                \n",
    "                # Sépare le nom du fichier et son extension\n",
    "                name, ext = os.path.splitext(filename)\n",
    "                \n",
    "                # Nouveau nom avec la taille ajoutée\n",
    "                new_filename = f\"{name}_{size_str}{ext}\"\n",
    "                new_file_path = os.path.join(root, new_filename)\n",
    "                \n",
    "                # Renommage du fichier\n",
    "                os.rename(file_path, new_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading Agriculture datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path = \"downloaded_agriculture_datasets\"\n",
    "\n",
    "for idx, row in df_consulting_datasets.iterrows():\n",
    "    ref = row[\"ref\"]\n",
    "    size_mb = row.get(\"Size (Mb)\", None)  # Sécurisé même si la colonne est absente\n",
    "\n",
    "    try:\n",
    "        download_dataset(ref, path=download_path, dataset_size=size_mb)\n",
    "        print(f\"✅ Dataset '{ref}' téléchargé avec succès.\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du téléchargement de {ref} : {str(e)}\\n\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions For Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_models(keyword):\n",
    "    print(f\"Lister les modèles correspondant à '{keyword}' :\")\n",
    "    \n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    \n",
    "    models = api.models_list(search=keyword)\n",
    "    desired_columns = [\n",
    "        'id', 'ref', 'title', 'description', 'url',\n",
    "        'totalVotes', 'lastUpdated', 'tags', 'licenseName'\n",
    "    ]\n",
    "    \n",
    "    result = []\n",
    "    for model in models:\n",
    "        model_dict = {key: model[key] for key in model if key in desired_columns}\n",
    "        result.append(model_dict)\n",
    "    \n",
    "    df = pd.DataFrame(result)\n",
    "\n",
    "    # Suppression des colonnes inutiles contenant \"has\" ou \"Nullable\"\n",
    "    df = df.loc[:, ~df.columns.str.contains('has|Nullable', case=False)]\n",
    "    df[\"tags\"] = df[\"tags\"].apply(lambda x: [d[\"name\"] for d in x] if x is not None else [])\n",
    "    # Vérification des liens URL pour voir si les modèles sont accessibles\n",
    "    for idx, row in df.iterrows():\n",
    "        url = row[\"url\"]\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            if response.status_code >= 400:\n",
    "                df.drop(idx, inplace=True)\n",
    "        except requests.exceptions.RequestException:\n",
    "            df.drop(idx, inplace=True)\n",
    "    \n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
